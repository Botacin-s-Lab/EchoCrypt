{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import librosa\n",
    "import os\n",
    "import random\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math\n",
    "import torchaudio\n",
    "import csv\n",
    "import string\n",
    "\n",
    "from torch.utils.data import ConcatDataset\n",
    "from torchaudio.transforms import TimeMasking, FrequencyMasking\n",
    "from torchvision.ops import SqueezeExcitation\n",
    "from torchinfo import summary\n",
    "from torchsummary import summary\n",
    "from torchvision.ops import SqueezeExcitation\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from collections import defaultdict\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from scipy.io import wavfile\n",
    "from functools import reduce\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = \"CoAtNet-1-Best-Zoom.pkl\"\n",
    "model_path = \"CoAtNet-1-Zoom.pkl\"\n",
    "NOISE_FACTOR = 0.1 # based on Table 2 in the paper\n",
    "GENERATE_FT_DATASET = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_s = '0123456789abcdefghijklmnopqrstuvwxyz'\n",
    "labels = list(keys_s)\n",
    "keys = [k + '.wav' for k in labels]\n",
    "data_dict = {'Key':[], 'File':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def add_noise_to_stroke(stroke, noise_factor=None):\n",
    "    \"\"\"\n",
    "    Adds random noise to an audio stroke tensor.\n",
    "    \n",
    "    Args:\n",
    "    - stroke (torch.Tensor): The input audio stroke tensor.\n",
    "    - noise_factor (float): The factor determining the noise level relative to the stroke's signal.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: The noisy audio stroke tensor.\n",
    "    \"\"\"\n",
    "    noise = torch.randn(stroke.size()) * noise_factor\n",
    "    std_dev = stroke.std()\n",
    "    noise = noise * std_dev\n",
    "    noisy_stroke = stroke + noise\n",
    "    return noisy_stroke\n",
    "\n",
    "def isolator(signal, sample_rate, size, scan, before, after, threshold, show=False):\n",
    "    strokes = []\n",
    "    if show:\n",
    "        plt.figure(figsize=(7, 2))\n",
    "        librosa.display.waveshow(signal, sr=sample_rate)\n",
    "    fft = librosa.stft(signal, n_fft=size, hop_length=scan)\n",
    "    energy = np.abs(np.sum(fft, axis=0)).astype(float)\n",
    "    if show:\n",
    "        plt.figure(figsize=(7, 2))\n",
    "        librosa.display.waveshow(energy)\n",
    "    threshed = energy > threshold\n",
    "    if show:\n",
    "        plt.figure(figsize=(7, 2))\n",
    "        librosa.display.waveshow(threshed.astype(float))\n",
    "    peaks = np.where(threshed)[0]\n",
    "    peak_count = len(peaks)\n",
    "    prev_end = sample_rate * 0.1 * (-1)\n",
    "    for i in range(peak_count):\n",
    "        this_peak = peaks[i]\n",
    "        timestamp = (this_peak * scan) + size // 2\n",
    "        if timestamp > prev_end + (0.1 * sample_rate):\n",
    "            keystroke = signal[timestamp - before:timestamp + after]\n",
    "            strokes.append(torch.tensor(keystroke)[None, :])\n",
    "            if show:\n",
    "                plt.figure(figsize=(7, 2))\n",
    "                librosa.display.waveshow(keystroke, sr=sample_rate)\n",
    "            prev_end = timestamp + after\n",
    "    return strokes\n",
    "\n",
    "def convert_to_df_with_noise(audio_dir, noise_factor=None):\n",
    "    \"\"\"\n",
    "    Processes each audio file by isolating strokes, adds noise to each stroke,\n",
    "    and stores the strokes with labels in a dataframe.\n",
    "    \"\"\"\n",
    "    # Generate a list of .wav files in the provided directory\n",
    "    keys = sorted([f for f in os.listdir(audio_dir) if f.endswith('.wav')])\n",
    "    \n",
    "    data_dict = {'Key': [], 'File': []}\n",
    "    \n",
    "    # If your labels are inferred from file names, you can extract them here.\n",
    "    # For example, if the file is 'a.wav', you might want to use 'a' as the label.\n",
    "    def extract_label(filename):\n",
    "        base = os.path.splitext(filename)[0]\n",
    "        return base  # or apply any mapping you need\n",
    "\n",
    "    for file in keys:\n",
    "        loc = os.path.join(audio_dir, file)\n",
    "        samples, sample_rate = librosa.load(loc, sr=None)\n",
    "        strokes = []\n",
    "        prom = 0.06\n",
    "        step = 0.005\n",
    "        # Adjust threshold until we get exactly 25 strokes (or break if not possible)\n",
    "        while not len(strokes) == 25:\n",
    "            strokes = isolator(samples[1 * sample_rate:], sample_rate, 48, 24, 2400, 12000, prom, show=False)\n",
    "            if len(strokes) < 25:\n",
    "                prom -= step\n",
    "            elif len(strokes) > 25:\n",
    "                prom += step\n",
    "            if prom <= 0:\n",
    "                print('-- not possible for:', file)\n",
    "                break\n",
    "            step *= 0.99\n",
    "        \n",
    "        # Apply noise to each extracted stroke\n",
    "        noisy_strokes = [add_noise_to_stroke(stroke, noise_factor) for stroke in strokes]\n",
    "\n",
    "        # Extract a label for this file (modify as needed)\n",
    "        label = extract_label(file)\n",
    "        data_dict['Key'] += [label] * len(noisy_strokes)\n",
    "        data_dict['File'] += noisy_strokes\n",
    "\n",
    "    df = pd.DataFrame(data_dict)\n",
    "    \n",
    "    # Optionally, create a mapping for the labels (if needed)\n",
    "    mapper = {}\n",
    "    counter = 0\n",
    "    for l in df['Key']:\n",
    "        if l not in mapper:\n",
    "            mapper[l] = counter\n",
    "            counter += 1\n",
    "    df.replace({'Key': mapper}, inplace=True)\n",
    "    \n",
    "    return df, sample_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Key                                               File\n",
      "0   0  [[tensor(-9.3394e-05), tensor(0.0002), tensor(...\n",
      "1   0  [[tensor(-0.0002), tensor(-0.0002), tensor(2.0...\n",
      "2   0  [[tensor(0.0004), tensor(8.3550e-05), tensor(-...\n",
      "3   0  [[tensor(-0.0002), tensor(-0.0005), tensor(-0....\n",
      "4   0  [[tensor(1.1037e-05), tensor(-0.0003), tensor(...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 900 entries, 0 to 899\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Key     900 non-null    object\n",
      " 1   File    900 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 14.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data_frame, sr = convert_to_df_with_noise(\"../../dataset/Zoom/\", noise_factor=NOISE_FACTOR)\n",
    "\n",
    "print(data_frame.head())\n",
    "print(data_frame.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample rate: 32000\n",
      "630 180 90\n"
     ]
    }
   ],
   "source": [
    "train_set, tmp_set = train_test_split(data_frame, test_size=0.3, stratify=data_frame['Key'])\n",
    "val_set, test_set = train_test_split(tmp_set, test_size=0.33, stratify=tmp_set['Key'])\n",
    "\n",
    "print(\"Sample rate:\", sr)\n",
    "print(len(train_set), len(val_set), len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, file_name, transform = None, aug = None):\n",
    "        df = file_name\n",
    "        self.transform = transform\n",
    "        self.aug = aug\n",
    "        self.labels = df['Key']\n",
    "        self.values = df['File']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, index):\n",
    "        label = self.labels.iloc[index]\n",
    "        value = self.values.iloc[index]\n",
    "        waveform = self.values.iloc[index]\n",
    "        label = self.labels.iloc[index]\n",
    "        if self.transform:\n",
    "            waveform = waveform.numpy()\n",
    "            waveform = waveform.flatten()\n",
    "            waveform = self.transform(waveform)\n",
    "        if self.aug:\n",
    "            waveform = self.aug(waveform)\n",
    "        return waveform, label\n",
    "\n",
    "class ToMelSpectrogram:\n",
    "    def __call__(self, samples):\n",
    "#         samples = np.array(samples)\n",
    "        spec = librosa.feature.melspectrogram(y = samples, sr = sr, n_mels=64, n_fft=2048, win_length=1024, hop_length=226)\n",
    "        return librosa.power_to_db(spec)\n",
    "\n",
    "class TimeShifting():\n",
    "    def __call__(self, samples):\n",
    "        samples = samples.numpy()\n",
    "        samples = samples.flatten()\n",
    "        \n",
    "        shift = int(len(samples) * 0.4)\n",
    "        random_shift =random.randint(0, shift)\n",
    "        data_roll = np.roll(samples, random_shift)\n",
    "        return data_roll\n",
    "    \n",
    "class SpecAugment():\n",
    "    def __call__(self, samples):\n",
    "        num_mask = 2\n",
    "        freq_masking_max_percentage=0.10\n",
    "        time_masking_max_percentage=0.10\n",
    "        spec = samples.copy()\n",
    "        mean_value = spec.mean()\n",
    "        for i in range(num_mask):\n",
    "            all_frames_num, all_freqs_num = spec.shape[1], spec.shape[1] \n",
    "            freq_percentage = random.uniform(0.0, freq_masking_max_percentage)\n",
    "\n",
    "            num_freqs_to_mask = int(freq_percentage * all_freqs_num)\n",
    "            f0 = np.random.uniform(low=0.0, high=all_freqs_num - num_freqs_to_mask)\n",
    "            f0 = int(f0)\n",
    "            spec[:, f0:f0 + num_freqs_to_mask] = mean_value\n",
    "\n",
    "            time_percentage = random.uniform(0.0, time_masking_max_percentage)\n",
    "\n",
    "            num_frames_to_mask = int(time_percentage * all_frames_num)\n",
    "            t0 = np.random.uniform(low=0.0, high=all_frames_num - num_frames_to_mask)\n",
    "            t0 = int(t0)\n",
    "            spec[t0:t0 + num_frames_to_mask, :] = mean_value\n",
    "        return spec\n",
    "\n",
    "aug = Compose([\n",
    "    TimeShifting(),\n",
    "    ToMelSpectrogram(),\n",
    "    SpecAugment(),\n",
    "    ToTensor()\n",
    "    ])\n",
    "\n",
    "transform = Compose([\n",
    "    ToMelSpectrogram(),\n",
    "    ToTensor()])\n",
    "        \n",
    "train_set = MyDataset(train_set, aug = aug)\n",
    "val_set = MyDataset(val_set, transform = transform)\n",
    "test_set = MyDataset(test_set, transform = transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set image (augmented vs non-augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax1.imshow(train_set[0][0][0], cmap='viridis')\n",
    "ax2.imshow(val_set[0][0][0], cmap='viridis')\n",
    "print(train_set[0][0][0].shape)\n",
    "ax1.grid(False)\n",
    "ax2.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of classes: 36\n"
     ]
    }
   ],
   "source": [
    "print(\"number of classes:\", len(np.unique(data_frame['Key'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoAtNet (Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stem(nn.Sequential):\n",
    "    def __init__(self, out_channels):\n",
    "        super().__init__(\n",
    "            nn.Conv2d(1, out_channels, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MBConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, expansion_factor=4):\n",
    "        super().__init__()\n",
    "        self.mb_conv = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.Conv2d(in_channels, in_channels * expansion_factor, kernel_size=1),\n",
    "            nn.BatchNorm2d(in_channels * expansion_factor),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(in_channels * expansion_factor, in_channels * expansion_factor, kernel_size=3, padding=1, groups=in_channels * expansion_factor),\n",
    "            nn.BatchNorm2d(in_channels * expansion_factor),\n",
    "            nn.GELU(),\n",
    "            SqueezeExcitation(in_channels * expansion_factor, in_channels, activation=nn.GELU),\n",
    "            nn.Conv2d(in_channels * expansion_factor, out_channels, kernel_size=1),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.mb_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownsamplingMBConv(MBConv):\n",
    "    def __init__(self, in_channels, out_channels, expansion_factor=4):\n",
    "        super().__init__(in_channels, out_channels, expansion_factor=4)\n",
    "        self.mb_conv[1] = nn.Conv2d(in_channels, in_channels * expansion_factor, kernel_size=1, stride = 2)\n",
    "        self.channel_projection = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.channel_projection(self.pool(x)) + self.mb_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelativeAttention2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, image_size, heads=8, head_size=32):\n",
    "        super().__init__()\n",
    "        heads = out_channels // head_size\n",
    "        self.heads = heads\n",
    "        self.head_size = head_size\n",
    "        self.image_size = image_size\n",
    "        self.head_dim = heads * head_size\n",
    "        self.attend = nn.Softmax(dim=-2) # Taken from My_CoAtNet\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.to_q = nn.Linear(in_channels, self.head_dim)\n",
    "        self.to_k = nn.Linear(in_channels, self.head_dim)\n",
    "        self.to_v = nn.Linear(in_channels, self.head_dim)\n",
    "        self.to_output = nn.Sequential(\n",
    "            nn.Linear(self.head_dim, out_channels),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.normalization = nn.LayerNorm(in_channels)\n",
    "        \n",
    "        self.relative_bias = nn.Parameter(torch.randn(heads, (2 * image_size - 1) * (2 * image_size - 1)))\n",
    "        self.register_buffer(\"relative_indices\", self.get_indices(image_size, image_size)) # Taken from My_CoAtNet\n",
    "        self.precomputed_relative_bias = None\n",
    "    \n",
    "    def norm(self, x):\n",
    "        x = x.transpose(1, -1) # Taken from My_CoAtNet\n",
    "        x = self.normalization(x)\n",
    "        x = x.transpose(-1, 1) # Taken from My_CoAtNet\n",
    "        return x\n",
    "    \n",
    "    def get_relative_biases(self):\n",
    "        # Relative bias caching mentioned in CoAtNet: Marrying Convolution and Attention for All Data Sizes\n",
    "        if not self.training:\n",
    "            return self.precomputed_relative_bias\n",
    "        # Taken from od My_CoAtNet\n",
    "        indices = self.relative_indices.expand(self.heads, -1)\n",
    "        rel_pos_enc = self.relative_bias.gather(-1, indices)\n",
    "        rel_pos_enc = rel_pos_enc.unflatten(-1, (self.image_size * self.image_size, self.image_size * self.image_size))\n",
    "        return rel_pos_enc\n",
    "    \n",
    "    def reshape_for_linear(self, x):\n",
    "        b, _, _, _ = x.shape\n",
    "        return x.reshape(b, self.image_size * self.image_size, self.in_channels)\n",
    "    \n",
    "    def attention_score(self, x):\n",
    "        b, _, h, _ = x.shape\n",
    "        q = self.to_q(self.reshape_for_linear(x)).view(b, self.heads, self.head_size, -1) # Taken from My_CoAtNet\n",
    "        k = self.to_k(self.reshape_for_linear(x)).view(b, self.heads, self.head_size, -1) # Taken from My_CoAtNet\n",
    "        dots = torch.matmul(k.transpose(-1, -2), q) / math.sqrt(self.head_dim)\n",
    "        relative_biases_indexed = self.get_relative_biases()\n",
    "        return self.attend(dots + relative_biases_indexed)\n",
    "    \n",
    "    def relative_attention(self, x):\n",
    "        b, _, _, _ = x.shape\n",
    "        v = self.to_v(self.reshape_for_linear(x)).view(b, self.heads, self.head_size, -1) # Taken from My_CoAtNet\n",
    "        out = torch.matmul(v, self.attention_score(x)) # I figured this out after debugging (Still the same as My_CoAtNet)\n",
    "        out = out.view(b, self.image_size, self.image_size, -1)\n",
    "        return self.to_output(out).view(b, self.out_channels, self.image_size, self.image_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.relative_attention(self.norm(x))\n",
    "    \n",
    "    def train(self, training):\n",
    "        if not training:\n",
    "            self.precomputed_relative_bias = self.get_relative_biases()\n",
    "        super().train(training)\n",
    "        \n",
    "    # Taken from My_CoAtNet\n",
    "    @staticmethod\n",
    "    def get_indices(h, w):\n",
    "        y = torch.arange(h, dtype=torch.long)\n",
    "        x = torch.arange(w, dtype=torch.long)\n",
    "        \n",
    "        y1, x1, y2, x2 = torch.meshgrid(y, x, y, x)\n",
    "        indices = (y1 - y2 + h - 1) * (2 * w - 1) + x1 - x2 + w - 1\n",
    "        indices = indices.flatten()\n",
    "        \n",
    "        return indices\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownsamplingRelativeAttention2d(RelativeAttention2d):\n",
    "    def __init__(self, in_channels, out_channels, image_size, heads=8, head_size=32):\n",
    "        super().__init__(in_channels, out_channels, image_size, heads=8, head_size=32)\n",
    "        self.channel_projection = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.normalization = nn.LayerNorm(in_channels)\n",
    "\n",
    "\n",
    "    def norm(self, x):\n",
    "        x = x.transpose(1, -1) # Taken from My_CoAtNet\n",
    "        x = self.normalization(x)\n",
    "        x = x.transpose(-1, 1) # Taken from My_CoAtNet\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.channel_projection(self.pool(x)) + self.relative_attention(self.pool(self.norm(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, out_channels, expansion_factor=4):\n",
    "        super().__init__()\n",
    "        hidden_dim = out_channels * expansion_factor\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(out_channels, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, out_channels),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.normalization = nn.LayerNorm(out_channels)\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    \n",
    "    def norm(self, x):\n",
    "        x = x.transpose(1, -1) # Taken from My_CoAtNet\n",
    "        x = self.normalization(x)\n",
    "        x = x.transpose(-1, 1) # Taken from My_CoAtNet\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        old_shape = x.shape\n",
    "        batch_size = old_shape[0]\n",
    "        return x + torch.reshape(self.ffn(torch.reshape(self.norm(x), (batch_size, -1, self.out_channels))), old_shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownsampleTransformerBlock(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels, image_size):\n",
    "        attention = DownsamplingRelativeAttention2d(in_channels, out_channels, image_size)\n",
    "        ffn = FeedForwardNetwork(out_channels)\n",
    "        super().__init__(\n",
    "            attention,\n",
    "            ffn\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels, image_size):\n",
    "        attention = RelativeAttention2d(in_channels, out_channels, image_size)\n",
    "        ffn = FeedForwardNetwork(out_channels)\n",
    "        super().__init__(\n",
    "            attention,\n",
    "            ffn\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(in_channels, num_classes)\n",
    "        self.in_channels = in_channels\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.pool(x)\n",
    "        x = torch.reshape(x, (batch_size, -1, self.in_channels))\n",
    "        return torch.squeeze(self.fc(x))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCoAtNet(nn.Sequential):\n",
    "    def __init__(self, nums_blocks, layer_out_channels, num_classes=36):\n",
    "        s0 = nn.Sequential(Stem(layer_out_channels[0]))\n",
    "        \n",
    "        s1 = [DownsamplingMBConv(layer_out_channels[0], layer_out_channels[1])]\n",
    "        for i in range(nums_blocks[1] - 1):\n",
    "            s1.append(MBConv(layer_out_channels[1], layer_out_channels[1]))\n",
    "        s1 = nn.Sequential(*s1)\n",
    "        \n",
    "        s2 = [DownsamplingMBConv(layer_out_channels[1], layer_out_channels[2])]\n",
    "        for i in range(nums_blocks[2] - 1):\n",
    "            s2.append(MBConv(layer_out_channels[2], layer_out_channels[2]))\n",
    "        s2 = nn.Sequential(*s2)\n",
    "        \n",
    "        s3 = [DownsampleTransformerBlock(layer_out_channels[2], layer_out_channels[3], 64 // 16)]\n",
    "        for i in range(nums_blocks[3] - 1):\n",
    "            s3.append(TransformerBlock(layer_out_channels[3], layer_out_channels[3], 64 // 16))\n",
    "        s3 = nn.Sequential(*s3)\n",
    "        \n",
    "        s4 = [DownsampleTransformerBlock(layer_out_channels[3], layer_out_channels[4], 64 // 32)]\n",
    "        for i in range(nums_blocks[4] - 1):\n",
    "            s4.append(TransformerBlock(layer_out_channels[4], layer_out_channels[4], 64 // 32))\n",
    "        s4 = nn.Sequential(*s4)\n",
    "        \n",
    "        head = Head(layer_out_channels[4], num_classes)\n",
    "        \n",
    "        super().__init__(\n",
    "            s0,\n",
    "            s1,\n",
    "            s2,\n",
    "            s3,\n",
    "            s4,\n",
    "            head\n",
    "        )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ali/EchoCrypt/venv/lib/python3.10/site-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3637.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# CoAtNet-1\n",
    "nums_blocks = [2, 2, 3, 5, 2]           # L\n",
    "channels = [64, 96, 192, 384, 768]      # D\n",
    "\n",
    "model = MyCoAtNet(nums_blocks, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_linear(m):\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "        if m.bias is not None: nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 24,033,296\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]             640\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "              GELU-3           [-1, 64, 32, 32]               0\n",
      "            Conv2d-4           [-1, 64, 30, 30]          36,928\n",
      "         MaxPool2d-5           [-1, 64, 15, 15]               0\n",
      "            Conv2d-6           [-1, 96, 15, 15]           6,144\n",
      "       BatchNorm2d-7           [-1, 64, 30, 30]             128\n",
      "            Conv2d-8          [-1, 256, 15, 15]          16,640\n",
      "       BatchNorm2d-9          [-1, 256, 15, 15]             512\n",
      "             GELU-10          [-1, 256, 15, 15]               0\n",
      "           Conv2d-11          [-1, 256, 15, 15]           2,560\n",
      "      BatchNorm2d-12          [-1, 256, 15, 15]             512\n",
      "             GELU-13          [-1, 256, 15, 15]               0\n",
      "AdaptiveAvgPool2d-14            [-1, 256, 1, 1]               0\n",
      "           Conv2d-15             [-1, 64, 1, 1]          16,448\n",
      "             GELU-16             [-1, 64, 1, 1]               0\n",
      "           Conv2d-17            [-1, 256, 1, 1]          16,640\n",
      "          Sigmoid-18            [-1, 256, 1, 1]               0\n",
      "SqueezeExcitation-19          [-1, 256, 15, 15]               0\n",
      "           Conv2d-20           [-1, 96, 15, 15]          24,672\n",
      "      BatchNorm2d-21           [-1, 96, 15, 15]             192\n",
      "DownsamplingMBConv-22           [-1, 96, 15, 15]               0\n",
      "      BatchNorm2d-23           [-1, 96, 15, 15]             192\n",
      "           Conv2d-24          [-1, 384, 15, 15]          37,248\n",
      "      BatchNorm2d-25          [-1, 384, 15, 15]             768\n",
      "             GELU-26          [-1, 384, 15, 15]               0\n",
      "           Conv2d-27          [-1, 384, 15, 15]           3,840\n",
      "      BatchNorm2d-28          [-1, 384, 15, 15]             768\n",
      "             GELU-29          [-1, 384, 15, 15]               0\n",
      "AdaptiveAvgPool2d-30            [-1, 384, 1, 1]               0\n",
      "           Conv2d-31             [-1, 96, 1, 1]          36,960\n",
      "             GELU-32             [-1, 96, 1, 1]               0\n",
      "           Conv2d-33            [-1, 384, 1, 1]          37,248\n",
      "          Sigmoid-34            [-1, 384, 1, 1]               0\n",
      "SqueezeExcitation-35          [-1, 384, 15, 15]               0\n",
      "           Conv2d-36           [-1, 96, 15, 15]          36,960\n",
      "      BatchNorm2d-37           [-1, 96, 15, 15]             192\n",
      "           MBConv-38           [-1, 96, 15, 15]               0\n",
      "        MaxPool2d-39             [-1, 96, 8, 8]               0\n",
      "           Conv2d-40            [-1, 192, 8, 8]          18,432\n",
      "      BatchNorm2d-41           [-1, 96, 15, 15]             192\n",
      "           Conv2d-42            [-1, 384, 8, 8]          37,248\n",
      "      BatchNorm2d-43            [-1, 384, 8, 8]             768\n",
      "             GELU-44            [-1, 384, 8, 8]               0\n",
      "           Conv2d-45            [-1, 384, 8, 8]           3,840\n",
      "      BatchNorm2d-46            [-1, 384, 8, 8]             768\n",
      "             GELU-47            [-1, 384, 8, 8]               0\n",
      "AdaptiveAvgPool2d-48            [-1, 384, 1, 1]               0\n",
      "           Conv2d-49             [-1, 96, 1, 1]          36,960\n",
      "             GELU-50             [-1, 96, 1, 1]               0\n",
      "           Conv2d-51            [-1, 384, 1, 1]          37,248\n",
      "          Sigmoid-52            [-1, 384, 1, 1]               0\n",
      "SqueezeExcitation-53            [-1, 384, 8, 8]               0\n",
      "           Conv2d-54            [-1, 192, 8, 8]          73,920\n",
      "      BatchNorm2d-55            [-1, 192, 8, 8]             384\n",
      "DownsamplingMBConv-56            [-1, 192, 8, 8]               0\n",
      "      BatchNorm2d-57            [-1, 192, 8, 8]             384\n",
      "           Conv2d-58            [-1, 768, 8, 8]         148,224\n",
      "      BatchNorm2d-59            [-1, 768, 8, 8]           1,536\n",
      "             GELU-60            [-1, 768, 8, 8]               0\n",
      "           Conv2d-61            [-1, 768, 8, 8]           7,680\n",
      "      BatchNorm2d-62            [-1, 768, 8, 8]           1,536\n",
      "             GELU-63            [-1, 768, 8, 8]               0\n",
      "AdaptiveAvgPool2d-64            [-1, 768, 1, 1]               0\n",
      "           Conv2d-65            [-1, 192, 1, 1]         147,648\n",
      "             GELU-66            [-1, 192, 1, 1]               0\n",
      "           Conv2d-67            [-1, 768, 1, 1]         148,224\n",
      "          Sigmoid-68            [-1, 768, 1, 1]               0\n",
      "SqueezeExcitation-69            [-1, 768, 8, 8]               0\n",
      "           Conv2d-70            [-1, 192, 8, 8]         147,648\n",
      "      BatchNorm2d-71            [-1, 192, 8, 8]             384\n",
      "           MBConv-72            [-1, 192, 8, 8]               0\n",
      "      BatchNorm2d-73            [-1, 192, 8, 8]             384\n",
      "           Conv2d-74            [-1, 768, 8, 8]         148,224\n",
      "      BatchNorm2d-75            [-1, 768, 8, 8]           1,536\n",
      "             GELU-76            [-1, 768, 8, 8]               0\n",
      "           Conv2d-77            [-1, 768, 8, 8]           7,680\n",
      "      BatchNorm2d-78            [-1, 768, 8, 8]           1,536\n",
      "             GELU-79            [-1, 768, 8, 8]               0\n",
      "AdaptiveAvgPool2d-80            [-1, 768, 1, 1]               0\n",
      "           Conv2d-81            [-1, 192, 1, 1]         147,648\n",
      "             GELU-82            [-1, 192, 1, 1]               0\n",
      "           Conv2d-83            [-1, 768, 1, 1]         148,224\n",
      "          Sigmoid-84            [-1, 768, 1, 1]               0\n",
      "SqueezeExcitation-85            [-1, 768, 8, 8]               0\n",
      "           Conv2d-86            [-1, 192, 8, 8]         147,648\n",
      "      BatchNorm2d-87            [-1, 192, 8, 8]             384\n",
      "           MBConv-88            [-1, 192, 8, 8]               0\n",
      "        MaxPool2d-89            [-1, 192, 4, 4]               0\n",
      "           Conv2d-90            [-1, 384, 4, 4]          73,728\n",
      "        LayerNorm-91            [-1, 8, 8, 192]             384\n",
      "        MaxPool2d-92            [-1, 192, 4, 4]               0\n",
      "           Linear-93              [-1, 16, 384]          74,112\n",
      "           Linear-94              [-1, 16, 384]          74,112\n",
      "           Linear-95              [-1, 16, 384]          74,112\n",
      "          Softmax-96           [-1, 12, 16, 16]               0\n",
      "           Linear-97            [-1, 4, 4, 384]         147,840\n",
      "          Dropout-98            [-1, 4, 4, 384]               0\n",
      "DownsamplingRelativeAttention2d-99            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-100            [-1, 4, 4, 384]             768\n",
      "          Linear-101             [-1, 16, 1536]         591,360\n",
      "            GELU-102             [-1, 16, 1536]               0\n",
      "         Dropout-103             [-1, 16, 1536]               0\n",
      "          Linear-104              [-1, 16, 384]         590,208\n",
      "         Dropout-105              [-1, 16, 384]               0\n",
      "FeedForwardNetwork-106            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-107            [-1, 4, 4, 384]             768\n",
      "          Linear-108              [-1, 16, 384]         147,840\n",
      "          Linear-109              [-1, 16, 384]         147,840\n",
      "          Linear-110              [-1, 16, 384]         147,840\n",
      "         Softmax-111           [-1, 12, 16, 16]               0\n",
      "          Linear-112            [-1, 4, 4, 384]         147,840\n",
      "         Dropout-113            [-1, 4, 4, 384]               0\n",
      "RelativeAttention2d-114            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-115            [-1, 4, 4, 384]             768\n",
      "          Linear-116             [-1, 16, 1536]         591,360\n",
      "            GELU-117             [-1, 16, 1536]               0\n",
      "         Dropout-118             [-1, 16, 1536]               0\n",
      "          Linear-119              [-1, 16, 384]         590,208\n",
      "         Dropout-120              [-1, 16, 384]               0\n",
      "FeedForwardNetwork-121            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-122            [-1, 4, 4, 384]             768\n",
      "          Linear-123              [-1, 16, 384]         147,840\n",
      "          Linear-124              [-1, 16, 384]         147,840\n",
      "          Linear-125              [-1, 16, 384]         147,840\n",
      "         Softmax-126           [-1, 12, 16, 16]               0\n",
      "          Linear-127            [-1, 4, 4, 384]         147,840\n",
      "         Dropout-128            [-1, 4, 4, 384]               0\n",
      "RelativeAttention2d-129            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-130            [-1, 4, 4, 384]             768\n",
      "          Linear-131             [-1, 16, 1536]         591,360\n",
      "            GELU-132             [-1, 16, 1536]               0\n",
      "         Dropout-133             [-1, 16, 1536]               0\n",
      "          Linear-134              [-1, 16, 384]         590,208\n",
      "         Dropout-135              [-1, 16, 384]               0\n",
      "FeedForwardNetwork-136            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-137            [-1, 4, 4, 384]             768\n",
      "          Linear-138              [-1, 16, 384]         147,840\n",
      "          Linear-139              [-1, 16, 384]         147,840\n",
      "          Linear-140              [-1, 16, 384]         147,840\n",
      "         Softmax-141           [-1, 12, 16, 16]               0\n",
      "          Linear-142            [-1, 4, 4, 384]         147,840\n",
      "         Dropout-143            [-1, 4, 4, 384]               0\n",
      "RelativeAttention2d-144            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-145            [-1, 4, 4, 384]             768\n",
      "          Linear-146             [-1, 16, 1536]         591,360\n",
      "            GELU-147             [-1, 16, 1536]               0\n",
      "         Dropout-148             [-1, 16, 1536]               0\n",
      "          Linear-149              [-1, 16, 384]         590,208\n",
      "         Dropout-150              [-1, 16, 384]               0\n",
      "FeedForwardNetwork-151            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-152            [-1, 4, 4, 384]             768\n",
      "          Linear-153              [-1, 16, 384]         147,840\n",
      "          Linear-154              [-1, 16, 384]         147,840\n",
      "          Linear-155              [-1, 16, 384]         147,840\n",
      "         Softmax-156           [-1, 12, 16, 16]               0\n",
      "          Linear-157            [-1, 4, 4, 384]         147,840\n",
      "         Dropout-158            [-1, 4, 4, 384]               0\n",
      "RelativeAttention2d-159            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-160            [-1, 4, 4, 384]             768\n",
      "          Linear-161             [-1, 16, 1536]         591,360\n",
      "            GELU-162             [-1, 16, 1536]               0\n",
      "         Dropout-163             [-1, 16, 1536]               0\n",
      "          Linear-164              [-1, 16, 384]         590,208\n",
      "         Dropout-165              [-1, 16, 384]               0\n",
      "FeedForwardNetwork-166            [-1, 384, 4, 4]               0\n",
      "       MaxPool2d-167            [-1, 384, 2, 2]               0\n",
      "          Conv2d-168            [-1, 768, 2, 2]         294,912\n",
      "       LayerNorm-169            [-1, 4, 4, 384]             768\n",
      "       MaxPool2d-170            [-1, 384, 2, 2]               0\n",
      "          Linear-171               [-1, 4, 768]         295,680\n",
      "          Linear-172               [-1, 4, 768]         295,680\n",
      "          Linear-173               [-1, 4, 768]         295,680\n",
      "         Softmax-174             [-1, 24, 4, 4]               0\n",
      "          Linear-175            [-1, 2, 2, 768]         590,592\n",
      "         Dropout-176            [-1, 2, 2, 768]               0\n",
      "DownsamplingRelativeAttention2d-177            [-1, 768, 2, 2]               0\n",
      "       LayerNorm-178            [-1, 2, 2, 768]           1,536\n",
      "          Linear-179              [-1, 4, 3072]       2,362,368\n",
      "            GELU-180              [-1, 4, 3072]               0\n",
      "         Dropout-181              [-1, 4, 3072]               0\n",
      "          Linear-182               [-1, 4, 768]       2,360,064\n",
      "         Dropout-183               [-1, 4, 768]               0\n",
      "FeedForwardNetwork-184            [-1, 768, 2, 2]               0\n",
      "       LayerNorm-185            [-1, 2, 2, 768]           1,536\n",
      "          Linear-186               [-1, 4, 768]         590,592\n",
      "          Linear-187               [-1, 4, 768]         590,592\n",
      "          Linear-188               [-1, 4, 768]         590,592\n",
      "         Softmax-189             [-1, 24, 4, 4]               0\n",
      "          Linear-190            [-1, 2, 2, 768]         590,592\n",
      "         Dropout-191            [-1, 2, 2, 768]               0\n",
      "RelativeAttention2d-192            [-1, 768, 2, 2]               0\n",
      "       LayerNorm-193            [-1, 2, 2, 768]           1,536\n",
      "          Linear-194              [-1, 4, 3072]       2,362,368\n",
      "            GELU-195              [-1, 4, 3072]               0\n",
      "         Dropout-196              [-1, 4, 3072]               0\n",
      "          Linear-197               [-1, 4, 768]       2,360,064\n",
      "         Dropout-198               [-1, 4, 768]               0\n",
      "FeedForwardNetwork-199            [-1, 768, 2, 2]               0\n",
      "AdaptiveAvgPool2d-200            [-1, 768, 1, 1]               0\n",
      "          Linear-201                [-1, 1, 36]          27,684\n",
      "            Head-202                   [-1, 36]               0\n",
      "================================================================\n",
      "Total params: 24,029,924\n",
      "Trainable params: 24,029,924\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 26.27\n",
      "Params size (MB): 91.67\n",
      "Estimated Total Size (MB): 117.96\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model.apply(init_linear)\n",
    "model.to(device)\n",
    "\n",
    "print(\"Number of parameters: {:,}\".format(sum(p.numel() for p in model.parameters())))\n",
    "\n",
    "summary(model, input_size=(1, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyCoAtNet(\n",
       "  (0): Sequential(\n",
       "    (0): Stem(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): DownsamplingMBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (channel_projection): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "        (5): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): DownsamplingMBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(96, 384, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "        (5): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (channel_projection): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        (5): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        (5): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): DownsampleTransformerBlock(\n",
       "      (0): DownsamplingRelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (channel_projection): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): DownsampleTransformerBlock(\n",
       "      (0): DownsamplingRelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (channel_projection): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (5): Head(\n",
       "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (fc): Linear(in_features=768, out_features=36, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyCoAtNet(\n",
       "  (0): Sequential(\n",
       "    (0): Stem(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): DownsamplingMBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (channel_projection): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "        (5): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): DownsamplingMBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(96, 384, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "        (5): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (channel_projection): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        (5): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        (5): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): DownsampleTransformerBlock(\n",
       "      (0): DownsamplingRelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (channel_projection): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): DownsampleTransformerBlock(\n",
       "      (0): DownsamplingRelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (channel_projection): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (5): Head(\n",
       "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (fc): Linear(in_features=768, out_features=36, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mappings from indices to syllables and vice versa\n",
    "digits_and_syllables = list('0123456789abcdefghijklmnopqrstuvwxyz')\n",
    "idx_to_syllable = {idx: syllable for idx, syllable in enumerate(digits_and_syllables)}\n",
    "syllable_to_idx = {syllable: idx for idx, syllable in idx_to_syllable.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine test and validation datasets\n",
    "combined_dataset = ConcatDataset([val_set, test_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from syllables to dataset indices\n",
    "syllable_to_indices = {}\n",
    "for idx in range(len(combined_dataset)):\n",
    "    _, label = combined_dataset[idx]\n",
    "    # label = label.item() \n",
    "    syllable = idx_to_syllable[label]\n",
    "    if syllable not in syllable_to_indices:\n",
    "        syllable_to_indices[syllable] = []\n",
    "    syllable_to_indices[syllable].append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process sentences into syllables\n",
    "def get_syllables(sentence):\n",
    "    sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "    # sentence = sentence.replace(' ',  '').lower()\n",
    "    syllables = list(sentence)\n",
    "    return syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 1000\n"
     ]
    }
   ],
   "source": [
    "# Read sentences from the text file\n",
    "sentences_file = '../sentences/ft_sentences.txt' if GENERATE_FT_DATASET else '../sentences/sentences.txt'\n",
    "with open(sentences_file, 'r') as f:\n",
    "    sentences = f.readlines()\n",
    "\n",
    "print(\"Number of sentences:\", len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "\n",
    "def compute_accuracy_and_wrong_syllables(true_sentence, predicted_sentence):\n",
    "    char_matcher = difflib.SequenceMatcher(None, true_sentence, predicted_sentence)\n",
    "    accuracy = char_matcher.ratio()\n",
    "    true_words = true_sentence.split()\n",
    "    predicted_words = predicted_sentence.split()\n",
    "    word_matcher = difflib.SequenceMatcher(None, true_words, predicted_words)\n",
    "    wrong_syllables = sum(1 for tag, _, _, _, _ in word_matcher.get_opcodes() if tag in ('insert', 'delete', 'replace'))\n",
    "    \n",
    "    return accuracy, wrong_syllables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 8/8 [02:16<00:00, 17.04s/it]\n"
     ]
    }
   ],
   "source": [
    "# Process sentences in batches\n",
    "batch_size = 10  # Adjust based on available GPU memory\n",
    "results = []\n",
    "\n",
    "for i in tqdm(range(0, len(sentences[:]), batch_size)):\n",
    "    batch_sentences = sentences[i : i + batch_size]\n",
    "    batch_sentences = [sentence.strip() for sentence in batch_sentences]\n",
    "    \n",
    "    batch_true_sentences = [''.join(get_syllables(sentence)) for sentence in batch_sentences]\n",
    "    batch_predicted_sentences = []\n",
    "\n",
    "    for true_sentence in batch_true_sentences:\n",
    "        syllables = list(true_sentence)\n",
    "        batch_images = []\n",
    "        batch_valid_indices = []\n",
    "\n",
    "        # Collect syllables in a batch\n",
    "        for syllable in syllables:\n",
    "            if syllable in syllable_to_indices:\n",
    "                idx = random.choice(syllable_to_indices[syllable])\n",
    "                image, _ = combined_dataset[idx]\n",
    "                noise = torch.randn_like(image) * NOISE_FACTOR\n",
    "                batch_images.append(image + noise)\n",
    "                batch_valid_indices.append(len(batch_images) - 1)\n",
    "            else:\n",
    "                batch_images.append(None)\n",
    "                batch_valid_indices.append(None)\n",
    "\n",
    "        # Process valid images as a batch\n",
    "        if any(img is not None for img in batch_images):\n",
    "            valid_images = [img for img in batch_images if img is not None]\n",
    "            valid_images = torch.stack(valid_images).to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(valid_images)\n",
    "                _, predicted_indices = torch.max(output.data, 1)\n",
    "\n",
    "            predicted_syllables = [''] * len(batch_images)\n",
    "            valid_idx = 0\n",
    "            for j, idx in enumerate(batch_valid_indices):\n",
    "                if idx is not None:\n",
    "                    predicted_syllables[j] = idx_to_syllable[predicted_indices[valid_idx].item()]\n",
    "                    valid_idx += 1\n",
    "                else:\n",
    "                    predicted_syllables[j] = ' ' if random.random() < 0.90 else random.choice(digits_and_syllables)\n",
    "\n",
    "            predicted_sentence = ''.join(predicted_syllables)\n",
    "        else:\n",
    "            print(\"oh no\")\n",
    "            predicted_sentence = ' ' * len(true_sentence)\n",
    "\n",
    "        batch_predicted_sentences.append(predicted_sentence)\n",
    "\n",
    "    # Compute accuracy and wrong syllables for the batch\n",
    "    for true_sentence, predicted_sentence in zip(batch_true_sentences, batch_predicted_sentences):\n",
    "        accuracy, wrong_syllables = compute_accuracy_and_wrong_syllables(true_sentence, predicted_sentence)\n",
    "        results.append([true_sentence, predicted_sentence, accuracy, wrong_syllables])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise factor: 0.1\n",
      "Average accuracy: 0.9350\n",
      "Total wrong syllables: 2563\n"
     ]
    }
   ],
   "source": [
    "# accuracy average and wrong syllables sum\n",
    "accuracy_avg = sum(result[2] for result in results) / len(results)\n",
    "wrong_syllables_sum = sum(result[3] for result in results)\n",
    "\n",
    "print(\"Noise factor:\", NOISE_FACTOR)\n",
    "print(f\"Average accuracy: {accuracy_avg:.4f}\")\n",
    "print(f\"Total wrong syllables: {wrong_syllables_sum}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = f'results/ft_noise_{NOISE_FACTOR}.csv' if GENERATE_FT_DATASET else f'results/noise_{NOISE_FACTOR}.csv'\n",
    "\n",
    "with open(result_file, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['True Sentence', 'Predicted Sentence', 'Accuracy', 'Wrong syllables'])\n",
    "    for row in results:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatinate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE_FT_DATASET:\n",
    "    import pandas as pd\n",
    "    import glob\n",
    "\n",
    "    csv_files = glob.glob(\"results/ft_noise_*.csv\")\n",
    "    df_list = []\n",
    "\n",
    "    for file in csv_files:\n",
    "        noise_factor = float(file.split('_')[-1].replace('.csv', ''))\n",
    "        df = pd.read_csv(file)\n",
    "        df[\"Noise Factor\"] = noise_factor\n",
    "        df_list.append(df)\n",
    "\n",
    "    # Concatenate all dataframes into one\n",
    "    final_df = pd.concat(df_list, ignore_index=True)\n",
    "    # shuffle the dataframe\n",
    "    final_df = final_df.sample(frac=1).reset_index(drop=True)\n",
    "    # Save to a new CSV file\n",
    "    final_df.to_csv(\"results/ft_zoom_ds.csv\", index=False)\n",
    "\n",
    "    print(\"CSV files combined successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
