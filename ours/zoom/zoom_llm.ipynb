{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import librosa\n",
    "import os\n",
    "import random\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math\n",
    "import torchaudio\n",
    "import csv\n",
    "import string\n",
    "\n",
    "from torch.utils.data import ConcatDataset\n",
    "from torchaudio.transforms import TimeMasking, FrequencyMasking\n",
    "from torchvision.ops import SqueezeExcitation\n",
    "from torchinfo import summary\n",
    "from torchsummary import summary\n",
    "from torchvision.ops import SqueezeExcitation\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from collections import defaultdict\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from scipy.io import wavfile\n",
    "from functools import reduce\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_s = '0123456789abcdefghijklmnopqrstuvwxyz'\n",
    "labels = list(keys_s)\n",
    "keys = [k + '.wav' for k in labels]\n",
    "data_dict = {'Key':[], 'File':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolator(signal, sample_rate, size, scan, before, after, threshold, show=False):\n",
    "    strokes = []\n",
    "    # -- signal'\n",
    "    if show:\n",
    "        plt.figure(figsize=(7, 2))\n",
    "        librosa.display.waveshow(signal, sr=sample_rate)\n",
    "    fft = librosa.stft(signal, n_fft=size, hop_length=scan)\n",
    "    energy = np.abs(np.sum(fft, axis=0)).astype(float)\n",
    "    # norm = np.linalg.norm(energy)\n",
    "    # energy = energy/norm\n",
    "    # -- energy'\n",
    "    if show:\n",
    "        plt.figure(figsize=(7, 2))\n",
    "        librosa.display.waveshow(energy)\n",
    "    threshed = energy > threshold\n",
    "    # -- peaks'\n",
    "    if show:\n",
    "        plt.figure(figsize=(7, 2))\n",
    "        librosa.display.waveshow(threshed.astype(float))\n",
    "    peaks = np.where(threshed == True)[0]\n",
    "    peak_count = len(peaks)\n",
    "    prev_end = sample_rate*0.1*(-1)\n",
    "    # '-- isolating keystrokes'\n",
    "    for i in range(peak_count):\n",
    "        this_peak = peaks[i]\n",
    "        timestamp = (this_peak*scan) + size//2\n",
    "        if timestamp > prev_end + (0.1*sample_rate):\n",
    "            keystroke = signal[timestamp-before:timestamp+after]\n",
    "            strokes.append(torch.tensor(keystroke)[None, :])\n",
    "            if show:\n",
    "                plt.figure(figsize=(7, 2))\n",
    "                librosa.display.waveshow(keystroke, sr=sample_rate)\n",
    "            prev_end = timestamp+after\n",
    "    return strokes\n",
    "\n",
    "def convert_to_df(AUDIO_FILE):\n",
    "    for i, File in enumerate(keys):\n",
    "        loc = AUDIO_FILE + File\n",
    "        samples, sample_rate = librosa.load(loc, sr=None)\n",
    "        #samples = samples[round(1*sample_rate):]\n",
    "        strokes = []\n",
    "        prom = 0.06\n",
    "        step = 0.005\n",
    "        while not len(strokes) == 25:\n",
    "            strokes = isolator(samples[1*sample_rate:], sample_rate, 48, 24, 2400, 12000, prom, False)\n",
    "            if len(strokes) < 25:\n",
    "                prom -= step\n",
    "            if len(strokes) > 25:\n",
    "                prom += step\n",
    "            if prom <= 0:\n",
    "                print('-- not possible for: ',File)\n",
    "                break\n",
    "            step = step*0.99\n",
    "        label = [labels[i]]*len(strokes)\n",
    "        data_dict['Key'] += label\n",
    "        data_dict['File'] += strokes\n",
    "\n",
    "    df = pd.DataFrame(data_dict)\n",
    "    mapper = {}\n",
    "    counter = 0\n",
    "    for l in df['Key']:\n",
    "        if not l in mapper:\n",
    "            mapper[l] = counter\n",
    "            counter += 1\n",
    "    df.replace({'Key': mapper}, inplace=True)\n",
    "    return df, sample_rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Key                                               File\n",
      "0   0  [[tensor(-6.1035e-05), tensor(-6.1035e-05), te...\n",
      "1   0  [[tensor(0.), tensor(-3.0518e-05), tensor(-3.0...\n",
      "2   0  [[tensor(3.0518e-05), tensor(3.0518e-05), tens...\n",
      "3   0  [[tensor(-0.0002), tensor(-0.0002), tensor(-0....\n",
      "4   0  [[tensor(6.1035e-05), tensor(6.1035e-05), tens...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 900 entries, 0 to 899\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Key     900 non-null    object\n",
      " 1   File    900 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 14.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data_frame, sr = convert_to_df(\"../../dataset/Zoom/\")\n",
    "\n",
    "print(data_frame.head())\n",
    "print(data_frame.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample rate: 32000\n",
      "630 180 90\n"
     ]
    }
   ],
   "source": [
    "train_set, tmp_set = train_test_split(data_frame, test_size=0.3, stratify=data_frame['Key'])\n",
    "val_set, test_set = train_test_split(tmp_set, test_size=0.33, stratify=tmp_set['Key'])\n",
    "\n",
    "print(\"Sample rate:\", sr)\n",
    "print(len(train_set), len(val_set), len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, file_name, transform = None, aug = None):\n",
    "        df = file_name\n",
    "        self.transform = transform\n",
    "        self.aug = aug\n",
    "        self.labels = df['Key']\n",
    "        self.values = df['File']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, index):\n",
    "        label = self.labels.iloc[index]\n",
    "        value = self.values.iloc[index]\n",
    "        waveform = self.values.iloc[index]\n",
    "        label = self.labels.iloc[index]\n",
    "        if self.transform:\n",
    "            waveform = waveform.numpy()\n",
    "            waveform = waveform.flatten()\n",
    "            waveform = self.transform(waveform)\n",
    "        if self.aug:\n",
    "            waveform = self.aug(waveform)\n",
    "        return waveform, label\n",
    "\n",
    "class ToMelSpectrogram:\n",
    "    def __call__(self, samples):\n",
    "#         samples = np.array(samples)\n",
    "        spec = librosa.feature.melspectrogram(y = samples, sr = sr, n_mels=64, n_fft=2048, win_length=1024, hop_length=226)\n",
    "        return librosa.power_to_db(spec)\n",
    "\n",
    "class TimeShifting():\n",
    "    def __call__(self, samples):\n",
    "        samples = samples.numpy()\n",
    "        samples = samples.flatten()\n",
    "        \n",
    "        shift = int(len(samples) * 0.4)\n",
    "        random_shift =random.randint(0, shift)\n",
    "        data_roll = np.roll(samples, random_shift)\n",
    "        return data_roll\n",
    "    \n",
    "class SpecAugment():\n",
    "    def __call__(self, samples):\n",
    "        num_mask = 2\n",
    "        freq_masking_max_percentage=0.10\n",
    "        time_masking_max_percentage=0.10\n",
    "        spec = samples.copy()\n",
    "        mean_value = spec.mean()\n",
    "        for i in range(num_mask):\n",
    "            all_frames_num, all_freqs_num = spec.shape[1], spec.shape[1] \n",
    "            freq_percentage = random.uniform(0.0, freq_masking_max_percentage)\n",
    "\n",
    "            num_freqs_to_mask = int(freq_percentage * all_freqs_num)\n",
    "            f0 = np.random.uniform(low=0.0, high=all_freqs_num - num_freqs_to_mask)\n",
    "            f0 = int(f0)\n",
    "            spec[:, f0:f0 + num_freqs_to_mask] = mean_value\n",
    "\n",
    "            time_percentage = random.uniform(0.0, time_masking_max_percentage)\n",
    "\n",
    "            num_frames_to_mask = int(time_percentage * all_frames_num)\n",
    "            t0 = np.random.uniform(low=0.0, high=all_frames_num - num_frames_to_mask)\n",
    "            t0 = int(t0)\n",
    "            spec[t0:t0 + num_frames_to_mask, :] = mean_value\n",
    "        return spec\n",
    "\n",
    "aug = Compose([\n",
    "    TimeShifting(),\n",
    "    ToMelSpectrogram(),\n",
    "    SpecAugment(),\n",
    "    ToTensor()\n",
    "    ])\n",
    "\n",
    "transform = Compose([\n",
    "    ToMelSpectrogram(),\n",
    "    ToTensor()])\n",
    "        \n",
    "train_set = MyDataset(train_set, aug = aug)\n",
    "val_set = MyDataset(val_set, transform = transform)\n",
    "test_set = MyDataset(test_set, transform = transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set image (augmented vs non-augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzYAAAGOCAYAAABFSZZwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAB/p0lEQVR4nO39e5BdV3kmcD/7cm5917Ul2ZIxwcFcYgMGjGIySYwSl7+EgsGVISnyjSdDhYKxCbaZSnBVgAxfggjUBEIiTGAYQ2rCeOKZMQlJYYYxYGYY22CBK1wSxwaDheVuWZe+nfvee31/CDppvc9rzlF3S72l51elKnv17nXWvq11dp9+n45CCAEiIiIiIiIlFp/tAYiIiIiIiKyWHmxERERERKT09GAjIiIiIiKlpwcbEREREREpPT3YiIiIiIhI6enBRkRERERESk8PNiIiIiIiUnp6sBERERERkdLTg42IiIiIiJSeHmxERERERKT00vXq+MCBA3jf+96HmZkZXH755fiTP/kTvPSlL/2x31cUBQ4fPozx8XFEUbRewxMRESKEgMXFRezatQtxfG797Ot01yVAa5OIyNky1LoU1sEdd9wRqtVq+M//+T+Hb33rW+E3f/M3w9TUVJidnf2x33vo0KEAQP/0T//0T//O4r9Dhw6tx/Jw1qxmXQpBa5P+6Z/+6d/Z/jfIuhSFEALW2JVXXomXvOQl+NM//VMAJ3/StXv3brz5zW/G2972tqf93vn5eUxNTeGZN74DSa2+4mv5qB1q3OY/OYsK2xachzy2bdzn26Yd2zb1SJdvvEqP/9LgH6hFGT8Ocde2Vxb4tmOH7fGtLuZ82384btryRx97uiGuuf4rXmja5p5VpdvOX94zbS+9hI/3/7v9y6bt0soCHwNpWyoSum0j4scygz0f3+ruoNs+1Npj2uKI38IV8npz2QjdtpnZ4zbOLnbHhfUTA2/7rcVdtP3hue12DFV+b2XkZl7q1ei2Idjju7DEt63W7DHzjm+3Z8/zzo/z628YR15v99n7gGCY2Tvr22PWn6+btqLTweG3vRtzc3OYnJwc/AU2uNWsS8A/rU0vx/8HKSprOrbkJ55B24/8rL0nlnbzPrJxu5CFClncALzsed8xba/a8nW67dZk0bTNZvy6GIvbpm1Xar8fAA5n46bts/OX0W3Z/FSQeRMAXj71iGn76fr36LabE3sPLxR8nj6a2zF0A1+jj+ejpu1QfyvdthHb+70f+Brynba9Ho717WsBQIscM0+v4PtxeGHC9tvm/W4ab5m2RoW/kepk9vWaXT4nj1Tt2t3s8TG0yLwecueNX2wnz8aofS0AiMga0G3zOaDI7XXJ1iAAiMgY0mpGt43Jtl6/bAz91hBrk7OuRG17XVbm+fGNe2RsTr9FlXzhlJcquh187w//fwOtS2v+q2i9Xg8HDx7ErbfeutwWxzH27duH++67z2zf7XbR7f7Tjb24eHISTGp182AT6nbnk2KdHmycbROybZquz68lxI0hHmz6zoMNeUeUkIcdAEjIxZVW+CSfJnYCiaK1Xex/nJDaN2VJld+8ccOe0Moo33Z03N684xV+QdBpu+DbjjhvkPtkgR6p8oWtFttj7D/Y2HFUM36O+mQRrKX83DP1+uDXajXw45707TWVenMxuZmTdPAHm7iw1w4AJDW7qHjHN0ntPqfugAeXkGfPtXiwKfr2mop7/DicfM1z59ethl2XAH9tSlFBusZzXULmUwBIqvb8xM4pixuDP9iwuW+EzHsAMJrYe20kc7aNbftYyufDUdJHNR98fvIebBpj9r4cI/M/AEyQfQsFv6k65A1y6ryp6OR23+o9Pkc2YjvPps6DTS2xx6fivMmvDPFgE5wHmySz12UcOdfqKNkPZ91MyYONew/UyHsYZ55l83rIBn+wSUac95NkDYgj5/iyBxvvfWpCxrAGDzZsDLGz7lLeg82pTxsA4i4/vglbP7x+a2Tf+C0w0Lq05r9AffToUeR5junp6RXt09PTmJmZMdvv378fk5OTy/9273Z+HCUiInIahl2XAK1NIiJldNYrQ2+99VbMz88v/zt06NDZHpKIiJzntDaJiJTPmv8q2tatW5EkCWZnZ1e0z87OYscOWzdQq9VQq5Hfi0xP/vvn8iE+rko65OMq/qk8KvZXQ5E2nV8/4b+CuS68Xy9jn3475RuoNG0fXulEn/wKTOrVMPX5x6VnUlGxY+tu4ttu2mp/z3t7nf/u9yWVedO2Mx2j2/4gWzJtx4oG3fZi8rvCANCHPXnfJb93DQC12B73kYRvu5Tbj+VfMsbrisbJ78Yfz/k+f6N5Ifl+flGNkv2Yb/A6H6aW8OvsaNf+Xvmi8zvaYzU7Bu93v9t9+6sePefXbrL++oRK5uRXXrxP33tdOwb2e9sAUCG/VtonNUVwagzKbNh1CfDXpvUQ9ZyiTmaIH0dWJvic84yRY7YttW0AUCG/q/2I86ucF6S21u5ZFX6fXJw2Tdv2Lf+Xbvvl9rNM2/85cQnddneF7RufcxLy67qP9vkxeyKbMm0XpHN02z3kOPSdepyEHN9jGZ97n+zY2gKvlmYktfsxVbXzPADkzq80HWnacXTY7+MDqMS2vUXmU2/b7eN2LfV0nbm3aJL50PtVNFKX3HJ+ZYz92hrmB/91VO+9HNPbzMcbyK+XgdRNAgDIvM7qY052PGAbgHTJvl79uLNv5DJhZR8AkJNfNyxOuaxzp4SCWfNPbKrVKq644grcc889y21FUeCee+7B3r171/rlREREnpbWJRGR88O6/MjxlltuwfXXX48Xv/jFeOlLX4oPfOADaDab+I3f+I31eDkREZGnpXVJROTcty4PNq997Wvx1FNP4R3veAdmZmbwghe8AHfffbcp3BQRETkTtC6JiJz71ueXxAHceOONuPHGG9erexERkaFoXRIRObet24PNatVOAMkpxUOsCMz7Q5ojs4MHDaQd8ocp552/39Kx7UWyPn/vYeofBu/X+xs9FRKCwPYXACrkj3GmbaeQuD34H29crXjc/iE3AOhM2RPa3cKr0yYrtgj9ksYs2RJ4ivwhtk6wha4AcIj8obpvd2xxPQC0Ch4rm5O/x/D11jPott9a3GnavL+z8vzxw6bN+8NvrLC15xS7dgtbNHlw6Rl020ZsC1gPtXnCwwL5myrdnI/hqUVb1Or9TZd2z443cwIBOsftGLzi00D+BgFIEMSw8u/ZfUtJCAgAxOSPFgcnPKBPCoQTsm1E5jhZX8XsU7R97LC93wunGH/pQnudTj6DF4uzgvWZ3P4xRgCYim26zlRCEncAHMntXP3N3hzddpws3s3Ag1eO9O3Ytlb5nMz8Y5+vV/OFDYf4Tt8ecwD48oINK5iu8j/cPE0CaLzwgFmyb090pui2/3DM/oFO9jdWAOAF2+z8XyXhMwDw6OI22n7kqB1baPH9OLRI/radF2RSt+PIyN/ZAnjRvNcvfY/Y4vM3+6OQ8VPO3wRaYsXtfAzsD1PytQLIyOUeFvnxpX8Wxvk7VRHpI3GOA3tL4OQRoTpP1hDn/WRG/iZQ5IRvpWSaipZW9pv3Bv+jbWc97llERERERGS19GAjIiIiIiKlpwcbEREREREpPT3YiIiIiIhI6enBRkRERERESm/DpqJtf2AB6SnRDK2LRs12vVH+bJaQBIXqAk/7iTOSHLbI4xuSf3zctHVe/Cy67Wo1jvLEi6JCkim6PDEir9lt0zbvtz5jk26SE4u832MnaPt6iFgcCID6nD2fUZ9f0heM2ZSaBPw4/L+WTb95pG3TaADgB60p0zZZ5Qk89xy9lLbPtmwKlmes6sSKEN/ELtP2hfZP0m37uY1GKUiKFgAsdGz6jZcylpGUmtxNv7HbskSck52Q6/oEP/eVBbttd7uTJkPSduKuMwZ6Xa4+Uax6wvbbOOLc3w2S1kPmBwBISUJiUSXnp6efd51pkZP8mDXI+eHBTTTdqOPMhx2SbHgk42N4PGwxbX+3tJtu285tvyd6POmsmth7xUs6++YJm1T27CmeaslSKb9BkicB4NGW/RtGR7p8Pp7v2v34PwvPpNuy+dBLbaxWbULYSJXHvbJ5uu/Mp/8wx9csZqFt0yABILRt35UT/PXyOpm/Uyehcd5eJ6HB52Rk5Nw5cxQJ+4MTGoe0bfutkNQvAKiQy9JL5O2RcMGY7QOACnl7FZFzDADdLXZH2Pu7k2Oz7SzRDADYMl84cwzbZydoD7UTdryN43x9rM6TlLz6yuOQ9Z0XIrSCiYiIiIhI6enBRkRERERESk8PNiIiIiIiUnp6sBERERERkdLbsOEBcauL+JQaqtpRW3AWd20bAGQkVCAkvHgqWbQVUUnTKdK+YAdvXwfjjy7Q9qJh97k3ZQu6AaB2whZrxV1ewFU07OWQzPNn39AfvIh9tYo2L8ZPSAhC7NRuj1e6ti1x+iWhAo/Hm+m2z52YMW3dgt9WrLAWADJSLLhlhBfRjqT2uLcyXuk3WWmbtqpT6ff3x+x1fWJhhG7Lqg0jp0Iziu2xLHq8OJLW9zrhAdVZe4zTFt82GyNjS5yKUrYpKTIFePHpWpj6jj1mSY8X1gYnWIPJSNBA3Lf9Zv3VByDIcKJRXmDfGyX3mnN68k12HfvpCx6j275w5PumbXflGN22E+y8tdTgxeYPLdrC/XknPICJ2Q0IoJbYeavmzGWdYOeG8ZjP9c8f/YFp+4fYBhUAwBNLk6atKJxgG1L8v9Tkx6xInaJ5IpC5t9fh68rRYEMQMmfuLZq8D5avw0IqAF64nzT5+4e8TkJaFnjHFfIehL0WAGQjJCDF2bW0M/jcWT9O5sk6//6RWbJvfWe9Idg8DQBVm3+Eis17AgD0SA5IIME4AA9GyPnbSb5GO+fCO0dM1rDn/tTv90IgGH1iIyIiIiIipacHGxERERERKT092IiIiIiISOnpwUZEREREREpPDzYiIiIiIlJ6GzYVDWkCJCuTEkLFPocVNSdBYsFGx6RNnqKS18lhCDzBpHL4OGm16SNrgaWfAUBI7HGoHncSvki6WzbFU2qi3MZYhOMnnm6IZ4SXwJZ07PksKvyY/aA5Zdoequ6h215Qs/u8p8bOO/CdzjbTNtOZ4Nue2ErbmcMLvA+WijPZ4Oe+QmNqbFoPACQkvWx0xCbJAcDSor03cieZJ6qQMThJQshIaleX/+yFJaQUXpIL2bZywkn7I8E81UUnTZEf9lUbmbXHPVni90B/yp6LpM3nubhH4rRIqlqWr9OOiSscn6PtSX+Xacud1CSWIPjMxlG6aT2288BTOZ9z6pHdtlXwJMa5nk1S3DnC0z1jMj892bLJYwCw1LOvt8mJhLqoavf5eMbX6D5JUNuU8n7ZUe/3eZIXm6e3blqk2zInFnkiJUtha4zyeTpJ7PHNMyd57LgTdUamyaIyeDxVxKciJCyRzOuWbEqTLgFkDdseajyeqyD3UfUYPw4LFw3+GUBCpmq6vwCSrh1vNuLc3+yQOaetqJJ53Qk57ZFbrrLk9UsanfMWk+OQV/mAvaTHFd/bG/xxRZ/YiIiIiIhI6enBRkRERERESk8PNiIiIiIiUnp6sBERERERkdLbsOEB/U0NhHRlYWxetc9h9SO8cC6da5u2bJIXzaekMJcW2gJAfOaeBUPMi8jymi3AikiwAgAUpFjL27fkOKkYq/Ai0Y2gcpgEGwR+jmcXbfHo3yc76LbdMXtbPKN+jG47mdrr7NG+DRQAgGaHH8s+KYpjxacAkLft+Qyb+bZHxuw+153wgIK8XrPFq/GLHikAJIXLAIC23bfIuYWiHinmnHfCAwYoNlzuY8n2W/CsA+QkM6RwCjQb84MX0Q6j+j1b/JxNT9FtKwtk7lqw1+TJL9jjELXt/BkKPqfK+im6/JhXWvYaq53g113zYtvGCvQBYEcyb9oWCh6Y8z0yn1WGuAHnenxOnqjYkIqs4Pf7sflR03ZiG6+GbtXsvJU7P8Nl4S/fW9pCt509bsMVYlKgDwC1iq2ab3X5/L+0ZI97OO6su2Se7jf4uUjH7Fxf9J351HknmDdIoJATHhDV7Tj40QGwRNaFPl9D+pvI/jlTL+sjaTrvjch+5HXecSBdpC0+XrZtb4puSkMFMn67gOR9IKs7x2zS7keROueNhPZ4ASUsDMIL0akskiAHZy2ttMm5OCUAIQyx5usTGxERERERKT092IiIiIiISOnpwUZEREREREpPDzYiIiIiIlJ6erAREREREZHS27CpaHE3Q5yvjGBIEpvU4CWHZZtsYkrhJIclHZvIEJ9YpNuGUSeyYh3EXRJB4bTHS06SUU6iJBInmoKIRnhSzkYQyNhikvABAGls81mqMT++3cLeFo+2t9NtZ9rjpu07T22l2/a6/HYrOvZ8VJ7isV0JOZ3NjF/X34ZNfZsa4YlZS22SJLTExxA37XhZugsAZKP2uHvpN0nXtsc29AsAUGmS1+IhSTTprMJvb9SP27kgbfFtq00382d1yP0Zd5w0uxGSnpQ4yUcsAS0lKXv54PODrI1k0xRt74/Ye6KzxUkgJKf9+20+Fz279qRpm0r4hT4R2znj8Zwnh333mG2vVfi1ezjYlDEvFW20YSeC7y7xfWvn9p5gqY8AMN+3k8Pj81N026xD5u+IJ03lmb2H8kUnijEh7z8284mv6A6eSJmTBLT4KB9D/agzf4/Y1+tucua9hl1PkwrfNmy2C1konOua7HO8yNfS2jG7z7XjTrdTti0bc85ng5wj77iTZDWWwAbwlLCYpIMCwyWBZmS8bH0FgIRcat5rsbdMI7N83+h67KTZtbbZ83bqrZU742f0iY2IiIiIiJSeHmxERERERKT09GAjIiIiIiKlpwcbEREREREpvQ0bHpB8/wiSeGURYLLJFhv2t9vibQBAQYqAF3mBfdy2xY1hYYn3ewaL6ePFDv8CKfiNmrwoPHRtZVjkBCCEGilEztepQHoNRC17fCJep4o+KYg+vDRJt/3OcVuUunB8lG6b1GyVXeEEGASnyD85YQs6Y2c/6Pc3eb/tpj2fwSne6/XsVJAe59ND2rL7V3WK8btT9rin/FIFyWxAf5wPuKjaMXj9svbCqeONyX7EmTOGdPBixmH0dm+yY2jzoItk3u5ccMJBsp1TZFt77WRZB/jujxmkrKmQOeeXFPY6mSe0MPfv56fpps9sPGXaRmK+Pn514WLT9kSLz50xCWk5cXyMbhvFdsATE/wmThPbrxc0MIwjLfv+od0l6yCA+rg9Pp0lvm1jxG4bj/L1fGnJvqdgx+ZkJ6S9x49DaA7+9i5yrqnaMTIE5/WyBRtAEzmBANmYPZ/BGW51kcz1Td4vm9dzO6yTYyOHMptwwg4aZJ2vDR6yEmrO+ygSruAFXbCQiKjNz0XsBPTQsZHdyKr8+kuXbL+Zk6cVyNCyxuDnzYQHDLHc6hMbEREREREpPT3YiIiIiIhI6enBRkRERERESk8PNiIiIiIiUnp6sBERERERkdLbsKloYWkRIVqZOBL2bDfbJV2bVnFyY5vqwNLPACDq2OiZYs8O3m/upJWsg2ixSdtDxyauZCdODNxvsvlZtL0YsfEhiZcOtwGERTu22Ekkq6Y29uVZU0fptp3c3hbf6vNbJSdJZ4UX79LlP0eg6SyjznVGUmYqi7zffrDns7XFSWarktShzTwqJyLTRuaksCQkCMgLfelP2H0OTjpQ0iPpLE5gIU1Lc8bQ2WK/EJPXAoDavB1b7TjvdxiVI+Sey5x5LiLjXWzxbcmpL+okkc9J6JL1kx8l8VMAxh6/wLRVmjzmqbXTxhtta/D5O47s/d4qeL8FuVlafZ4GVknsdRqT5CdPL+NJU0tNe3OP1XiK2wS54fss+glAJ7NzWe7EL2UkOdJLL2PrTUaSOQGgWCKRUF4qGhF5cVGk3U3L8prZqXOGlnRsJ7V5vm1x3E5GuZOuxRKzvGRAmibq7FtBLuHIOT6BpHB6/dL4Lud9CeLBo76izuCfQ7DUuNoJ57omx50lmgFAlZxPeo2AJzp6a797LP/5Js4SyOgTGxERERERKT092IiIiIiISOnpwUZEREREREpPDzYiIiIiIlJ6Q4cHfOlLX8L73vc+HDx4EE8++STuuusuvPrVr17+eggB73znO/HRj34Uc3NzuOqqq3DbbbfhkksuGep14p3TiOOVxYy9MVvtlVf4s1natNVl3lNcqNnqtHyMF1KGIYq9VitMjfMvZCOmKVriQQPJhTvtt0/yKr2ob6vA8uODhxKccdu3mKbKIt+02bbnkxXQAsCmqi0+HWvwQtWjhydtY8qrKyOncq6okKJ5pw+QIRekSA8Aim32C5Uqr8Drt0iFpldEO0aCBhpOgT0pEg0J3zcWFODU/CKv2m2TrjPeUdtW57kR9Ph6ku76BIn0t4+ZtnSOpDAACLE9vknPCUnJ7M4li7bfkPNrfSM7U+vSmZZ+/4hpKyp2TgeAuGuX81bGi/y/sXihaWvnZA4AcKxjb6D5Nk/qaHdsHwUJWAGA0LE3d2uejzeZtHNZzFJXADzWtOvCZJXfP5N1235inkwY4EEBwZkjTxy393DihSik5L6c42/N6HzoTUNkaN582pvknaQV20njKN82q5NAF/tWBQBQkHHEXnE4ebnCeefKi9ud9ZgU9Kctfq32JtjB5GOgIS0VfuBDxA7E4MFBiTNVsyCHyAlcGJmxr5eNeGFAdtvRWX7iuhP2QHhBAxHZt/yUqaBYz/CAZrOJyy+/HAcOHKBff+9734sPfvCD+PCHP4wHHngAo6OjuOaaa9Dp8IlFRERkNbQuiYgIcBqf2Fx77bW49tpr6ddCCPjABz6A3/3d38WrXvUqAMCf//mfY3p6Gp/61Kfwq7/6q6sbrYiIyCm0LomICLDGNTaPPfYYZmZmsG/fvuW2yclJXHnllbjvvvvo93S7XSwsLKz4JyIishZOZ10CtDaJiJTRmj7YzMzMAACmp6dXtE9PTy9/7VT79+/H5OTk8r/du3ev5ZBEROQ8djrrEqC1SUSkjM56Ktqtt96K+fn55X+HDh0620MSEZHznNYmEZHyGbrG5uns2LEDADA7O4udO/8puWV2dhYveMEL6PfUajXUajaxKjTbCKfEZFRm7HCLC0kqFYD+pE1XiUkqEAAkR+ZMW5rzbaO+jZZo/8RWuu2qkcQjAABJKkl2bKebhro9DiwJCQCilm3Pek7k1kbw1HHTFPe30U0DSSQ73uXpNwXZtpc5cTIkWSVe4tsWDX5NhSkSV9J1Xo8kvPQneYLJruk52zZGYmMAzHdtUt4jTzjXFEkziltO6gtLQHPS4epPkSQXJwmlIOFJrA0AEnK5VxadFCCS+sLSfgCgT5JjeN7gcPKaPZbRCN+5gmwbnKTIZN6m/WH2KdsWNvA9fxpOZ10C/LXpTAodG3uULvD5O+3Yq2+hy9PLdjbsPLA54Wl6C33bR7PJ+6037LWTO3MnSxRLnFSqvG77WOjwMUw3nGhMopvZ9xRsrQCAas3O0902T5ILJAkuI8lPABA17Rhisq4AQM6S2UiqJgBUFuwY0uZwqa4svay13dkPtrw5L8e2rR3n+1FdImuek8LJXq/gpwhJz/Yb951zP2fbvOQwljznpYHRlNMa7zcm03KFHBsAqJ+wC2dB3jc+7diISpOt53zblKSGeqnC1SU7iN74ym1zcr48a/qJzcUXX4wdO3bgnnvuWW5bWFjAAw88gL17967lS4mIiPxYWpdERM4fQ39is7S0hEcffXT5/x977DE89NBD2Lx5M/bs2YObbroJv//7v49LLrkEF198Md7+9rdj165dK/6mgIiIyFrRuiQiIsBpPNg8+OCD+Pmf//nl/7/lllsAANdffz0+/vGP47d/+7fRbDbxhje8AXNzc3j5y1+Ou+++G/U6/9hYRERkNbQuiYgIcBoPNj/3cz+HEPzfdYuiCO9617vwrne9a1UDExERGYTWJRERAdY4PGAt5UeeQhStrPpKclsQVa3xXQg1WzEWtXlxZJgnf58gcQoeY6eoez1kvHI6mrfFkaHrFPyS4tOwyIsr83Pgr3AHL2+hYo+lV1h7dNGGChRe4eeYLSiNF3jBcag6xYZ9O+i4zXeEFYR299hzDABbG03TtqPO/xZHNbbHZ2ZinG670LPHJ13i+1ZZtO3uOVqybQkpQASAnBT0516dN+kiG+GbsgLLtM3HMPKUk2ywSknb9ps0+TlOWiS8YqFFtw0tEh4QsZNx1sMy5WlEHb6OJeT0Hl3iASkjlU2mre6EBxxt2T7yFl93O5G9V5KEVycXNdLuhAewMJXcmZOXMjsRPNmaoNvOnLBzXHGUTySdCqlCZ/sA0FCZyAugSe0xG2Yu8xTkFGUjvAOvwJ6cTjfQhc1F44ec+Zu8Hiu6B4DOFDnPTnYAK05nxwHgYTO5E0CDiAQKbeLnPichQXGHX9c0rMDZt9px+4WJx517KyWdONcOC8dxgxHIbkTOfdidJAEaTr9sp08NNQjJ4MEXWsFERERERKT09GAjIiIiIiKlpwcbEREREREpPT3YiIiIiIhI6enBRkRERERESm/DpqIxYcc201bUeZxH0rQpYdEcTwNjYRFRo8G3XSLRTetljidY5XPzpi0iqR0AEO/YbtrCrq1026RnE75w5Bgfw7HjtP1Mimo2OoYlnQBAltln+CTmiSJbx22a2GKHx9T02k6cDBF3vFQ0GwfD0sQAIGHBdSQxCACeWJw0bYt9vh+LXdu+cIJHh8ULdtpInH3LSChTiL1oH5agxvutLto+xp5wEopIF61t/Gc6LEEn7fDxxtkQEUVDqBwhqYeHDvMxTJK0p7oXqWSFzN7zIZB5QDaOxElMtNMW5o7wVLRHOnbeqjd4sma3y24KJ43pKZs0mY/wGK1kxF5nxTYvZczuc7PNr/MnY3tPLLb4ttlTfJ1nKvN2ns1GnTm9SuYGZ9fY/BQqfG6JSNpa9Tif/yvk7U7u/NmmlAcpIiZBebEzPbBtKy2+01VySeROaihL7eqPO9uy0+mEacUkaLK6wI978wLblo84JzQZfF04NfkL8NPhAtmPnKR4AvxYeolvbAyRs7axVLSszucjtkYnPNyTj+3UbnuDH1d9YiMiIiIiIqWnBxsRERERESk9PdiIiIiIiEjp6cFGRERERERKb8OGB0RpiihaObxQs1VVRY3vQtwilWyLvPC/6NqKpjjaAM98ZFwAkGzdYtrCBC8SDRmp0gtOYVhij2+UbthLBChs1Rsr/gaA7jFbVThXI9cIgJGaLaJtd52QgCXbXrDCUQCRU/uWtG2hX9znRYH9cdtJ9RivNlw8Yq+TOa+unIzNO/O1E3Zs3r5FpCjVCwSozdlOvPOZk/3wik/Tjr1Oxg7zgua8ZvuoH+fXSdyxfWSjq79fQsX2EV2wg2+8xA6wczLYfNIn+xb4/sqZx8Id4hZLEOHFxZU5PjfkY3bjLgkUAICcFO7HTnhAvM2OLSNzJADki6Td6ZeFB4AveVho2gr5fse5L8dJJXyTbxsVZN4jxfwA6MmI+JSDomH3Ocq9fsn3O0EDbC5jARMAkLacOYM0e8XtrAi9O+4EXZDXq83zA5SSYJqo4IOIyOmMnePOtvX2rTpP1uje4HM9K7r3eNcJW2PbW3jHtQV7MlKncJ+tx7Wj/D5Mm7a9s4UftKzBrj/eb6Vt24pk5fdnfYUHiIiIiIjIeUQPNiIiIiIiUnp6sBERERERkdLTg42IiIiIiJSeHmxERERERKT0NmzkVTw2gjiqrmiLji7Q7ZiQkFSRHdvotsmijQrJZmb5tlNTtH09RFOT/Avx4M+jEUvQeeoY3Tafmx+43w2BpLh5ohEbgRI5UV6LHRu5FVjkEIDQsBEmsZPAU1nk5y0iIVS9KSdZjYXceZcDOTxeYltIbHvc5R2zsVUW+PGJSHP9KB9Ddcm2t7bzMRRV0uiEprSmScqYE75UP0YSijLeceXJE6YtexafY4YR9e21Gmpsh4GIpR6ygw4ANXtds9TDqKgAPHhLzrB485Rpy7bzdSFt2+s028WjkLZvXjRt/Zzfa8ePjj/NCFcKLJGPpIkB8BPQaMe2qbfI74naBEk5Tfk9XJBkLG8eocNy+qWpls5xiHr2uFcWnfWGzOlekld/0o4tpLzfjg3QBMD3IyVBjABQXSCJnU3n+JA5tag4SaCj9vh4+zx6xF5TsZOmxfoonONTadp2ljoH8DU6429T0Zu0fXjrOXsLko3xbWOSqpc4c3qVJJU1Zvi8kdftQYv7/GRUl+yBCM7alLbZuruyLcsGT+vUJzYiIiIiIlJ6erAREREREZHS04ONiIiIiIiUnh5sRERERESk9DZseAC2bgGSlcWuISHPYUeO02+PClu4FI04FVykMDe9+CK6aWg6lXPrIXeKKzuksMsZV2jbirGCtJUSuR5ip74srdrroZfxy7/TqZi28VF+zDaN2+O+OGmLtAGg/QSv9Ks/ZYvv0jbdlBY89qZItSJ4YELo8kK/ZMG2syJIAEi6pODRKeZMyWFzMhto0SQrMgWAvG7HkI06RcqsntmZ+fqkDxpEAqB/wWbeyWrF9vViFgICACxoYGmJb0vCNqKKvdajYoiibllXxeSoaetP8KJ5Vsy8ZTO/Fn5qy5P2tZyAlIewy7SdOM7nstCyN1bc4j8/DVtJ5b43N7DCexJ4AgCjDbs+Vsk8DQCL7bppazpF/v3c3isu0kftuBMIQArWIxZqAKC71d6b+Zgz/2fkuHuV6c7UGfdsGwsJAIDqom0feZIXofcn7HXS3M4nZTpkZ7wFWYcqS3w+y6sklMA5xUnP7lte5YOoktebfJTP30sXNUxblDuBC+Q090f4GJLu4AkYLEgnzvgxS+btIIqKE/BD5qP6UXJBAYj7JISptXLbJOfXEu1v4C1FREREREQ2KD3YiIiIiIhI6enBRkRERERESk8PNiIiIiIiUnp6sBERERERkdLbuKloRNSxiQrZU0/RbZNNm0xbqDmRFzFJx6jybSOWzLZOQo8nSERVm4rjhIQgP2ZT45KtW/jGEUmaenLGHd/Zlm+eMG3FEME14w2eVFJJbEJHt89vlUrqRIcRocqTSrpbbAJJ0uFntHbUtvemeYJJfcReP/3USZ6Zt3EyI7N8DCx5Lm3yfStIgJMXzMMu4sZRvm+VJdKJcxOwRBsvfYkltmWjTuQbiYKLe6tPFGPzHLs3ASB07bahx6MB4232fgl1m+AX8i4w+2MGKWdEvGTnqHqXR2bFz9xm2qop33aCxC6mMb92N4/YbRcWecJoDvt6Rerc8CRBzY1MJCljcYOPt9Ozi0BwEt/G6jZpqdfj93u2ZMcb5c59WbH7kfEgOSQtkormHIbKoj2W3hhADg9LtASA2hzvIiZBVM6hpNrbeYJfQZLgvGRNloDJ9g0AemPk+DjHsjNlt6Wv5fDSy1KydgfnHmCJZIGkYgJA3LYbe7cWSzRNW/y9ClvfmhfYtDYAqM3Z+9tPObX7kdf4gJOWXceix1cmN0aBvx9m9ImNiIiIiIiUnh5sRERERESk9PRgIyIiIiIipacHGxERERERKb2NGx5wfA6IVxaehb4tXIrHx/n3kyJ/WpQLADkpqppwKv1Sp8JtPbBxOWPwwg6SHdO2seIUkDdsIXGS8THkTmjDmVSM2H1OnFPcWrBFjCPbeJH1JVN23453R+m23zu+2b7WHC+8i/q8KLCo2aLAUHGKGFnlPSmsBYD2Qp33wYzaMfRH+M89YlKPHPEaZVRato0W84MXUiZ9vm2ckY2dQ5a27LaVRX7uWzvsPdAb4/d8bX7w4IhhFJP2Wou+/yTZEnyecwIiill7XbMgEgxRpCnri83JrT02BAIAslF7Axxf5PPWI43tpi12EjUWu3YM9Qa/RpYW7LrpFtjXyf3T94qLbXtB9hfgORv9nN/DvczeK/0Fu78AEGe2Yy/kJWmTQACn4D2v2+Pu5QGw6Z+FuQBA9YTtJOV5OUja/NyPzZAwCGdt4oEAfNvGUTvo6gI/94H1O0QATXCCV9jlHjvrDQtMqC3wbVmBfd7g119lyd4DXpF/ZwsJxXCCBpKOvdjyunPQyG5457izefBHhqxBwhkq/H0qC1dIJn5iZX9ZB/jSYK+tT2xERERERKT09GAjIiIiIiKlpwcbEREREREpPT3YiIiIiIhI6enBRkRERERESm/DpqJFYyOI4lPSSRKSLLHY5B0UNlkidHmSS370qGmLT8w54yIpMxfwlJrVimo8nQWdrt028IQOsLQ0J20tOrFg2rINkH7myUbt5eslz1Qm7TEbr9g2AChI5MpSj5+LLLPbjky16bbthKeURU2yH73B03acIBcarRM3eToLTTVzwmT6Y/YFWSIOAOR0l/m2Mbk9Jx7nJzTtkLSeqpPi1rd9dDeRNDAAWYMlCfEDXFmwA85G1mBKJfdyNOmkP+bk+DjzRv7EYdvYsTFJeXBiluSMKxp2/o5z53pcsu0Lx3hC46PRVtO2eYxEGAJIY5LayGKiACC120YdJ4WTJPrFbX4Ps2S1WoNfp5tH7X70nFS0uSVyfEj6GcCTuLxUtJCSe9iZ0yOSahk5gYvZqO3Xnf7Zro3wbasLfGz9RXvccj510nmydpyfo96kvSa8pDOW/OVtG5F7o72Vb9wfJ2spDxGkSaBeAmt/3B6zxFlDkp69X7JRfq2yhLnCWW7YOuYl1A2jNzb4ZyHsmPUm+Bh6E3ZH0tbK45CTY+W+9sBbioiIiIiIbFB6sBERERERkdLTg42IiIiIiJSeHmxERERERKT0hqp03b9/P/7n//yf+Id/+Ac0Gg389E//NP7wD/8Qz372s5e36XQ6eOtb34o77rgD3W4X11xzDT70oQ9henp6uJEVAaYsrmuLsnOnuD3Zts20RSkvymLFugUpqgWAOD77z4L58ROmLWLBCgCiEVtBGFVIoACA0CeFfpFTcOaFFZxBMSkmi52650rFVmM2M14FOdsaM21zS7zqste2xzKQQAEASOac240Uj8ZO8Sjdv4Sfi3TEVu9lzmlLj5MAA2cMXsEsE8hlmTb5IFjwQ3+UH8vupG1Pu85xaNsd8cI2WAEsK14FgKXd9t6qH1t94X0+Zov/47klvjErrO2xJAggHiWVsWQ+i0MPWHz6MW40Z3RtWgfJBA+gySr2Bkqb/PxmdTufsdAUAJieHPwEN3u2XxaaAsANHBlU8Oayeft6STJ4MXG3z+fegsy9qPJ+oy65V9wCctsW4sHXzMgJZ0hbtj2v8X6zhm1n3w/46+bihYO/30nb9vWyuvNeg72vcK6dpGf77ZPieAAIJMQmG+HbZiRcoag4axM5H61p3m930+CBC2yfUycPix3fyLmkYhJUUThjYAEE1QXeMQsEcO950p7w6YiGCmT1lW05uf88Q71Lv/fee3HDDTfg/vvvx+c+9zn0+3384i/+IprNfzoTN998Mz796U/jzjvvxL333ovDhw/jNa95zTAvIyIiMjCtTSIiAgz5ic3dd9+94v8//vGPY/v27Th48CD+xb/4F5ifn8fHPvYxfPKTn8TVV18NALj99tvxnOc8B/fffz9e9rKXrd3IRUREoLVJREROWtXvVc3PzwMANm/eDAA4ePAg+v0+9u3bt7zNpZdeij179uC+++6jfXS7XSwsLKz4JyIicrq0NomInJ9O+8GmKArcdNNNuOqqq/D85z8fADAzM4NqtYqpqakV205PT2NmZob2s3//fkxOTi7/27179+kOSUREznNam0REzl+n/WBzww034Jvf/CbuuOOOVQ3g1ltvxfz8/PK/Q4cOrao/ERE5f2ltEhE5fw1VY/MjN954I/7mb/4GX/rSl3DhhRcut+/YsQO9Xg9zc3MrfjI2OzuLHTt20L5qtRpqNZsCVMwvoIhWxjjEYzbVJx4n8SMAsHXKNBU1ntCRslS0uXm6bdFq8ddbB2GUxHYASGo7bWPuRFixfuv2eJ/8AkndmOfpOaHvxMGcQem8jdioLPF9m1uom7bFBo/oKEgCSr/vJOqxcJc23zbuOvEh5McLXvIYSw6LOvz18grbmA+BjcFLymFJZwW/tWgfqQ03BMDTb4LzoxeWGtdzEtSKlKRFNXnyUUKS1bw0o9iLmFuluGUPWqjwqTpqk2u4y6/rqGqPQ1SzbXGRli4V7UfOxNq0HnLn19zivr3Qs3En3ojc27U6v4mr5Aaa79o5EgCeenLSNubO/ETmoqLmpJeR9LFQ8Hu4P2rvtUo8eCpa5MRH1cnx6ZOkSwCI+2RdGOf95iPkPYWTtkbn3jY/DrVjJB3OW1fYuJwEtdYuvj1bhypD/EZmf9RJYSNvHzIv6SwhyY/OO1c3fYxgCV0sIQwAWEgdTQgDEJH2wN/K0fWNJeoBPN2t4oVlknRBd7zksmSpoyf7IP067xNY0lnuHIeEhBCbcQ2RuDjUJzYhBNx4442466678PnPfx4XX3zxiq9fccUVqFQquOeee5bbHn74YTz++OPYu3fvMC8lIiIyEK1NIiICDPmJzQ033IBPfvKT+Ku/+iuMj48v/27y5OQkGo0GJicn8frXvx633HILNm/ejImJCbz5zW/G3r17lTojIiLrQmuTiIgAQz7Y3HbbbQCAn/u5n1vRfvvtt+Pf/Jt/AwB4//vfjziOcd111634I2giIiLrQWuTiIgAQz7YhAH+2ny9XseBAwdw4MCB0x6UiIjIoLQ2iYgIcJrhAWdClMSIolNKgEjRe9TjRezRCVLhNjHGX2zEVjTFqXNo5s/c3zKIWqSiCqBBAYUzLhZ2kExM8H4btnh0I4QEeCJyHOI+f4OTHLMFoUerTpUe4b1vCqyINuUbZ2NOwbpTKMr0x2zf6ZJT6Hfc3i/VOV6Bl7DTPHhtLrIR3s6KOXOnHjsll3ufFEwCQELOc6XtnPue3ZG0ycM2QsqKZfk9kBxvmrbOnim67TCSoyS4JHXCK2J77oslOy4AiEfsSQpkTgx5F5h9+jHKmRFl9trNa05YCLmvOm1eTf1UYoN4epkTUEHms1AMXsmbLvLx0uwNJ2gg9Ox13uvx8eZ1UrTshBIsHrHXf3qc91udt/06mQRgy1DuBNCwIBRWgA7wsAI3YMUp6ma8AIKUZSU5rxciVmHPD1BBLsuocA4m6bd21OmX5D54xweki7TlrDckVMYLwcloBsfg/XrXFAsw8MZAw3ycW5YV7te6/D5k4QoZud8AHlYQ8aWJf/8pN1Fw3tvR7x38ZURERERERDYmPdiIiIiIiEjp6cFGRERERERKTw82IiIiIiJSenqwERERERGR0tuwqWihnyGcmorWshEQoc2TwyKSABR1ebpRWFiy25IENgCIt26m7eshNFkkCRBN2VSzqOCJb8moTb8pTpzgr7dw5hLf1gJLDKou8TSPfMq2T43xSJFu394W7aNO7BdJfUnnefpN/RhPD8lsKB+KipPw1SGpXcf50FgaTHDCtdgYWKrJyU5sU3WRj7c2b9t74/w4sAS0tMP7rbTt+SySwZOa8vrgP9OJO/xAFN/9vm1cg1S0bOcm0xb1nUS9eRszEzmJjiwSefAjJmcFmeMKktwH8MSsKObXTUZSwlqLfM2L5mzEEkvyAnhykycmSWde2lrUt+29Fk98a9ftOt91EtSqT9n2mLwW4CRNeYlkJGXMSzqLydsSmlIJPqdHzrmgqVRO0mV1wUnyJAlfmZNUOYy8avvwEk1ZEldnq5PERZLgKs7aVGnZg1FxUtFSkl7mJXYWFXuSvHWMpc7R6wz+eWYqLft6Wc05byxtrePMGzWyb+wNAYD6CdtHcNZoNrbawsodzvqDHwB9YiMiIiIiIqWnBxsRERERESk9PdiIiIiIiEjp6cFGRERERERKb8OGBxTNForolEqwpi2UTS+8gH5/qJEKrBPzdNt83hbNJ8kU3dYrzF0XOS+WChUyhs2TvI/CFnYlVV6dls8esa+VeRXkZ1/UtMX/tWO8yD8iBX3j9S7ddqRGik/b/JgVPVuNn4/wwrten/8cISGFpqlTxMjq9LqbePFebxMZB98UteN2P2rH+LY5CRroOoWJrKC/0nQKKUmBZnXeuQdIv4EUpAIAqZl3QxSStn29qOkElDz7J3gnq5Qeesq0hQ6/VjFiT0b0ExcN/mI9Um3LDpisr5hfkPmkrd7ORvg8wgrLCxISAPC5r17hc/2xxAbTFHO8cJ/NL1mDz4cRCQpIFvl4WdF7njmFyGSfKxU+jyxtse3pHD8Xadu+XpHweyWQHIZ0yQlGYMfMZv6c3JbcrjX7tuiHg2Ad8E1ZgT4ANI6TonmeuYPeBJmTnRdkYTMJmf8BIJCAHq8IPSfLNLsvACBr2C+wsASAB9544Tppmy04fFt2eLwAjvqCvQnqx3nKRE7e7yB2rr+MnONxZ4EkXbhBF+QcJT0+F9SP2fvQfD8JUvHoExsRERERESk9PdiIiIiIiEjp6cFGRERERERKTw82IiIiIiJSenqwERERERGR0tuwqWhMVLNRI8WJOb5t1aa2RKM8MStt2GSh0OFJSGFxkbRO021XjaWfAcAJm+KGSZtcM2y/8ZbNpo0lpW0UodkybU0nJQ+Rje5Y6vJkn35uE0GCE1USNe22SdtJPyOpOgBPV0mcECyW5tXZ5qTJjJAkoN7gP8soeBAcEnJreMkzMUlcyZ3kmUBSW6o8yJCKcn4cko5NU6me4FEuSdMe+NBwEqDi9fm5UPbkjGmLKnwMUdeO1x0VGy855lFBopdkfRU8tStp2uu0Os/n7/HH7A17bBffls1xWc6vnJikUmUNPt6IpITFCU8zCvP2mg4Vfg9nE+T1nDl56YkJu6mTXpYs2X0uqnzb7tjgKZNxx/brJTEWpD12bkGWoNYb59vScTn9ZnV+LPujJLGTpX6Bj63vvC1hCWpJn4+hsmA7Zq/lyZ0ENZbCVqROuiebfodIOvNS52iymndNkfuzN84XU5YOV11afdpl4yl7AWUj/MJmqXORkySX11lC3cq2rO/cQIQ+sRERERERkdLTg42IiIiIiJSeHmxERERERKT09GAjIiIiIiKlt2HDA9Id00jjlRVbYYJUos2RQnoAxZytOk7qNnzg5BdIUVKPV9mFnBdNroeIhBqcHAQpAst5gSY6pBg6cwo/08GLszaCcMF209addIr8SQFsL+OXf3OeFOR1nWOTkmJZr/DTOUWsqJQWKwKISahA2uT7nEVk//imyOp2P5IO35gVj4aIb1tdtNv2R5xzRItPnZ+9kNdLes4BZsWcdX4+e5tsJW7s9Fs/zIJEVi++7FLbttim24aWbWdzHwDEmzeRRnZ89fOujSL6waxpG5nnFdl53YbYzNWcUILYXtPtHk8LyRacyYiIFsm149Qss/u9cMIDIlKMH+V8HglkrscQS5s3n4YuCdpwiqFTEhRDC8Wfpg8mJ29hvJAXNu+lPBPJXbNYPkNR5ceHhRh46xhTONN3RtaLtOWEQZBMmIgE2ABASsIDYuftXUH69cIgWJCOd61mJM/Ku04y9nbQubcCCUHgcTnOMSucEA8SFOBtm7btCc1G+NrCj1n4sdt4tIKJiIiIiEjp6cFGRERERERKTw82IiIiIiJSenqwERERERGR0tODjYiIiIiIlN6GTUVDHNnEHpbaNT7Kv52kmgWSEAYAYElnVR41EsGLIFl7xdFjvL1jo02SLZvptlGFjDfjsRuhOHOJb2shm7LpZUXFif0iwR0sXO7kF0gfiRftQ8Y1wrfNG04fBUl94SFYqGZ22/4E77e6s8k7IbrHbeRKVPDYl7zOonJ4v0XN/uwk9uJZSEpN7iTwFCT1JdCEL6DWttd73OXXepyQNKOcH9/+ZhJpswZCjdyzS06cUdfOaTT9DECo24iiqE/mAvfGkDMtJ2tA3HauhcimohVkvgCAbt8u/b2e83aAzX0s0gxAiElaIUk0cznjjYZYmujc4CRj0dci8zEAJC3S5rylYEuI/4K2qbrgpMOdGLxbliLlpn45b2sScqlFzvzA0uTCEO8wvXPcH2VzvbfOk6QzLzB2sz1ANHkM/Dy7Kac04Ytvy9Lo3GuKrE3OEo0KSY1LnOS7tGN3pLrIdy7u2/Z0kS/o2Zhdb7z3ZzlpT3qnpKL1B7+H9YmNiIiIiIiUnh5sRERERESk9PRgIyIiIiIipacHGxERERERKb0NHB4Q2/CAzFZgRR1euESLyyJeuBTatlLbrf1r2IL19RJypzqN7EfU4FVvoVGzjX1eRZYfOz7w2DaCiBWykaI5AAikmtO5HBBX7XVWLPDqynTBVu9V550CWC9/gJxmr8CetXtFjHFMCilJGwB0Sbs33iopYD210G+5nRRCZix8ALzoMiWBAgCQzNudrjR5KEZCwgO84tOYFBmzgkkAiFv2PsrrTjXnEKIuuT9JGIqr4OONWKDKqJ03Qj5M5bOcaUWLVLGDX9PRCVvACwALFXuNFJnzc05W0O+tpam9f4ITvBL3h7jOyKZsvgCAokGuf++leqQw3QuKIeMtnHdQLEAmcu4rVljOAhAAoHbC9usVZMek2DruOIX/Xh4FOZTecadF817BN8ujGKIYnwbYAMjJ2x2vX8Yr3GfH3eu3N2nHxsbliQp+zOrH2UHjfdDgCOdcDHOO2XXZn+I7x7b1wg5YQER728qbK/fCTQh9YiMiIiIiIqWnBxsRERERESk9PdiIiIiIiEjp6cFGRERERERKTw82IiIiIiJSehs2FS37wWEg4klU/1yU8l2IR0YGf7HERjVEIzxlzI3SWgeh70RjEdkPnqDtydSkacsXlk57TBtJeqxp2uI+P+/DJD0lKUlFq/DrLFRs0kg2yvuNSQIPAKQ2lA/BSQ/Jxsi2zo8n8tx+IQQnpaYgiUokrefkF0ib021MwrwqTuoLS22pLvBBxD2S6uQkCUUVcn87iYOVORIP5B2z3GlfpajNou+c65fMf6HDI45ociJJmkTunXg509ILdpm2MEkmAQA5Scfy5pyCzYdkDgCAiLU7l366ZOecpD14CmI2xu9LmvLk7Js3Nob14fXL5sPqgtfz4MlYMQlzZG1Ot24SKJPXnGPmpE+yacdLqmTHnaVdAUBB3tolTjJbpUnS3Zzjw1LqvLU0Jf1W2k4KJ0n9dJM1SXqZt0az/fDS1hKy5nlJZ1md3IdOcml1gaR7VviA84Y9mGnLWS8SljjozAVr/LZan9iIiIiIiEjp6cFGRERERERKTw82IiIiIiJSenqwERERERGR0hsqPOC2227Dbbfdhu9973sAgOc973l4xzvegWuvvRYA0Ol08Na3vhV33HEHut0urrnmGnzoQx/C9PT0mg/8R0LGq8jyBbeqzyIVchEJFABAgwbWSzzKq9CLpi2aR+yMq1I1TemuHbzfE3ODvdYGUXzvkGlLXriVbpsctceh2R38XEZd52cApLB2mJAAAKjOD15sWJAC4dpxvnFn3O5zXHGK8VuDF/0mHTve2oJTfEoKIWOn2LU2Z+9lFhIAAEV18J/J0ILFmH9/dzsJn3DCDipLJBlhDUQdEh7gFKpG9bppC21+obH7O1pi1baDh5ZsFBtxbVoTJLSkaPBQnUqTFRfzOS5jc59TwVtZJCEkdEsucgq9EzIVpW1+X7J5pLPFGcW4V3lPtOwcScNRAARyq7AieABIybJZGSazxzvApD0l8zEAVFr2oCUdJzSFFJADQEjt+fDm3pwUrAfvfQmZoth4T/ZB3p85Bfb9Ebtt0uXb0mJ659yzYBp2v3m8AAO2lvbG+fHNarY9Tvi5Z+8f2HuHk69nL2IWVAD46zGTduwNztoAoDFAKFeWOSeSGOoTmwsvvBDvec97cPDgQTz44IO4+uqr8apXvQrf+ta3AAA333wzPv3pT+POO+/Evffei8OHD+M1r3nNMC8hIiIyFK1NIiICDPmJzStf+coV//8Hf/AHuO2223D//ffjwgsvxMc+9jF88pOfxNVXXw0AuP322/Gc5zwH999/P172spet3ahFRER+SGuTiIgAq6ixyfMcd9xxB5rNJvbu3YuDBw+i3+9j3759y9tceuml2LNnD+677z63n263i4WFhRX/RERETofWJhGR89fQDzbf+MY3MDY2hlqthje+8Y2466678NznPhczMzOoVquYmppasf309DRmZmbc/vbv34/Jycnlf7t37x56J0RE5PymtUlERIZ+sHn2s5+Nhx56CA888ADe9KY34frrr8e3v/3t0x7Arbfeivn5+eV/hw7ZgnAREZGno7VJRESGqrEBgGq1imc961kAgCuuuAJf/epX8cd//Md47Wtfi16vh7m5uRU/GZudncWOHTyFCwBqtRpqtdrwI/+hmKQCAaDpZW7CV7DJEvmSs23BUx3OpCi1py2enOAbO2lK54LQtSkZ1XkndWPWJn9ki/zyT0golJdSxtJOvPSbpD14gglN8gJQJelj7e389aLEJpgEJ/ko6Q+eJsNkdSdRiSSgefvWH7cH001mI+ksXpILS9UJJOUGAKLcjjdd5Clh6eycaetf4pyMYRRkP5zzFjod0xZVSdITAGyestv2bBpSVHSBuacb4Ma00damtRDIOuRlOaaTdi1szPA5LsrsNZLX+PxUkBdkcyQApEvsXuPbkkBJRN7ySubI2BlDeMruW1F1UhtJgFrshR0OEQUXkW1ZAhbAjyVL9wK8tYKPgaVgecmc/Uk+Z/RHB//ZN00Zc7CUsZykfnnijL9WStasfoMfy4y0e9c1O/d5hR94dj4K7502GVpeG/w9W2WRH4fqkl1DcicVjV1TqfNeBWTt7mzmO8fOsSfp29erLK6cDIoBktN+ZNV/x6YoCnS7XVxxxRWoVCq45557lr/28MMP4/HHH8fevXtX+zIiIiID09okInL+GeoTm1tvvRXXXnst9uzZg8XFRXzyk5/EF7/4RXz2s5/F5OQkXv/61+OWW27B5s2bMTExgTe/+c3Yu3evUmdERGTdaG0SERFgyAebI0eO4F//63+NJ598EpOTk7jsssvw2c9+Fr/wC78AAHj/+9+POI5x3XXXrfgjaCIiIutFa5OIiABDPth87GMfe9qv1+t1HDhwAAcOHFjVoERERAaltUlERIDTCA84myJWyBnzMqGobrdNRkZ4x6QIHRV+aEKz5Y5vrUUNHowQkf2IUq+klHXgFE47+7xRxaOjtq3PC8hzciizUadY1uYMoLrIj1lBuuiP0U2RV51AgHnbSf0E34+CFO9V552xzQ5e+FydY4WmXmEiCdtw9o0VJlZIYePJ17OVw15BaVGx7bETHhBltj3u8m3jnh1DPMfTIIpJe/2tCRIeEFigAICo0Ri426hlgwZCZqunQ+FV0MoZN73VNOVVPk+nLVv1Hvd5UXiUD144HZNgEa/InwUF5PXBi8q9flmISNJxAkto7o+z5pHwgNybNslU5BWFu0XoREpCBRpH+YHIRuwgnFwRGprSnXICc5z5MO3YdhZKAPDglcZTPImhu8mOg40X4EEK/TGnPHyIrKSMTJ3u9UfOJ3tPAQAxeTtZdYr82bXWG+f9skAKb7wpuTe8NbpPivxDTN4EAWgcIQci4teUF4DBFL0fP8dk/cHf4646PEBERERERORs04ONiIiIiIiUnh5sRERERESk9PRgIyIiIiIipacHGxERERERKb0NG4PV//kXIKRO7MR5ovOCZ5zhV5w+w6935uy4n0SVnCNGnzzbI1gbLN3HSzpjssYQyYDD2Dp48thaaD/vgjP6eqfKsg5w5KwOQX4oWrIpnImTBNrfOWXaOlt5MlFv0+D3VdK2bWmT98u29dKuitTGPLH0M4CnUmXO24PuFImPcn6EWyGJkrU5vi1Ly3RT0UjSmZeMxfpg6WcAUJApjqVlAUBlgSQ8kuQyAIgy3s5SItvTPDYuHyXJdU6CWqU5+PWHyO60t8+Us21C3hKwFE+AJ+3FzjFjyaUsXQ4AsGibvATWKkkTTVteEqgdm5sYy5JHnXu2u5mnpTH1Oft63nmrztl4wnRp5U2fZTbV06NPbEREREREpPT0YCMiIiIiIqWnBxsRERERESk9PdiIiIiIiEjp6cFGRERERERKb8OmoomIiJzPQoskAW2aoNt2N9u0qmyUxxCFCklN6jqJZB3bXlTppsgbJOnM65e0e6lUgaSBeWNg+xblfAyBhDz1x3i/CTkVLK0NAGIb8oTCSQjLyRgyJ4gxJq9XW3TSrur2YBaFk37mJXyRMXvJVqy5SPk+xz12nfD9aJB2r9/ISX2jYyDbRs7xAdk2r/MUzv6EfVvN9vdkH2Q/vONLksrc1FDSbe6khrIUNw/dD2e8Gdm3lKQFAvy+721aOZ9lzjXK6BMbEREREREpPT3YiIiIiIhI6enBRkRERERESk8PNiIiIiIiUnoKDxARESmJ0OBV86zAnrWd7CM3bXnq/JyzIEX+KS/kTdokaMB5l8H6iHtOkb8drlvFnk+Ryv3YKVo+ao+lF6KQjQw8BKRN29Yf5dtmI/b1ki7fNu7bF2xv4uctInXliVPE7raT12NjAHhxu4cdt+AEAuQ1sn9egb0TusBU5+11klecY0mu4bRFrjMAlaW+HVfC++2PkaCBvnMfksPT3UySJ8DDFSpL7CYC0rZtD5EX+sD7oGOo2sknznnYQUHmnlNDDQKZhzz6xEZEREREREpPDzYiIiIiIlJ6erAREREREZHS04ONiIiIiIiUnh5sRERERESk9DZsKlrlCw8hjU5JfIhtykIyOcE7SMmuBSeRYW6ebMpjN6LEjqH3sz/Fx7BK1Xu/wb9A0keiKk/KiVi6BdkHAMhPnBh4bBtBVLH7fOzXr6DbHn2JTfOIJ2x6CQCEzD7vRyd4+khlwW7rJdqwpJxh1ebtddma5mkhzZ8g+1fh90D6lD2WE48OPq6YB8QMlczD0nbSNt+28aQ9mHGrR7ctxuqmLSRO+hK7t7y5oG+vqd4m+1rDqj+xYF+ry69VdMk+505yDZkTA/n+rODHUc6CzZOmKRuv0U3jzF6ntWP8Oi+q5FpwQodCYvv1UtFoshUZFwBE5DIN3o9aSRdJhw84arJ4OL5t7bhtrx930tZqJB3OOWZp1/YRtfm2MbndvPm00rITKptjAT7Peil5pyZQLW9P5sN0iQ8uIutmNsJPKE3wc1LVWMKXl8yWkuPjYYlkHjbe/hg/mOw+TFt8Tk56drxFlR+zvEqSzpp8f9maFZPX8uSNwT/zSNr8emD3cp7yY8buo1Ovh2FS9/SJjYiIiIiIlJ4ebEREREREpPT0YCMiIiIiIqWnBxsRERERESm9DRsewLCggGhijG4bWh3Tlh+f4x0XTrEt63eIbVfNCTuIUlI82ufFxXnXVrJ7QQNlE4+NmjavkDLKSOFn4RRMkvakz7dNSUGoFxLAimUBIAqs0I9vy4po3YJbUuAbp/wAsQLh6iLvNiJj8I572rZf8IoYK4vkGuY1ogALxYidA1GQ14v4tuwsR5l3zNbn50KhYgssvfCA0CIXoBceUCHTfZ8UfgaFB2wUgZyzKPduCitveP2yiYRvG7dJQMqSlzQweIEvDRaxyzYAPs92p5x+yVxPb2wABVlKexPOXN+ybYlTxM72zZun0w6Ze52icFZAHTthLIN+P/A0Rehk7isqzo4MMx2SIVeavAi9dtzOZwWZIwEgGyEBU856k7TI6zkhCr0JGx5UVJywA9LcneLhQ/Sa8G4hcsy8MbDrr3BCo1iQTtLha0jasuuQd00l/cHDCgqylkanvP8NzjrM6BMbEREREREpPT3YiIiIiIhI6enBRkRERERESk8PNiIiIiIiUnp6sBERERERkdIrVSpaIAlfOOEkALH0kCpPpihICFBCErdOfsEmS/C8otULGU8J8dopkh4V10gUDIBAti06TkzNBhDVbLpbbYEnZzSeJOetxZ/rCxIe4qWUsW0z59KJnQuFpfh4yUdJ27anLScZZdHe3l6iTX3BtqfdwRMA06aXokLaSQocAMTdIa5rkoCWj/K0P5YyhsI5vi1yop1zUYzz+2i1InIcvOSZqG7HEHr8Yo3qdbttROZU59jImRcvsSguJ7WrRtL0cr7mRSTlkbUBQHWepCY582FObonAw5jofMjSzwAg6ZJ5r8PH28/JOlbj60JBkiMj8v0AEGdkWyeoqTdGjq+zLTuWvTE+T7Pj4EwNiMh42foB+OeIpdxFzvwQk7ElHe+4236zBn87mpAdzOp8wDFJ4oqddaw/bu8NlqoG8ORSb81jKWw5uTcBIGuwNDAnaY+83DAJid55qy7YGzHu8X0rUrLu1vl5y+skTbHrpO+RsUWnJA7GSkUTEREREZHziR5sRERERESk9PRgIyIiIiIipacHGxERERERKb0NGx4QpSmiaOXwovExux0pIgaAUJBCoz4vTo5i0k5CAjaKeHzcNvZ5ZToLGgi5UxjGwhk2sKJpC2vTNi8wCzErrOX91lixrHNoIlaP59S4VZq8eC8lBZ2JEzTAiu+SSV49mnRJEW3B7xdWyEvqRgHwY+wWBZKCv1B1QhuqdjqK+/wksbFFOR9DMm8rkqOec79UyJToFHNWWjZYI3vmFrrtMKKFJTuEzDkOrHLYKRItTszZtpa9h/KwXnEoMqziqWOmLWLXKICUFPYmbRsYAfCgALYMAnzuC86PROvHBi+w707ZMeR8uADIXOaFEpBbJSHhKABQP0rm+o5THE/DDpxCb7bPznya9Gwfw+wbK8QHgIQUlrshJEMEhrDieIAH03ivR9cW5/iwgn5vn2MS/NCb4qEyeY3cL07YQSCBHV4QD1sL07YTBBUN8Rac7HLsnAv6vsQ5xXHHXtiRs+7GsIEL0ZITVhPstrmz9qctux+nXpMKDxARERERkfOKHmxERERERKT09GAjIiIiIiKlpwcbEREREREpvVU92LznPe9BFEW46aablts6nQ5uuOEGbNmyBWNjY7juuuswOzu72nGKiIgMRGuTiMj56bRT0b761a/iz/7sz3DZZZetaL/55pvxt3/7t7jzzjsxOTmJG2+8Ea95zWvw5S9/eaj+Q54jRCufu8JS027nJBaFnk1qYAlhnnx+gbbHoyMD97FayfR22h5FNh4jtGzyEwAEkhRVtG2aEwBEqU2xCH2eeLEhkCS4uM+TM7Ixe51kE4Onu9SOO5EtRGov06fVmyAJRc5hb5A0Iy91iKW+RU7aTkFmgv4o/7kHS1zJRpyfkZBkFG+8acsOOOnxAcddu23knPtQt2MAS00EeAKal7zozD3rwkszInNBTpLOACCq2nSgZMtm0xaKHnB8yPFtIOu9Np1J8Tabsheq5HoG0Nlu16aRI07CV8ZiBfkYWAJacOaRrD74/JSyy9QZQ5TZ/ah4sY2kE5ZoBgBJ1/abk30AgIjc7zlJ4QKAmCSSeaKCpXA6aVdkTo/JsTnZB9l4DaYslnQJ8LTLrOGsISSFLSbpcABQVMk15SSaRuS4p8664B1jJmvYCz44755Z2pp3jth1wq51ACjI8aXpZwAq8zbKsKjxAWfjNdPmpdklJN0t7vD31UmTpK1lzkEj99apKade6ilzWp/YLC0t4XWvex0++tGPYtOmTcvt8/Pz+NjHPoY/+qM/wtVXX40rrrgCt99+O/7f//t/uP/++0/npURERAaitUlE5Px2Wg82N9xwA37pl34J+/btW9F+8OBB9Pv9Fe2XXnop9uzZg/vuu4/21e12sbCwsOKfiIjIsLQ2iYic34b+VbQ77rgDX/va1/DVr37VfG1mZgbVahVTU1Mr2qenpzEzM0P7279/P/7Df/gPww5DRERkmdYmEREZ6hObQ4cO4S1veQv+4i/+AvW6+yeCh3Lrrbdifn5++d+hQ4fWpF8RETk/aG0SERFgyE9sDh48iCNHjuBFL3rRclue5/jSl76EP/3TP8VnP/tZ9Ho9zM3NrfjJ2OzsLHbs2EH7rNVqqNVs8dLJYqKVBUWhawuiIva94IWyw4QHoHCq084gVhgMAEhIIZsXojBE8X/YAPs8jKhuz313il/S/S323Fcm7PUEAP26vXaighfspkukeLtBN0XK8x1QXbDnLnGKXXNSSNmb5NdJfzMp3qvzc9xL7D535vnPPVjhcdrm11913h53WtQKAKSgNKTOz17IvRHlvN+ob9tDze4vAIQGOc9OsSwrJl4LYYwElHgBBqQt9oosA2knc4kbrLCBndG1aR2kF15A25vPmzZtWZ1fC80d9lz2x/nrZWSOCqmzhpDpJek6RfNk3vKCBlioQNLhY2DbdrbyfvM6CRog8/QPezYtsTM9sRAFFrpyslsSCOAUx7NCehZqAPBz4QXmBDKGghS2A0DS4TvN+vYyG1LSh1egX6SDh/FE5MB7oQT9MXuxeceSjcE7lkmPhDA5wREhIWv0KL8JCtJcafExsHAddu0AQD7K368wCSn+Z9cOAB5iQ/bX5ayZ3n6crqEebF7xilfgG9/4xoq23/iN38Cll16K3/md38Hu3btRqVRwzz334LrrrgMAPPzww3j88cexd+/etRu1iIjID2ltEhERYMgHm/HxcTz/+c9f0TY6OootW7Yst7/+9a/HLbfcgs2bN2NiYgJvfvObsXfvXrzsZS9bu1GLiIj8kNYmEREBVvF3bDzvf//7EccxrrvuOnS7XVxzzTX40Ic+tNYvIyIiMjCtTSIi575VP9h88YtfXPH/9XodBw4cwIEDB1bbtYiIyGnR2iQicv45rb9jIyIiIiIispGs+a+irSeWahaPkAQhAGjYyE/vKa5otQYfhJO8tB6ymdl16TdK+WkfKjVuAwg9G8HTG3POcmrPWxw7SRwsecYLlyPbsqQTgCeaATzxx0sSYsk8cEKsoq7dODiRNmnbtlea/PiwBLS476SzkASnuMfvobRFDrKTzkKTzir8oGVTNtkqJt8PAHGTJOVlzj2fOidptUhyTESudQBAu2O/fYiXKubmbVtwXkvWTRjlUYo0uSnnZ7g2ZycCdv8BQDFBEgidqZOlhIXESZoic5w3d7KgSZa4CADIyD3hXeiki2zEmctaLF2Rd8uSomIyLoCfI+/4ZnXbb4j53MLSo3oTfNuEzMnVOb7GB5Z2BaA/Tk6Sk2zFUruSLp9Lopp9D5I3nP0gKZrpEu83HyHvbZzEraQg5945n4Hch6wN4OfIS/1iybde6iFb56tz/OZiaaK5k4jXJ8fMGy9LvuuTdFqPl77H1vnslHFl3jpM6BMbEREREREpPT3YiIiIiIhI6enBRkRERERESk8PNiIiIiIiUnobNjyg//MvQEhtAIDZ7gyM5Wzp77vibA+hdMae4MV0Y59krVWnF1Y456UHnH1jP+Dt2x4appczF4qR13mRaF53gkDWhTP1kaCBM63zjM1n9fWzrAN84awO4bwTdfn8woJFvBCS7hQrGOavx4rmhwks8Qrs2XgTksfh9Rv3nCJr0lw4AQaBhMIkbf4z3MqS3TZt001pQIoXYEADZJxcBLrcOAX6SYeMt3DSYwg3TKLCB8fOBwslAHgxfeHMs0WFBNt4AQZjtg836IIW/zuBOc3B17ysNnhQTNK25yN1gngYr8g/YqEhzjUVEpaAxDeutEgoFwlsAECDGCISVAAABTlm7LwDQLpk579kfmUwTpw7EwmhT2xERERERKT09GAjIiIiIiKlpwcbEREREREpPT3YiIiIiIhI6enBRkRERERESm/DpqKJiIicFzKeQsSSyrI6TzfKRlnb4GlMw/HimGwTSxNzex0iZaxwQi2Luu0kp2lZQH+MJHlVeL8xiWCNbKAUAKDStq/nJb7R1xompNLrlvzY2kseY2l2AD8fEUnGAoCCJXGxNvDUrrjPB5Eu2YMRnHQtlrpFxwXQS9jbll3DcY+Pl+1HlHsHmKUT8jEULHXOSWvLq/Y4ePdWRPYj6vMLkCWzOQF+Q2GvF+X50/7/09EnNiIiIiIiUnp6sBERERERkdLTg42IiIiIiJSeHmxERERERKT0FB4gIiJyFoWROm1nxelFhRcXd7bYKt6ixit70yYpWvZqrEnds1uITOp7g/PjU9Zv3OPbspr3tO0MmPy81tuWjdcr8k+csdF+hzhmtKDfqcimhfvO8WXF5sMEOXjjCKTg/WTng19TbBxeKEF/gqQ5OP2mLXtCWegDwIMCQjr4z/oj7xxl9uTnDeetNgsw8IIRyPn0VOftxeoFRwQSNIDMC2ewfXj7xs4nCyoAgHzUJoHE1ZX9FkMEaugTGxERERERKT092IiIiIiISOnpwUZEREREREpPDzYiIiIiIlJ6erAREREREZHSUyqaiIjIWRTqJPkJQH/U/uyxuZOnG6XPXDRtY40u3fb43KhpSw7xZLaka18vbdFNkZCX89LAaMqTs3HSsW0Vu7snu8hJGpiXtkbaWVIaAIAMLXES1Ni2HpYQllf5OS5IalelxZOmWDKbl4yVtvlOJ20Sy+ekogV2jEnyGMCT1byxDXMsWR9eyhhNnnOSzvKG7SMkCd22wtLAnMQ3dg+46YRkbF7KHUsqYylwAJB0SJLcErnhwPc5bvPYuVCx2xZVfsxYezjlvOXZ4I8r+sRGRERERERKTw82IiIiIiJSenqwERERERGR0tODjYiIiIiIlJ7CA0RERM6iKOMF4HHOCoZ5H92+LcDtpHyJL3p224rTb161Yxim0Ds4RcsFy0voOMXtpHC6P8aH0N1mi6GjzClij+3Pdkdmeb+sGN8LD0i6tr1wAgH6o6yAnG8bkxr//gj/+TTLYWD7AAB5zvsIESlCrzqvR/pOl/hFlY+SYnEWJuFwrz86Lqdwn12XXuE+y1YYItTAE2fk/s54kAO7j+Ie35bts/cpBpt7inqVb0zCK7zAhYKEB3jBE2wM4ZTX8u4JRp/YiIiIiIhI6enBRkRERERESk8PNiIiIiIiUnp6sBERERERkdLTg42IiIiIiJSeUtFEREQ2IJbGNP4DHm0VFSOmrbu5QbeNR1jKGE83ins2jShykpCyEbttZZFuSvetcN6R9O2uuelwcZeMt++krXXIGFhaG4CcBEVlDf6z4bRt28IQP0ZmaXjutpnzBbLLcZ/3yxLUTn4DOZZOshrbv2x0iLeYzhjY63kpgqyPuO/cLyQpr6jw6yTpOK9HFCQ5LHbGy5K+vMS3iFwTSZvfBCGxYzg1Zezp2tn3A6DXg6eokOPgnIvKCXvDhFNS1aK8O/Br6xMbEREREREpPT3YiIiIiIhI6enBRkRERERESk8PNiIiIiIiUnobNjyg+n++iTRaWcUXVW31Xuj16PeHzKuoW3v9fVesS7+V/32Qf4EUnMEp5oxSe4rZcQSAotUaeGwbVXY1PxeHX14zbb0pp6iQHMqk7RSftljxHx8bK5YFgMqSbasuDF482ryAj621h9wDKd/n6qytmJ14lL9e2rVjS9t8vEnXvp5XiFlUyYFzruvqCVtImDT5XIA+OQ7sHgKAwo4tyviJCw17TXV2jfN+h1D//gnbuEAuEgDInYuKiEZJBXbPFp9mhXMcZd1EHX7M48xe/3mVX7udbSQQYJNzfdRIe+YUF3dJcXGbb5skdgwh8Yqhyfe79cGk0JsvY3z+rThhBw3bb0ICBU72ywrpncAFct68Av0isW1eIAANFXCmMlZsHpFxPZ1A+k46/JqKe7bdOz6MFwhQVOwBGiaUIKuTA+yNwRlvSMl10uXHoSCF9yxQ4GTHAw+NBnYUdSfpgr2UV/jP1ljnngW7ppygCzZebwxFlbxPddb+QegTGxERERERKT092IiIiIiISOnpwUZEREREREpPDzYiIiIiIlJ6Qz3Y/N7v/R6iKFrx79JLL13+eqfTwQ033IAtW7ZgbGwM1113HWZnZ9d80CIiIj+itUlERIDTSEV73vOeh//9v//3P3Xwz1K3br75Zvzt3/4t7rzzTkxOTuLGG2/Ea17zGnz5y18eemAhyxBOTS5KbLrFmUw/2zCGSIsILDWJpUSdI+KcJ6vENvzJTZPJG7YPL9UkzkhaSpv3G/GhIZDQltwGbgEAKk177uO+syNMMXhCkTdeluTipsmQFJS8zo9l2ho84atokKnLSVwJUd20eYkrUd+OIe7w+8VLe1qtiCSVeSlugcyJUcVJyiHnKPTta4WC3Swb35lam9ZDMd6g7VndnvfeGL8WsgmS6DfiXLtdct2Q9DMAiLv29SpNPgaWKObNIxEZmpeKxlLGWvyQoSDzd+TMkSz1y8PSn7z0MpaAxtLPAD5HFqmXtka+39sHMj95SXJxf/DXy2v8OmGpll5iVkFSxjxJj1xAzlwfk/k75M65Zyl33nhZYif4CWVpaVGf3wQ5W8e8t3dkbF7KGEuY89a8vG7H4L2PYvtWVJzrgaTDRV40IOti8LcDxtAPNmmaYseOHaZ9fn4eH/vYx/DJT34SV199NQDg9ttvx3Oe8xzcf//9eNnLXnb6oxQREXkaWptERGToGptHHnkEu3btwjOf+Uy87nWvw+OPPw4AOHjwIPr9Pvbt27e87aWXXoo9e/bgvvvuc/vrdrtYWFhY8U9ERGQYWptERGSoB5srr7wSH//4x3H33Xfjtttuw2OPPYaf+ZmfweLiImZmZlCtVjE1NbXie6anpzEzM+P2uX//fkxOTi7/271792ntiIiInJ+0NomICDDkr6Jde+21y/992WWX4corr8RFF12Ev/zLv0Sj4fzC649x66234pZbbln+/4WFBS0gIiIyMK1NIiICnEaNzT83NTWFn/zJn8Sjjz6KX/iFX0Cv18Pc3NyKn4zNzs7S33v+kVqthlrNqZQ+Reg6lYVMTAq7ilVUI50FUcWr9LMFY+6xIQVjod9bzbA2tMpTTdqeduybG1YwD/BCUxo+AKBI7PGNql5Bn/N6pE7PK7gtKrbv6gIvyKs/aW9vryi1ssAKTZ2C0iFuI1awmHScwsQWOchOcSQTt5zrOrYfTIcKL/xkRZfo8n4j0u9aCB1yL3shKak9x8EZL32ttq32DqH888OZXptWzSnsZfda4wS/f7Z+1V6PnS02OAMA+mO2LWs4ASBkzsiduYHNnakzd7L5Nzi3FJsPq3NeAbm9t1nICwBUWuT7ncuf1T376wLZ1rmFWXG8dxziIQrIaciLt+Y5RfO0EJ4EOQA8xCA4oTvJEPvBitNjpxifFdh7+0bH5fSbdMk58sJjWMiE02+osKALL2WItDnXCTvudG0DkC7ZCz5ywgPAchz4ls4N7pwLEo5zaqhS8NKeiFWtzEtLS/jOd76DnTt34oorrkClUsE999yz/PWHH34Yjz/+OPbu3bualxERERmY1iYRkfPTUJ/Y/Pt//+/xyle+EhdddBEOHz6Md77znUiSBL/2a7+GyclJvP71r8ctt9yCzZs3Y2JiAm9+85uxd+9epc6IiMi60dokIiLAkA82P/jBD/Brv/ZrOHbsGLZt24aXv/zluP/++7Ft2zYAwPvf/37EcYzrrrsO3W4X11xzDT70oQ+ty8BFREQArU0iInLSUA82d9xxx9N+vV6v48CBAzhw4MCqBiUiIjIorU0iIgKsssZGRERERERkI1hVKtqGVrIEtGFELEFimO8nSUoAELzkpRLpXDhB23MSbpR0ecpG0hk8fSNtkxQgkrQD+Ak6cd+evbTDz2h10caStLbyhC8aIuLsGktfqizxMaRdkvriJOWwBLSUpZ+Bpw7BSXKJ+iStp+tcv7ndNs74/BBqNokw1HkyVtyyiWJrgd3fqPKExNBu27Y+Pw4R64McG4Rzd+7cqKLDT9H2xqi99ljSIABEuU1A603wuT6v2T68FETm1MSi5TGw1CQnZYz14aVBsoClxAkCZcmR3njpuuCEkbJ53UsvK1JyD9MJjs+9CZljAb4fLLEL4Oll7rbONRXYew1yfAEg6dh5JziJZCxRLOk5czJJ+PIS1GLSR1QMnsTlpXbRPry0P7JmeYlkyYJtz0crdNuiak9+0uZzfbo4xNrEzrGT+BnR9cK5rlkir5OSx8Zw6hrvJrWx1x54SxERERERkQ1KDzYiIiIiIlJ6erAREREREZHS04ONiIiIiIiU3jkbHsAK5MtWHB/6vOoyOEVrVGwLzsp2HDzx6Khpm/sJXnjX2mkLz0LNK0y3hWyxEzQQk20LPgS/0JQUY3pFtHFmO8lrfGwhtsV7br/kmvICAdImKdB0ikTjnn3BeIlf17QY3ylMBCv+97at2hMSUl5NHHXt2KIOr1IONDxgCx/DEEJn8MLPomnDA6KEX2iha/ejIK9VDDXByFoI5LoDeMGsV4DbnbTXdMe5HPs77DmOyHwBAFgka2nupJCQZlagDwAJ2WUWpALw8AAvCIXxgltYAAF9LfDQlOqCU/BOitu9InYWsJI3nOJtMn+z7weA2ClYp/2SeRoAEtJHXudvGwtyXXrrQqjYbbMan5MDOc+x0y9IeEDihNUw+ShPjihqdrxxd/UhKywEJ+nyc8/OpxeiEGrkTUgxxPXg7BsLmQhOvzREwXs91kd2aniAk0JC6BMbEREREREpPT3YiIiIiIhI6enBRkRERERESk8PNiIiIiIiUnp6sBERERERkdI7Z1PRzpXkr1UrVp/csWHFLIXF2ZRcDkUyeLKPl2jGJE6oVeQEuYC0e+ll9Nt5mAxyFvDi7EdWt239Ub5x2iHpQCecpDOW5OKk6oS+bWcpZa7K4NMZS5sCAJDX81JfQFLG1kLo2RSfkHsXNknwm5rk/bLUuFZrqLHJ+ojHbMIjAHSnbKQYS1E8ue0QMWEde2+z9CkASJt227TjpESS25UljwFA2rbXY6U1eCpaf5SPoT9BkhhJeiUAJGQ/2FoBABlJn4zG+OTL0tK8VLSiSuZZZ61gKZPeecsaJM3O2TZJnDmuYw9G3HUOkJPQRTcl+0GPA5x103mpQBMh+dxZVO256485iW8kxa0SedeUPT5ekiFLjWOvdbIT2+SdC5a25iL74SWB0m2dhFH67V0noY6tb8nKfqMh3svqExsRERERESk9PdiIiIiIiEjp6cFGRERERERKTw82IiIiIiJSeudseICc++LREdOWjfCCvpB4lfuk37Z93o+dmjfW7hXzR04dPC2iJW0AkHZI0aVTbJg3WLWhU8BasYOm4QMAsro9xmmN7zQLD4hIceXJQZACVhIQcbITcp6zIQomaZGp83o958RVK4O/3jDIvnnF5aFpi/9D37lYUxLOULEnOQoR4HQh6yN/6ihtrx7fatpY0TMAVOft+e1NOAXOTduHO0eyLrxwE1YH79UWk5fLq3y8LLCkftwZQn/w+bt+nAShLPKdC6Q4nhV/A0CRsv1YfVhNVJDAHDLHuryiezpe0LnIu/5YOII7NtJF1OfbsvCAuMfn+qhHCvfJ2gbwgv6EhBp4Y/AENn+TcQFAUSMBD87a5IVP0G3ZdcnCYwAEGsLk3APeujkoZwwggTk4NazDC/Eh9ImNiIiIiIiUnh5sRERERESk9PRgIyIiIiIipacHGxERERERKT092IiIiIiISOkpFU1KKz8xZ9oiJzgjkDSwUOEb52TbaMmJ9mEhH07wR+wk6DDefkQkDCZxQruS7uDJPKkN10LjGB9EZckOgqWfAUBMEtDiJfJiANDpmqYwZpPvAAAJSfjq8+QZlhIWkYQwAEBqz3NU4elnbvrYKkUVMjZv3zKSArSwRLeNJ8bsa9Vrtk2paGccO48AkDTtPRH1+bWbdhq232TwlMgo59uyRKii5iQs9VjEF92U/lg1cq67wIbm9JvYQ+bOkSz50UtmS3rkmDnzdFEhCWpOqlVCki69tDWazuWtNx07T0deMhZLmQQ/7l5CWExSzeh5AxD1yRri9MtS2AqSaHayDxa35gyC8a6plr0/3ZQyuuzyMcRtMn87CaP0HDmpoSzxjaWfneyDfH/HSWYjaWmh5oyBzj1O1CpJW4u6p0wGSkUTEREREZHziR5sRERERESk9PRgIyIiIiIipacHGxERERERKT2FB0hpxRMTps0rVnRq5p2ObVNR4YWCRc12XPA6YOSFU0DYJ8EGzo8csrrtwy3QJONwCz/Jtt4YWGFrlDnHhxR+Rg1bsH6yX1JE6xTNg2zLCv8B59Q7RbTo2eplr7A7kG3XBAs2iJxiTrIfUZWHHYAUuxZNG+RQBCUHbBhH50xTPGpDAgCgNm/DIdLm4IW9cd+bn0ibU4xfWbLXGPt+AEi7dtu0PXhBtle8HWIyRzpzWTLEHMmOWeFUm7NQgaQzRCCAI+6R4u3UC4ggx8FZCOMuSaUBD4VhxxfgBf1sTj/ZMenDC0wgQQP0++EUzTuF++z68UIbQI5l5ATmsHnWw4ICCic8gB2fIubbxmRdiNv8RmTHzA1GIAE/kVfUT+apUHH2jbSH0fqK/y/yKvAD/u2n0ic2IiIiIiJSenqwERERERGR0tODjYiIiIiIlJ4ebEREREREpPT0YCMiIiIiIqWnVDQpL5JWVWnyNI+kZZ/h3ZSynm1PW16ajG2LeMAMTT8DgKRn2xOSGOT14aXqsGQe1zCpcURR5T8jYa1eMkpUIdNR7hxMJ+mGSsgovLSehKS4xU4iWcVJH1stlsLmpdSw4+OkW4UeibIqyPcH55jLmUfPj5cGZtti7/bJhrh/hkjtKqosbc0ZLxuCMyzWR04SIgEgGyHdOrd7laS4efsbe4lZBJ2TvUNO7u2kywdM06qc4xuzZufaiXv8QmEJaEWdv21kiWIsVQ0AcrYGpM762CHzYd85PmT/vPUmJ/vBkuQAnoDmJqixfXb6ZQloXuocez0/BZYk4jljoNeEs+6Gdtu+FEvxBOgay86P65R1103YY986+KuIiIiIiIhsTHqwERERERGR0tODjYiIiIiIlJ4ebEREREREpPQUHiDlFUhx2jAF846Y1ComHb5tZYl8v1PMmdq6u5N9k5purw9WPBpl3ra2zSs25IW8TmACeb3YKeZ0i96Zvj3wtOAdQFSt2saUF4kGFkpAipwBIOr1beMQRYtrIbDX84o5vXAFhoQdsGLOKMQACcWQs2DrZtNU1PiyndftzymzOu+2P07uSyeFJOnae6U670wk5LphoQbey9HieAA5uV8LJ7ujqAweNNCdJPu26AV12CY3KIbNyd7cm9oDFJzC9CKy23oF2TS/wDm+wSnyp+fI2ZYGEDhjo+Nwti1Y8b9z7ocpTveOBd+YXH9Vvt6AnE8vRCFu2zXPDQPqD358abu3jJFQgVCv8THkY7aRhd0AiLp27Q41sm4DAAtMOPX9QM5fh3Y38JYiIiIiIiIblB5sRERERESk9PRgIyIiIiIipacHGxERERERKb2hH2yeeOIJ/Pqv/zq2bNmCRqOBn/qpn8KDDz64/PUQAt7xjndg586daDQa2LdvHx555JE1HbSIiMg/p7VJRESGSkU7ceIErrrqKvz8z/88PvOZz2Dbtm145JFHsGnTpuVt3vve9+KDH/wgPvGJT+Diiy/G29/+dlxzzTX49re/jXrdiWgROQ3FUtM2eiEh7BHeiR8JLAHFSWFh/QaSMgIAec1JS2OJa06CjtvOkKgzL3El7dgvVJo88iciiT00EQdA1LYpY3HTiYcrSModSfJykVQ1AIh6ZKedBDWa4lb14pecPtZBcPYt9EnyTDzEuAp73kIgyXAb3Lm6NrFEv1Dly3Z/hKQbeYlkLGDJmbfouLx+2f3jdMuSzuK+l8Ro27zbLwxx+aetwV4L4MmRTnAkXYe8BDU23rzm7RzNOqObsnkaleF+lu0lbtJt6dC8KDiSxjhMSpmDrd2eiKRPFixB05GQtQ0Aoh5JOnNS0QJLfHP2gfXrpqKxPrxjwxJNvbRNtm46/QayLU0odUTxKddqPHgC6FAPNn/4h3+I3bt34/bbb19uu/jii5f/O4SAD3zgA/jd3/1dvOpVrwIA/Pmf/zmmp6fxqU99Cr/6q786zMuJiIj8WFqbREQEGPJX0f76r/8aL37xi/Erv/Ir2L59O174whfiox/96PLXH3vsMczMzGDfvn3LbZOTk7jyyitx33330T673S4WFhZW/BMRERmU1iYREQGGfLD57ne/i9tuuw2XXHIJPvvZz+JNb3oTfuu3fguf+MQnAAAzMzMAgOnp6RXfNz09vfy1U+3fvx+Tk5PL/3bv3n06+yEiIucprU0iIgIM+WBTFAVe9KIX4d3vfjde+MIX4g1veAN+8zd/Ex/+8IdPewC33nor5ufnl/8dOnTotPsSEZHzj9YmEREBhqyx2blzJ5773OeuaHvOc56D//E//gcAYMeOHQCA2dlZ7Ny5c3mb2dlZvOAFL6B91mo11Gq1YYYhclJEnsud+riY1fnFw1TicyxUIOJ1gm7xKCui9X7mUF20nSRd3m9libfTbZu2CDFp8x2Ju6Q40i2kHKIQnRVKe0X+pGAxajsHgvVxamHij5BierR42EHo2sJ9YBvvdwhRao9DNMrHG3rkmDmFnxELxeiycxy5IRwb1bm6NkXkXIac3xNJl9zDzi2RN2ybV4ecdOx14/XLQwn4tuzKK1KnEJndws58yor/vUAAVrBOi+7hBMUM86Nh5wBHOQl9cJamhASheMEtgQQFOEuT+wVWYI+E73ReJ28nnX1mY/PmnKRD1hvnHMVkvfHCNuh4HbT43yuaJ4EAIXFuAhLYEZz3JVHK3u84FwoZb9x11mISTEPPO0DXzVCr0k1pUIATUEKDEbJTrut88PcSQ31ic9VVV+Hhhx9e0faP//iPuOiiiwCcLNbcsWMH7rnnnuWvLyws4IEHHsDevXuHeSkREZGBaG0SERFgyE9sbr75Zvz0T/803v3ud+Nf/at/ha985Sv4yEc+go985CMATv5E8KabbsLv//7v45JLLlmO1Ny1axde/epXr8f4RUTkPKe1SUREgCEfbF7ykpfgrrvuwq233op3vetduPjii/GBD3wAr3vd65a3+e3f/m00m0284Q1vwNzcHF7+8pfj7rvv3rB/J0BERMpNa5OIiABDPtgAwC//8i/jl3/5l92vR1GEd73rXXjXu961qoGJiIgMSmuTiIgM92doRURERERENqChP7ER2Siiqo0kSzs8LSVt22d4JzwKacsmd6QtZ1vyet62NZJoBvD0scqSE+NDUma6UzxxJe6TBBIvCI4ctrjPk1FYYkpUONuemmwC+EkuLOnMS2dhaTveCXVSfAbtN2TOuViDVD06BPJ67FoHACTk+JCUG8BJcGLH0YvHkjPvqeOmKWmQSDMA9U32V+q6E861T67dwgluSjukreWkUpHgIi+RLM5IwpeXdNa3244/zueGfoOkuPX4tilJkvNSLdncycblbRucRKiEJBN620ZsfmJpWQAKlorm9MvOBQBELZLK5817bA1haWLOOIK3LtAOeL+BpHYVVefCJrw1DyQ9z0NT0Zx9o+fTOb60D2euTljKmLeWktRQd7xsbXHOBfvYhJ0fgCd2mvcDQ1wf+sRGRERERERKTw82IiIiIiJSenqwERERERGR0tODjYiIiIiIlJ7CA6S0imbTtNVO8OrT2gn7DO8V6Y0cscVwtRO8AjbKbfEeKwYFgKTVo+1xh/TNiu4BRF3bx7hbVGeLib3iURaC4BWwxou2mpiGBIAf48grxGSFiV7hfsPuWxjlRdX09byCRxZgUKvRTUOPVEqvk9AmFdwAQo9cU9HgBZqKCdjgWHGwM2+x67y65BT5k9sq8urgSb9eSEtEpoG86hTNk8L7uMf7LVgfzni9sAKGzU9ewXvSZkEbg/frBbfkdXu/suPoibzxsmuHBAqc7IQ3FzX7FtErxqeF8PngBd9sLfUEJxAmIhcxC1EA+HijNQgPGEbBgh+8wn1W/D9EEI8XolPUbDBN3Oryftk67wXbEDELNXD6DSMr190wxD2hT2xERERERKT09GAjIiIiIiKlpwcbEREREREpPT3YiIiIiIhI6W248IDww4KuDP3SVLZmGS/sXa0onLni5HNF1ufnIu+R4jSn7i4jBYSJU8TOCh6DU8wZcn4+45z9lWAnPKCwxeLe9cdernCKOfk+e+O1hYVR4YQHkIPMijZPDo79VWOnYrAghfDOCaWv54UHsHbvr1yT8a7FXJAEEgjgVE4GOkd4xbLkr82T78/Q/2HfJZmAz5CzsTYFcr9HBV+22bXH7msAyFmoxxDhASCF/4ATHuAUOAcWHuD0W5A+cqfivSDtXmBJIFNOcI4ZHdsQ4QHuvEd44QGBFFl74QFsgcudYJHYKdyPyesV8eDhAd7Y6F+g9/6APStYd84nG0PmjIFtS1/LeT0vFoGtQ8G7B9iatQbhAey9RsTeZwAoSL9sjQeAqLDtXkBEIO9h3IAIMrZTl7zsh2MaZF2KwgZbvX7wgx9g9+7dZ3sYIiLntUOHDuHCCy8828PYMLQ2iYicXYOsSxvuwaYoChw+fBjj4+NYXFzE7t27cejQIUxMTJztoa2phYUF7VsJad/KSfs2uBACFhcXsWvXLsTsJ6vnKa1N5ad9KyftWzmt5b4Nsy5tuF9Fi+N4+WnsR393YWJi4pw74T+ifSsn7Vs5ad8GMzk5uSb9nEu0Np07tG/lpH0rp7Xat0HXJf04TkRERERESk8PNiIiIiIiUnob+sGmVqvhne98J2q12tkeyprTvpWT9q2ctG+yls7lY659KyftWzlp39behgsPEBERERERGdaG/sRGRERERERkEHqwERERERGR0tODjYiIiIiIlJ4ebEREREREpPT0YCMiIiIiIqW3oR9sDhw4gGc84xmo1+u48sor8ZWvfOVsD2loX/rSl/DKV74Su3btQhRF+NSnPrXi6yEEvOMd78DOnTvRaDSwb98+PPLII2dnsEPYv38/XvKSl2B8fBzbt2/Hq1/9ajz88MMrtul0OrjhhhuwZcsWjI2N4brrrsPs7OxZGvFwbrvtNlx22WXLfzF37969+MxnPrP89TLv2z/3nve8B1EU4aabblpuK/O+/d7v/R6iKFrx79JLL13+epn3DQCeeOIJ/Pqv/zq2bNmCRqOBn/qpn8KDDz64/PWyzidlci6sS4DWpjLOA+fLugScW2uT1qUzO5ds2Aeb//bf/htuueUWvPOd78TXvvY1XH755bjmmmtw5MiRsz20oTSbTVx++eU4cOAA/fp73/tefPCDH8SHP/xhPPDAAxgdHcU111yDTqdzhkc6nHvvvRc33HAD7r//fnzuc59Dv9/HL/7iL6LZbC5vc/PNN+PTn/407rzzTtx77704fPgwXvOa15zFUQ/uwgsvxHve8x4cPHgQDz74IK6++mq86lWvwre+9S0A5d63H/nqV7+KP/uzP8Nll122or3s+/a85z0PTz755PK///t//+/y18q8bydOnMBVV12FSqWCz3zmM/j2t7+N//gf/yM2bdq0vE1Z55OyOFfWJUBrUxnngfNhXQLOzbVJ69IZnEvCBvXSl7403HDDDcv/n+d52LVrV9i/f/9ZHNXqAAh33XXX8v8XRRF27NgR3ve+9y23zc3NhVqtFv7rf/2vZ2GEp+/IkSMBQLj33ntDCCf3o1KphDvvvHN5m7//+78PAMJ99913toa5Kps2bQr/6T/9p3Ni3xYXF8Mll1wSPve5z4Wf/dmfDW95y1tCCOU/b+985zvD5ZdfTr9W9n37nd/5nfDyl7/c/fq5NJ9sVOfiuhSC1qYyzQOnOpfWpRDOzbVJ69KZnUs25Cc2vV4PBw8exL59+5bb4jjGvn37cN99953Fka2txx57DDMzMyv2c3JyEldeeWXp9nN+fh4AsHnzZgDAwYMH0e/3V+zbpZdeij179pRu3/I8xx133IFms4m9e/eeE/t2ww034Jd+6ZdW7ANwbpy3Rx55BLt27cIzn/lMvO51r8Pjjz8OoPz79td//dd48YtfjF/5lV/B9u3b8cIXvhAf/ehHl79+Ls0nG9H5si4B59a1dK6uTefiugScu2uT1qUzN5dsyAebo0ePIs9zTE9Pr2ifnp7GzMzMWRrV2vvRvpR9P4uiwE033YSrrroKz3/+8wGc3LdqtYqpqakV25Zp377xjW9gbGwMtVoNb3zjG3HXXXfhuc99bun37Y477sDXvvY17N+/33yt7Pt25ZVX4uMf/zjuvvtu3HbbbXjsscfwMz/zM1hcXCz9vn33u9/FbbfdhksuuQSf/exn8aY3vQm/9Vu/hU984hMAzp35ZKM6X9Yl4Ny5ls7FtelcXZeAc3dt0rp0ZueSdF16lfPKDTfcgG9+85srfmf0XPDsZz8bDz30EObn5/Hf//t/x/XXX4977733bA9rVQ4dOoS3vOUt+NznPod6vX62h7Pmrr322uX/vuyyy3DllVfioosuwl/+5V+i0WicxZGtXlEUePGLX4x3v/vdAIAXvvCF+OY3v4kPf/jDuP7668/y6EQ2nnNxbToX1yXg3F6btC6dWRvyE5utW7ciSRKTCjE7O4sdO3acpVGtvR/tS5n388Ybb8Tf/M3f4Atf+AIuvPDC5fYdO3ag1+thbm5uxfZl2rdqtYpnPetZuOKKK7B//35cfvnl+OM//uNS79vBgwdx5MgRvOhFL0KapkjTFPfeey8++MEPIk1TTE9Pl3bfmKmpKfzkT/4kHn300VKfNwDYuXMnnvvc565oe85znrP8Kw3nwnyykZ0v6xJwblxL5+radC6uS8D5tTZpXVrf/duQDzbVahVXXHEF7rnnnuW2oihwzz33YO/evWdxZGvr4osvxo4dO1bs58LCAh544IENv58hBNx4442466678PnPfx4XX3zxiq9fccUVqFQqK/bt4YcfxuOPP77h981TFAW63W6p9+0Vr3gFvvGNb+Chhx5a/vfiF78Yr3vd65b/u6z7xiwtLeE73/kOdu7cWerzBgBXXXWVia39x3/8R1x00UUAyj2flMH5si4B5b6Wzre16VxYl4Dza23SurTOc8m6RBKsgTvuuCPUarXw8Y9/PHz7298Ob3jDG8LU1FSYmZk520MbyuLiYvj6178evv71rwcA4Y/+6I/C17/+9fD9738/hBDCe97znjA1NRX+6q/+Kvzd3/1deNWrXhUuvvji0G63z/LIn96b3vSmMDk5Gb74xS+GJ598cvlfq9Va3uaNb3xj2LNnT/j85z8fHnzwwbB3796wd+/eszjqwb3tbW8L9957b3jsscfC3/3d34W3ve1tIYqi8L/+1/8KIZR73071z5NnQij3vr31rW8NX/ziF8Njjz0WvvzlL4d9+/aFrVu3hiNHjoQQyr1vX/nKV0KapuEP/uAPwiOPPBL+4i/+IoyMjIT/8l/+y/I2ZZ1PyuJcWZdC0NpUxnngfFqXQjh31iatS2d2LtmwDzYhhPAnf/InYc+ePaFarYaXvvSl4f777z/bQxraF77whQDA/Lv++utDCCej8N7+9reH6enpUKvVwite8Yrw8MMPn91BD4DtE4Bw++23L2/TbrfDv/t3/y5s2rQpjIyMhH/5L/9lePLJJ8/eoIfwb//tvw0XXXRRqFarYdu2beEVr3jF8uIRQrn37VSnLh5l3rfXvva1YefOnaFarYYLLrggvPa1rw2PPvro8tfLvG8hhPDpT386PP/5zw+1Wi1ceuml4SMf+ciKr5d1PimTc2FdCkFrUxnngfNpXQrh3FmbtC6d2bkkCiGE9fksSERERERE5MzYkDU2IiIiIiIiw9CDjYiIiIiIlJ4ebEREREREpPT0YCMiIiIiIqWnBxsRERERESk9PdiIiIiIiEjp6cFGRERERERKTw82IiIiIiJSenqwERERERGR0tODjYiIiIiIlJ4ebEREREREpPT+/4o2n9uDqLcSAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax1.imshow(train_set[0][0][0], cmap='viridis')\n",
    "ax2.imshow(val_set[0][0][0], cmap='viridis')\n",
    "print(train_set[0][0][0].shape)\n",
    "ax1.grid(False)\n",
    "ax2.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of classes: 36\n"
     ]
    }
   ],
   "source": [
    "print(\"number of classes:\", len(np.unique(data_frame['Key'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoAtNet (Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stem(nn.Sequential):\n",
    "    def __init__(self, out_channels):\n",
    "        super().__init__(\n",
    "            nn.Conv2d(1, out_channels, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MBConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, expansion_factor=4):\n",
    "        super().__init__()\n",
    "        self.mb_conv = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.Conv2d(in_channels, in_channels * expansion_factor, kernel_size=1),\n",
    "            nn.BatchNorm2d(in_channels * expansion_factor),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(in_channels * expansion_factor, in_channels * expansion_factor, kernel_size=3, padding=1, groups=in_channels * expansion_factor),\n",
    "            nn.BatchNorm2d(in_channels * expansion_factor),\n",
    "            nn.GELU(),\n",
    "            SqueezeExcitation(in_channels * expansion_factor, in_channels, activation=nn.GELU),\n",
    "            nn.Conv2d(in_channels * expansion_factor, out_channels, kernel_size=1),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.mb_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownsamplingMBConv(MBConv):\n",
    "    def __init__(self, in_channels, out_channels, expansion_factor=4):\n",
    "        super().__init__(in_channels, out_channels, expansion_factor=4)\n",
    "        self.mb_conv[1] = nn.Conv2d(in_channels, in_channels * expansion_factor, kernel_size=1, stride = 2)\n",
    "        self.channel_projection = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.channel_projection(self.pool(x)) + self.mb_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelativeAttention2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, image_size, heads=8, head_size=32):\n",
    "        super().__init__()\n",
    "        heads = out_channels // head_size\n",
    "        self.heads = heads\n",
    "        self.head_size = head_size\n",
    "        self.image_size = image_size\n",
    "        self.head_dim = heads * head_size\n",
    "        self.attend = nn.Softmax(dim=-2) # Taken from My_CoAtNet\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.to_q = nn.Linear(in_channels, self.head_dim)\n",
    "        self.to_k = nn.Linear(in_channels, self.head_dim)\n",
    "        self.to_v = nn.Linear(in_channels, self.head_dim)\n",
    "        self.to_output = nn.Sequential(\n",
    "            nn.Linear(self.head_dim, out_channels),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.normalization = nn.LayerNorm(in_channels)\n",
    "        \n",
    "        self.relative_bias = nn.Parameter(torch.randn(heads, (2 * image_size - 1) * (2 * image_size - 1)))\n",
    "        self.register_buffer(\"relative_indices\", self.get_indices(image_size, image_size)) # Taken from My_CoAtNet\n",
    "        self.precomputed_relative_bias = None\n",
    "    \n",
    "    def norm(self, x):\n",
    "        x = x.transpose(1, -1) # Taken from My_CoAtNet\n",
    "        x = self.normalization(x)\n",
    "        x = x.transpose(-1, 1) # Taken from My_CoAtNet\n",
    "        return x\n",
    "    \n",
    "    def get_relative_biases(self):\n",
    "        # Relative bias caching mentioned in CoAtNet: Marrying Convolution and Attention for All Data Sizes\n",
    "        if not self.training:\n",
    "            return self.precomputed_relative_bias\n",
    "        # Taken from od My_CoAtNet\n",
    "        indices = self.relative_indices.expand(self.heads, -1)\n",
    "        rel_pos_enc = self.relative_bias.gather(-1, indices)\n",
    "        rel_pos_enc = rel_pos_enc.unflatten(-1, (self.image_size * self.image_size, self.image_size * self.image_size))\n",
    "        return rel_pos_enc\n",
    "    \n",
    "    def reshape_for_linear(self, x):\n",
    "        b, _, _, _ = x.shape\n",
    "        return x.reshape(b, self.image_size * self.image_size, self.in_channels)\n",
    "    \n",
    "    def attention_score(self, x):\n",
    "        b, _, h, _ = x.shape\n",
    "        q = self.to_q(self.reshape_for_linear(x)).view(b, self.heads, self.head_size, -1) # Taken from My_CoAtNet\n",
    "        k = self.to_k(self.reshape_for_linear(x)).view(b, self.heads, self.head_size, -1) # Taken from My_CoAtNet\n",
    "        dots = torch.matmul(k.transpose(-1, -2), q) / math.sqrt(self.head_dim)\n",
    "        relative_biases_indexed = self.get_relative_biases()\n",
    "        return self.attend(dots + relative_biases_indexed)\n",
    "    \n",
    "    def relative_attention(self, x):\n",
    "        b, _, _, _ = x.shape\n",
    "        v = self.to_v(self.reshape_for_linear(x)).view(b, self.heads, self.head_size, -1) # Taken from My_CoAtNet\n",
    "        out = torch.matmul(v, self.attention_score(x)) # I figured this out after debugging (Still the same as My_CoAtNet)\n",
    "        out = out.view(b, self.image_size, self.image_size, -1)\n",
    "        return self.to_output(out).view(b, self.out_channels, self.image_size, self.image_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.relative_attention(self.norm(x))\n",
    "    \n",
    "    def train(self, training):\n",
    "        if not training:\n",
    "            self.precomputed_relative_bias = self.get_relative_biases()\n",
    "        super().train(training)\n",
    "        \n",
    "    # Taken from My_CoAtNet\n",
    "    @staticmethod\n",
    "    def get_indices(h, w):\n",
    "        y = torch.arange(h, dtype=torch.long)\n",
    "        x = torch.arange(w, dtype=torch.long)\n",
    "        \n",
    "        y1, x1, y2, x2 = torch.meshgrid(y, x, y, x)\n",
    "        indices = (y1 - y2 + h - 1) * (2 * w - 1) + x1 - x2 + w - 1\n",
    "        indices = indices.flatten()\n",
    "        \n",
    "        return indices\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownsamplingRelativeAttention2d(RelativeAttention2d):\n",
    "    def __init__(self, in_channels, out_channels, image_size, heads=8, head_size=32):\n",
    "        super().__init__(in_channels, out_channels, image_size, heads=8, head_size=32)\n",
    "        self.channel_projection = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.normalization = nn.LayerNorm(in_channels)\n",
    "\n",
    "\n",
    "    def norm(self, x):\n",
    "        x = x.transpose(1, -1) # Taken from My_CoAtNet\n",
    "        x = self.normalization(x)\n",
    "        x = x.transpose(-1, 1) # Taken from My_CoAtNet\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.channel_projection(self.pool(x)) + self.relative_attention(self.pool(self.norm(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, out_channels, expansion_factor=4):\n",
    "        super().__init__()\n",
    "        hidden_dim = out_channels * expansion_factor\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(out_channels, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, out_channels),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.normalization = nn.LayerNorm(out_channels)\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    \n",
    "    def norm(self, x):\n",
    "        x = x.transpose(1, -1) # Taken from My_CoAtNet\n",
    "        x = self.normalization(x)\n",
    "        x = x.transpose(-1, 1) # Taken from My_CoAtNet\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        old_shape = x.shape\n",
    "        batch_size = old_shape[0]\n",
    "        return x + torch.reshape(self.ffn(torch.reshape(self.norm(x), (batch_size, -1, self.out_channels))), old_shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownsampleTransformerBlock(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels, image_size):\n",
    "        attention = DownsamplingRelativeAttention2d(in_channels, out_channels, image_size)\n",
    "        ffn = FeedForwardNetwork(out_channels)\n",
    "        super().__init__(\n",
    "            attention,\n",
    "            ffn\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels, image_size):\n",
    "        attention = RelativeAttention2d(in_channels, out_channels, image_size)\n",
    "        ffn = FeedForwardNetwork(out_channels)\n",
    "        super().__init__(\n",
    "            attention,\n",
    "            ffn\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(in_channels, num_classes)\n",
    "        self.in_channels = in_channels\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.pool(x)\n",
    "        x = torch.reshape(x, (batch_size, -1, self.in_channels))\n",
    "        return torch.squeeze(self.fc(x))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCoAtNet(nn.Sequential):\n",
    "    def __init__(self, nums_blocks, layer_out_channels, num_classes=36):\n",
    "        s0 = nn.Sequential(Stem(layer_out_channels[0]))\n",
    "        \n",
    "        s1 = [DownsamplingMBConv(layer_out_channels[0], layer_out_channels[1])]\n",
    "        for i in range(nums_blocks[1] - 1):\n",
    "            s1.append(MBConv(layer_out_channels[1], layer_out_channels[1]))\n",
    "        s1 = nn.Sequential(*s1)\n",
    "        \n",
    "        s2 = [DownsamplingMBConv(layer_out_channels[1], layer_out_channels[2])]\n",
    "        for i in range(nums_blocks[2] - 1):\n",
    "            s2.append(MBConv(layer_out_channels[2], layer_out_channels[2]))\n",
    "        s2 = nn.Sequential(*s2)\n",
    "        \n",
    "        s3 = [DownsampleTransformerBlock(layer_out_channels[2], layer_out_channels[3], 64 // 16)]\n",
    "        for i in range(nums_blocks[3] - 1):\n",
    "            s3.append(TransformerBlock(layer_out_channels[3], layer_out_channels[3], 64 // 16))\n",
    "        s3 = nn.Sequential(*s3)\n",
    "        \n",
    "        s4 = [DownsampleTransformerBlock(layer_out_channels[3], layer_out_channels[4], 64 // 32)]\n",
    "        for i in range(nums_blocks[4] - 1):\n",
    "            s4.append(TransformerBlock(layer_out_channels[4], layer_out_channels[4], 64 // 32))\n",
    "        s4 = nn.Sequential(*s4)\n",
    "        \n",
    "        head = Head(layer_out_channels[4], num_classes)\n",
    "        \n",
    "        super().__init__(\n",
    "            s0,\n",
    "            s1,\n",
    "            s2,\n",
    "            s3,\n",
    "            s4,\n",
    "            head\n",
    "        )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\miniconda3\\Lib\\site-packages\\torch\\functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# CoAtNet-1\n",
    "nums_blocks = [2, 2, 3, 5, 2]           # L\n",
    "channels = [64, 96, 192, 384, 768]      # D\n",
    "\n",
    "model = MyCoAtNet(nums_blocks, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_linear(m):\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "        if m.bias is not None: nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 24,033,296\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]             640\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "              GELU-3           [-1, 64, 32, 32]               0\n",
      "            Conv2d-4           [-1, 64, 30, 30]          36,928\n",
      "         MaxPool2d-5           [-1, 64, 15, 15]               0\n",
      "            Conv2d-6           [-1, 96, 15, 15]           6,144\n",
      "       BatchNorm2d-7           [-1, 64, 30, 30]             128\n",
      "            Conv2d-8          [-1, 256, 15, 15]          16,640\n",
      "       BatchNorm2d-9          [-1, 256, 15, 15]             512\n",
      "             GELU-10          [-1, 256, 15, 15]               0\n",
      "           Conv2d-11          [-1, 256, 15, 15]           2,560\n",
      "      BatchNorm2d-12          [-1, 256, 15, 15]             512\n",
      "             GELU-13          [-1, 256, 15, 15]               0\n",
      "AdaptiveAvgPool2d-14            [-1, 256, 1, 1]               0\n",
      "           Conv2d-15             [-1, 64, 1, 1]          16,448\n",
      "             GELU-16             [-1, 64, 1, 1]               0\n",
      "           Conv2d-17            [-1, 256, 1, 1]          16,640\n",
      "          Sigmoid-18            [-1, 256, 1, 1]               0\n",
      "SqueezeExcitation-19          [-1, 256, 15, 15]               0\n",
      "           Conv2d-20           [-1, 96, 15, 15]          24,672\n",
      "      BatchNorm2d-21           [-1, 96, 15, 15]             192\n",
      "DownsamplingMBConv-22           [-1, 96, 15, 15]               0\n",
      "      BatchNorm2d-23           [-1, 96, 15, 15]             192\n",
      "           Conv2d-24          [-1, 384, 15, 15]          37,248\n",
      "      BatchNorm2d-25          [-1, 384, 15, 15]             768\n",
      "             GELU-26          [-1, 384, 15, 15]               0\n",
      "           Conv2d-27          [-1, 384, 15, 15]           3,840\n",
      "      BatchNorm2d-28          [-1, 384, 15, 15]             768\n",
      "             GELU-29          [-1, 384, 15, 15]               0\n",
      "AdaptiveAvgPool2d-30            [-1, 384, 1, 1]               0\n",
      "           Conv2d-31             [-1, 96, 1, 1]          36,960\n",
      "             GELU-32             [-1, 96, 1, 1]               0\n",
      "           Conv2d-33            [-1, 384, 1, 1]          37,248\n",
      "          Sigmoid-34            [-1, 384, 1, 1]               0\n",
      "SqueezeExcitation-35          [-1, 384, 15, 15]               0\n",
      "           Conv2d-36           [-1, 96, 15, 15]          36,960\n",
      "      BatchNorm2d-37           [-1, 96, 15, 15]             192\n",
      "           MBConv-38           [-1, 96, 15, 15]               0\n",
      "        MaxPool2d-39             [-1, 96, 8, 8]               0\n",
      "           Conv2d-40            [-1, 192, 8, 8]          18,432\n",
      "      BatchNorm2d-41           [-1, 96, 15, 15]             192\n",
      "           Conv2d-42            [-1, 384, 8, 8]          37,248\n",
      "      BatchNorm2d-43            [-1, 384, 8, 8]             768\n",
      "             GELU-44            [-1, 384, 8, 8]               0\n",
      "           Conv2d-45            [-1, 384, 8, 8]           3,840\n",
      "      BatchNorm2d-46            [-1, 384, 8, 8]             768\n",
      "             GELU-47            [-1, 384, 8, 8]               0\n",
      "AdaptiveAvgPool2d-48            [-1, 384, 1, 1]               0\n",
      "           Conv2d-49             [-1, 96, 1, 1]          36,960\n",
      "             GELU-50             [-1, 96, 1, 1]               0\n",
      "           Conv2d-51            [-1, 384, 1, 1]          37,248\n",
      "          Sigmoid-52            [-1, 384, 1, 1]               0\n",
      "SqueezeExcitation-53            [-1, 384, 8, 8]               0\n",
      "           Conv2d-54            [-1, 192, 8, 8]          73,920\n",
      "      BatchNorm2d-55            [-1, 192, 8, 8]             384\n",
      "DownsamplingMBConv-56            [-1, 192, 8, 8]               0\n",
      "      BatchNorm2d-57            [-1, 192, 8, 8]             384\n",
      "           Conv2d-58            [-1, 768, 8, 8]         148,224\n",
      "      BatchNorm2d-59            [-1, 768, 8, 8]           1,536\n",
      "             GELU-60            [-1, 768, 8, 8]               0\n",
      "           Conv2d-61            [-1, 768, 8, 8]           7,680\n",
      "      BatchNorm2d-62            [-1, 768, 8, 8]           1,536\n",
      "             GELU-63            [-1, 768, 8, 8]               0\n",
      "AdaptiveAvgPool2d-64            [-1, 768, 1, 1]               0\n",
      "           Conv2d-65            [-1, 192, 1, 1]         147,648\n",
      "             GELU-66            [-1, 192, 1, 1]               0\n",
      "           Conv2d-67            [-1, 768, 1, 1]         148,224\n",
      "          Sigmoid-68            [-1, 768, 1, 1]               0\n",
      "SqueezeExcitation-69            [-1, 768, 8, 8]               0\n",
      "           Conv2d-70            [-1, 192, 8, 8]         147,648\n",
      "      BatchNorm2d-71            [-1, 192, 8, 8]             384\n",
      "           MBConv-72            [-1, 192, 8, 8]               0\n",
      "      BatchNorm2d-73            [-1, 192, 8, 8]             384\n",
      "           Conv2d-74            [-1, 768, 8, 8]         148,224\n",
      "      BatchNorm2d-75            [-1, 768, 8, 8]           1,536\n",
      "             GELU-76            [-1, 768, 8, 8]               0\n",
      "           Conv2d-77            [-1, 768, 8, 8]           7,680\n",
      "      BatchNorm2d-78            [-1, 768, 8, 8]           1,536\n",
      "             GELU-79            [-1, 768, 8, 8]               0\n",
      "AdaptiveAvgPool2d-80            [-1, 768, 1, 1]               0\n",
      "           Conv2d-81            [-1, 192, 1, 1]         147,648\n",
      "             GELU-82            [-1, 192, 1, 1]               0\n",
      "           Conv2d-83            [-1, 768, 1, 1]         148,224\n",
      "          Sigmoid-84            [-1, 768, 1, 1]               0\n",
      "SqueezeExcitation-85            [-1, 768, 8, 8]               0\n",
      "           Conv2d-86            [-1, 192, 8, 8]         147,648\n",
      "      BatchNorm2d-87            [-1, 192, 8, 8]             384\n",
      "           MBConv-88            [-1, 192, 8, 8]               0\n",
      "        MaxPool2d-89            [-1, 192, 4, 4]               0\n",
      "           Conv2d-90            [-1, 384, 4, 4]          73,728\n",
      "        LayerNorm-91            [-1, 8, 8, 192]             384\n",
      "        MaxPool2d-92            [-1, 192, 4, 4]               0\n",
      "           Linear-93              [-1, 16, 384]          74,112\n",
      "           Linear-94              [-1, 16, 384]          74,112\n",
      "           Linear-95              [-1, 16, 384]          74,112\n",
      "          Softmax-96           [-1, 12, 16, 16]               0\n",
      "           Linear-97            [-1, 4, 4, 384]         147,840\n",
      "          Dropout-98            [-1, 4, 4, 384]               0\n",
      "DownsamplingRelativeAttention2d-99            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-100            [-1, 4, 4, 384]             768\n",
      "          Linear-101             [-1, 16, 1536]         591,360\n",
      "            GELU-102             [-1, 16, 1536]               0\n",
      "         Dropout-103             [-1, 16, 1536]               0\n",
      "          Linear-104              [-1, 16, 384]         590,208\n",
      "         Dropout-105              [-1, 16, 384]               0\n",
      "FeedForwardNetwork-106            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-107            [-1, 4, 4, 384]             768\n",
      "          Linear-108              [-1, 16, 384]         147,840\n",
      "          Linear-109              [-1, 16, 384]         147,840\n",
      "          Linear-110              [-1, 16, 384]         147,840\n",
      "         Softmax-111           [-1, 12, 16, 16]               0\n",
      "          Linear-112            [-1, 4, 4, 384]         147,840\n",
      "         Dropout-113            [-1, 4, 4, 384]               0\n",
      "RelativeAttention2d-114            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-115            [-1, 4, 4, 384]             768\n",
      "          Linear-116             [-1, 16, 1536]         591,360\n",
      "            GELU-117             [-1, 16, 1536]               0\n",
      "         Dropout-118             [-1, 16, 1536]               0\n",
      "          Linear-119              [-1, 16, 384]         590,208\n",
      "         Dropout-120              [-1, 16, 384]               0\n",
      "FeedForwardNetwork-121            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-122            [-1, 4, 4, 384]             768\n",
      "          Linear-123              [-1, 16, 384]         147,840\n",
      "          Linear-124              [-1, 16, 384]         147,840\n",
      "          Linear-125              [-1, 16, 384]         147,840\n",
      "         Softmax-126           [-1, 12, 16, 16]               0\n",
      "          Linear-127            [-1, 4, 4, 384]         147,840\n",
      "         Dropout-128            [-1, 4, 4, 384]               0\n",
      "RelativeAttention2d-129            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-130            [-1, 4, 4, 384]             768\n",
      "          Linear-131             [-1, 16, 1536]         591,360\n",
      "            GELU-132             [-1, 16, 1536]               0\n",
      "         Dropout-133             [-1, 16, 1536]               0\n",
      "          Linear-134              [-1, 16, 384]         590,208\n",
      "         Dropout-135              [-1, 16, 384]               0\n",
      "FeedForwardNetwork-136            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-137            [-1, 4, 4, 384]             768\n",
      "          Linear-138              [-1, 16, 384]         147,840\n",
      "          Linear-139              [-1, 16, 384]         147,840\n",
      "          Linear-140              [-1, 16, 384]         147,840\n",
      "         Softmax-141           [-1, 12, 16, 16]               0\n",
      "          Linear-142            [-1, 4, 4, 384]         147,840\n",
      "         Dropout-143            [-1, 4, 4, 384]               0\n",
      "RelativeAttention2d-144            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-145            [-1, 4, 4, 384]             768\n",
      "          Linear-146             [-1, 16, 1536]         591,360\n",
      "            GELU-147             [-1, 16, 1536]               0\n",
      "         Dropout-148             [-1, 16, 1536]               0\n",
      "          Linear-149              [-1, 16, 384]         590,208\n",
      "         Dropout-150              [-1, 16, 384]               0\n",
      "FeedForwardNetwork-151            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-152            [-1, 4, 4, 384]             768\n",
      "          Linear-153              [-1, 16, 384]         147,840\n",
      "          Linear-154              [-1, 16, 384]         147,840\n",
      "          Linear-155              [-1, 16, 384]         147,840\n",
      "         Softmax-156           [-1, 12, 16, 16]               0\n",
      "          Linear-157            [-1, 4, 4, 384]         147,840\n",
      "         Dropout-158            [-1, 4, 4, 384]               0\n",
      "RelativeAttention2d-159            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-160            [-1, 4, 4, 384]             768\n",
      "          Linear-161             [-1, 16, 1536]         591,360\n",
      "            GELU-162             [-1, 16, 1536]               0\n",
      "         Dropout-163             [-1, 16, 1536]               0\n",
      "          Linear-164              [-1, 16, 384]         590,208\n",
      "         Dropout-165              [-1, 16, 384]               0\n",
      "FeedForwardNetwork-166            [-1, 384, 4, 4]               0\n",
      "       MaxPool2d-167            [-1, 384, 2, 2]               0\n",
      "          Conv2d-168            [-1, 768, 2, 2]         294,912\n",
      "       LayerNorm-169            [-1, 4, 4, 384]             768\n",
      "       MaxPool2d-170            [-1, 384, 2, 2]               0\n",
      "          Linear-171               [-1, 4, 768]         295,680\n",
      "          Linear-172               [-1, 4, 768]         295,680\n",
      "          Linear-173               [-1, 4, 768]         295,680\n",
      "         Softmax-174             [-1, 24, 4, 4]               0\n",
      "          Linear-175            [-1, 2, 2, 768]         590,592\n",
      "         Dropout-176            [-1, 2, 2, 768]               0\n",
      "DownsamplingRelativeAttention2d-177            [-1, 768, 2, 2]               0\n",
      "       LayerNorm-178            [-1, 2, 2, 768]           1,536\n",
      "          Linear-179              [-1, 4, 3072]       2,362,368\n",
      "            GELU-180              [-1, 4, 3072]               0\n",
      "         Dropout-181              [-1, 4, 3072]               0\n",
      "          Linear-182               [-1, 4, 768]       2,360,064\n",
      "         Dropout-183               [-1, 4, 768]               0\n",
      "FeedForwardNetwork-184            [-1, 768, 2, 2]               0\n",
      "       LayerNorm-185            [-1, 2, 2, 768]           1,536\n",
      "          Linear-186               [-1, 4, 768]         590,592\n",
      "          Linear-187               [-1, 4, 768]         590,592\n",
      "          Linear-188               [-1, 4, 768]         590,592\n",
      "         Softmax-189             [-1, 24, 4, 4]               0\n",
      "          Linear-190            [-1, 2, 2, 768]         590,592\n",
      "         Dropout-191            [-1, 2, 2, 768]               0\n",
      "RelativeAttention2d-192            [-1, 768, 2, 2]               0\n",
      "       LayerNorm-193            [-1, 2, 2, 768]           1,536\n",
      "          Linear-194              [-1, 4, 3072]       2,362,368\n",
      "            GELU-195              [-1, 4, 3072]               0\n",
      "         Dropout-196              [-1, 4, 3072]               0\n",
      "          Linear-197               [-1, 4, 768]       2,360,064\n",
      "         Dropout-198               [-1, 4, 768]               0\n",
      "FeedForwardNetwork-199            [-1, 768, 2, 2]               0\n",
      "AdaptiveAvgPool2d-200            [-1, 768, 1, 1]               0\n",
      "          Linear-201                [-1, 1, 36]          27,684\n",
      "            Head-202                   [-1, 36]               0\n",
      "================================================================\n",
      "Total params: 24,029,924\n",
      "Trainable params: 24,029,924\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 26.27\n",
      "Params size (MB): 91.67\n",
      "Estimated Total Size (MB): 117.96\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model.apply(init_linear)\n",
    "model.to(device)\n",
    "\n",
    "print(\"Number of parameters: {:,}\".format(sum(p.numel() for p in model.parameters())))\n",
    "\n",
    "summary(model, input_size=(1, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyCoAtNet(\n",
       "  (0): Sequential(\n",
       "    (0): Stem(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): DownsamplingMBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (channel_projection): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "        (5): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): DownsamplingMBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(96, 384, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "        (5): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (channel_projection): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        (5): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        (5): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): DownsampleTransformerBlock(\n",
       "      (0): DownsamplingRelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (channel_projection): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): DownsampleTransformerBlock(\n",
       "      (0): DownsamplingRelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (channel_projection): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (5): Head(\n",
       "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (fc): Linear(in_features=768, out_features=36, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model.load_state_dict(torch.load(\"CoAtNet-1-Best-Zoom.pkl\"))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_set,\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from My_CoAtNet\n",
    "def separate_parameters(model):\n",
    "    parameters_decay = set()\n",
    "    parameters_no_decay = set()\n",
    "    modules_weight_decay = (nn.Linear, nn.Conv2d)\n",
    "    modules_no_weight_decay = (nn.LayerNorm, nn.BatchNorm2d)\n",
    "    \n",
    "    for m_name, m in model.named_modules():\n",
    "        for param_name, param in m.named_parameters():\n",
    "            full_param_name = f\"{m_name}.{param_name}\" if m_name else param_name\n",
    "\n",
    "            if isinstance(m, modules_no_weight_decay):\n",
    "                parameters_no_decay.add(full_param_name)\n",
    "            elif param_name.endswith(\"bias\"):\n",
    "                parameters_no_decay.add(full_param_name)\n",
    "            elif isinstance(m, modules_weight_decay):\n",
    "                parameters_decay.add(full_param_name)\n",
    "    \n",
    "    # sanity check\n",
    "    assert len(parameters_decay & parameters_no_decay) == 0\n",
    "    assert len(parameters_decay) + len(parameters_no_decay) == len(list(model.parameters()))\n",
    "\n",
    "    return parameters_decay, parameters_no_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 5e-4\n",
    "weight_decay = 0.1\n",
    "num_epochs = 1100\n",
    "min_learning_rate = 1e-6\n",
    "\n",
    "param_dict = {pn: p for pn, p in model.named_parameters()}\n",
    "parameters_decay, parameters_no_decay = separate_parameters(model)\n",
    "parameter_groups = [\n",
    "    {\"params\": [param_dict[pn] for pn in parameters_decay], \"weight_decay\": weight_decay},\n",
    "    {\"params\": [param_dict[pn] for pn in parameters_no_decay], \"weight_decay\": 0.0},\n",
    "]\n",
    "optimizer = torch.optim.Adam(parameter_groups, lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=min_learning_rate / learning_rate, total_iters=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from My_CoAtNet\n",
    "def plot_results(train_losses, train_accuracies, val_losses, val_accuracies):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title(\"Loss\")\n",
    "    plt.plot(train_losses)\n",
    "    plt.plot(val_losses)\n",
    "    plt.legend([\"Training loss\", \"Validation loss\"], loc =  \"best\")\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.plot(train_accuracies)\n",
    "    plt.plot(val_accuracies)\n",
    "    plt.legend([\"Training accuracy\", \"Validation accuracy\"], loc =  \"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = \"CoAtNet-1-Best-Zoom.pkl\"\n",
    "model_path = \"CoAtNet-1-Zoom.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyCoAtNet(\n",
       "  (0): Sequential(\n",
       "    (0): Stem(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): DownsamplingMBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (channel_projection): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "        (5): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): DownsamplingMBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(96, 384, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "        (5): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (channel_projection): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        (5): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        (5): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): DownsampleTransformerBlock(\n",
       "      (0): DownsamplingRelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (channel_projection): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): DownsampleTransformerBlock(\n",
       "      (0): DownsamplingRelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (channel_projection): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (5): Head(\n",
       "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (fc): Linear(in_features=768, out_features=36, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mappings from indices to syllables and vice versa\n",
    "digits_and_syllables = list('0123456789abcdefghijklmnopqrstuvwxyz')\n",
    "idx_to_syllable = {idx: syllable for idx, syllable in enumerate(digits_and_syllables)}\n",
    "syllable_to_idx = {syllable: idx for idx, syllable in idx_to_syllable.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine test and validation datasets\n",
    "combined_dataset = ConcatDataset([val_set, test_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from syllables to dataset indices\n",
    "syllable_to_indices = {}\n",
    "for idx in range(len(combined_dataset)):\n",
    "    _, label = combined_dataset[idx]\n",
    "    # label = label.item() \n",
    "    syllable = idx_to_syllable[label]\n",
    "    if syllable not in syllable_to_indices:\n",
    "        syllable_to_indices[syllable] = []\n",
    "    syllable_to_indices[syllable].append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process sentences into syllables\n",
    "def get_syllables(sentence):\n",
    "    sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "    # sentence = sentence.replace(' ',  '').lower()\n",
    "    syllables = list(sentence)\n",
    "    return syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 1000\n"
     ]
    }
   ],
   "source": [
    "# Read sentences from the text file\n",
    "with open('../sentences/sentences.txt', 'r') as f:\n",
    "    sentences = f.readlines()\n",
    "\n",
    "print(\"Number of sentences:\", len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "\n",
    "def compute_accuracy_and_wrong_syllables(true_sentence, predicted_sentence):\n",
    "    # Character-level accuracy using SequenceMatcher\n",
    "    char_matcher = difflib.SequenceMatcher(None, true_sentence, predicted_sentence)\n",
    "    accuracy = char_matcher.ratio()\n",
    "    \n",
    "    # Word-level wrong syllable count using SequenceMatcher on word lists\n",
    "    true_words = true_sentence.split()\n",
    "    predicted_words = predicted_sentence.split()\n",
    "    word_matcher = difflib.SequenceMatcher(None, true_words, predicted_words)\n",
    "    \n",
    "    # Calculate wrong syllables based on insert, delete, and replace operations\n",
    "    wrong_syllables = sum(1 for tag, _, _, _, _ in word_matcher.get_opcodes() if tag in ('insert', 'delete', 'replace'))\n",
    "    \n",
    "    return accuracy, wrong_syllables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:13<00:00,  1.31s/it]\n"
     ]
    }
   ],
   "source": [
    "# Process each sentence\n",
    "noise_factor = 6\n",
    "results = []\n",
    "\n",
    "for sentence in tqdm(sentences[:10]):\n",
    "    sentence = sentence.strip()\n",
    "    syllables = get_syllables(sentence)\n",
    "    true_sentence = ''.join(syllables)\n",
    "    predicted_syllables = []\n",
    "\n",
    "    for syllable in syllables:\n",
    "        if syllable in syllable_to_indices:\n",
    "            # Randomly select an index for the syllable\n",
    "            idx = random.choice(syllable_to_indices[syllable])\n",
    "            # Retrieve the image and label from the dataset\n",
    "            image, _ = combined_dataset[idx]\n",
    "\n",
    "            noise = torch.randn_like(image) * noise_factor\n",
    "            image = image + noise\n",
    "            image = image.unsqueeze(0).to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(image)\n",
    "                output = output.reshape(1, -1)\n",
    "                _, predicted_idx = torch.max(output.data, 1)\n",
    "                predicted_syllable = idx_to_syllable[predicted_idx.item()]\n",
    "        else:\n",
    "            if random.random() < 0.90:\n",
    "                predicted_syllable = ' '\n",
    "            else:\n",
    "                predicted_syllable = random.choice(digits_and_syllables)\n",
    "        predicted_syllables.append(predicted_syllable)\n",
    "    \n",
    "    predicted_sentence = ''.join(predicted_syllables)\n",
    "    accuracy, wrong_syllables = compute_accuracy_and_wrong_syllables(true_sentence, predicted_sentence)\n",
    "    results.append([true_sentence, predicted_sentence, accuracy, wrong_syllables])\n",
    "    # print(f\"accuracy: {accuracy}, wrong: {wrong_syllables}, true: {true_sentence}, predicted: {predicted_sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise factor: 6\n",
      "Average accuracy: 0.7224\n",
      "Total wrong syllables: 25\n"
     ]
    }
   ],
   "source": [
    "# accuracy average and wrong syllables sum\n",
    "accuracy_avg = sum(result[2] for result in results) / len(results)\n",
    "wrong_syllables_sum = sum(result[3] for result in results)\n",
    "\n",
    "print(\"Noise factor:\", noise_factor)\n",
    "print(f\"Average accuracy: {accuracy_avg:.4f}\")\n",
    "print(f\"Total wrong syllables: {wrong_syllables_sum}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Noise level: 1\n",
    "- Average accuracy: 0.9776\n",
    "- Total wrong syllables: 1355\n",
    "---\n",
    "- Noise factor: 5\n",
    "- Average accuracy: 0.8453\n",
    "- Total wrong syllables: 2878\n",
    "---\n",
    "- Noise factor: 6\n",
    "- Average accuracy: 0.7241\n",
    "- Total wrong syllables: 2257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results/{noise_factor}.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['True Sentence', 'Predicted Sentence', 'Accuracy', 'Wrong syllables'])\n",
    "    for row in results:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
