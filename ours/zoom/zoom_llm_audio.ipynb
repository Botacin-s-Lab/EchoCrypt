{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import librosa\n",
    "import os\n",
    "import random\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math\n",
    "import torchaudio\n",
    "import csv\n",
    "import string\n",
    "\n",
    "from torch.utils.data import ConcatDataset\n",
    "from torchaudio.transforms import TimeMasking, FrequencyMasking\n",
    "from torchvision.ops import SqueezeExcitation\n",
    "from torchinfo import summary\n",
    "from torchsummary import summary\n",
    "from torchvision.ops import SqueezeExcitation\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from collections import defaultdict\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from scipy.io import wavfile\n",
    "from functools import reduce\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_s = '0123456789abcdefghijklmnopqrstuvwxyz'\n",
    "labels = list(keys_s)\n",
    "keys = [k + '.wav' for k in labels]\n",
    "data_dict = {'Key':[], 'File':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def add_noise_to_stroke(stroke, noise_factor=0.005):\n",
    "    # print(stroke.shape)\n",
    "    noise = torch.randn_like(stroke)\n",
    "    return stroke + noise_factor * noise\n",
    "\n",
    "def isolator(signal, sample_rate, size, scan, before, after, threshold, show=False):\n",
    "    strokes = []\n",
    "    if show:\n",
    "        plt.figure(figsize=(7, 2))\n",
    "        librosa.display.waveshow(signal, sr=sample_rate)\n",
    "    fft = librosa.stft(signal, n_fft=size, hop_length=scan)\n",
    "    energy = np.abs(np.sum(fft, axis=0)).astype(float)\n",
    "    if show:\n",
    "        plt.figure(figsize=(7, 2))\n",
    "        librosa.display.waveshow(energy)\n",
    "    threshed = energy > threshold\n",
    "    if show:\n",
    "        plt.figure(figsize=(7, 2))\n",
    "        librosa.display.waveshow(threshed.astype(float))\n",
    "    peaks = np.where(threshed)[0]\n",
    "    peak_count = len(peaks)\n",
    "    prev_end = sample_rate * 0.1 * (-1)\n",
    "    for i in range(peak_count):\n",
    "        this_peak = peaks[i]\n",
    "        timestamp = (this_peak * scan) + size // 2\n",
    "        if timestamp > prev_end + (0.1 * sample_rate):\n",
    "            keystroke = signal[timestamp - before:timestamp + after]\n",
    "            strokes.append(torch.tensor(keystroke)[None, :])\n",
    "            if show:\n",
    "                plt.figure(figsize=(7, 2))\n",
    "                librosa.display.waveshow(keystroke, sr=sample_rate)\n",
    "            prev_end = timestamp + after\n",
    "    return strokes\n",
    "\n",
    "def convert_to_df_with_noise(audio_dir, noise_factor=0.005):\n",
    "    \"\"\"\n",
    "    Processes each audio file by isolating strokes, adds noise to each stroke,\n",
    "    and stores the strokes with labels in a dataframe.\n",
    "    \"\"\"\n",
    "    # Generate a list of .wav files in the provided directory\n",
    "    keys = sorted([f for f in os.listdir(audio_dir) if f.endswith('.wav')])\n",
    "    \n",
    "    data_dict = {'Key': [], 'File': []}\n",
    "    \n",
    "    # If your labels are inferred from file names, you can extract them here.\n",
    "    # For example, if the file is 'a.wav', you might want to use 'a' as the label.\n",
    "    def extract_label(filename):\n",
    "        base = os.path.splitext(filename)[0]\n",
    "        return base  # or apply any mapping you need\n",
    "\n",
    "    for file in keys:\n",
    "        loc = os.path.join(audio_dir, file)\n",
    "        samples, sample_rate = librosa.load(loc, sr=None)\n",
    "        strokes = []\n",
    "        prom = 0.06\n",
    "        step = 0.005\n",
    "        # Adjust threshold until we get exactly 25 strokes (or break if not possible)\n",
    "        while not len(strokes) == 25:\n",
    "            strokes = isolator(samples[1 * sample_rate:], sample_rate, 48, 24, 2400, 12000, prom, show=False)\n",
    "            if len(strokes) < 25:\n",
    "                prom -= step\n",
    "            elif len(strokes) > 25:\n",
    "                prom += step\n",
    "            if prom <= 0:\n",
    "                print('-- not possible for:', file)\n",
    "                break\n",
    "            step *= 0.99\n",
    "        \n",
    "        # Apply noise to each extracted stroke\n",
    "        noisy_strokes = [add_noise_to_stroke(stroke, noise_factor) for stroke in strokes]\n",
    "\n",
    "        # Extract a label for this file (modify as needed)\n",
    "        label = extract_label(file)\n",
    "        data_dict['Key'] += [label] * len(noisy_strokes)\n",
    "        data_dict['File'] += noisy_strokes\n",
    "\n",
    "    df = pd.DataFrame(data_dict)\n",
    "    \n",
    "    # Optionally, create a mapping for the labels (if needed)\n",
    "    mapper = {}\n",
    "    counter = 0\n",
    "    for l in df['Key']:\n",
    "        if l not in mapper:\n",
    "            mapper[l] = counter\n",
    "            counter += 1\n",
    "    df.replace({'Key': mapper}, inplace=True)\n",
    "    \n",
    "    return df, sample_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Key                                               File\n",
      "0   0  [[tensor(0.0006), tensor(0.0032), tensor(-0.00...\n",
      "1   0  [[tensor(-0.0003), tensor(-0.0005), tensor(0.0...\n",
      "2   0  [[tensor(0.0037), tensor(0.0034), tensor(0.004...\n",
      "3   0  [[tensor(-0.0036), tensor(-0.0048), tensor(0.0...\n",
      "4   0  [[tensor(-0.0037), tensor(0.0050), tensor(-0.0...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 900 entries, 0 to 899\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Key     900 non-null    object\n",
      " 1   File    900 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 14.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data_frame, sr = convert_to_df_with_noise(\"../../dataset/Zoom/\", noise_factor=0.005)\n",
    "\n",
    "print(data_frame.head())\n",
    "print(data_frame.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample rate: 32000\n",
      "630 180 90\n"
     ]
    }
   ],
   "source": [
    "train_set, tmp_set = train_test_split(data_frame, test_size=0.3, stratify=data_frame['Key'])\n",
    "val_set, test_set = train_test_split(tmp_set, test_size=0.33, stratify=tmp_set['Key'])\n",
    "\n",
    "print(\"Sample rate:\", sr)\n",
    "print(len(train_set), len(val_set), len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, file_name, transform = None, aug = None):\n",
    "        df = file_name\n",
    "        self.transform = transform\n",
    "        self.aug = aug\n",
    "        self.labels = df['Key']\n",
    "        self.values = df['File']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, index):\n",
    "        label = self.labels.iloc[index]\n",
    "        value = self.values.iloc[index]\n",
    "        waveform = self.values.iloc[index]\n",
    "        label = self.labels.iloc[index]\n",
    "        if self.transform:\n",
    "            waveform = waveform.numpy()\n",
    "            waveform = waveform.flatten()\n",
    "            waveform = self.transform(waveform)\n",
    "        if self.aug:\n",
    "            waveform = self.aug(waveform)\n",
    "        return waveform, label\n",
    "\n",
    "class ToMelSpectrogram:\n",
    "    def __call__(self, samples):\n",
    "#         samples = np.array(samples)\n",
    "        spec = librosa.feature.melspectrogram(y = samples, sr = sr, n_mels=64, n_fft=2048, win_length=1024, hop_length=226)\n",
    "        return librosa.power_to_db(spec)\n",
    "\n",
    "class TimeShifting():\n",
    "    def __call__(self, samples):\n",
    "        samples = samples.numpy()\n",
    "        samples = samples.flatten()\n",
    "        \n",
    "        shift = int(len(samples) * 0.4)\n",
    "        random_shift =random.randint(0, shift)\n",
    "        data_roll = np.roll(samples, random_shift)\n",
    "        return data_roll\n",
    "    \n",
    "class SpecAugment():\n",
    "    def __call__(self, samples):\n",
    "        num_mask = 2\n",
    "        freq_masking_max_percentage=0.10\n",
    "        time_masking_max_percentage=0.10\n",
    "        spec = samples.copy()\n",
    "        mean_value = spec.mean()\n",
    "        for i in range(num_mask):\n",
    "            all_frames_num, all_freqs_num = spec.shape[1], spec.shape[1] \n",
    "            freq_percentage = random.uniform(0.0, freq_masking_max_percentage)\n",
    "\n",
    "            num_freqs_to_mask = int(freq_percentage * all_freqs_num)\n",
    "            f0 = np.random.uniform(low=0.0, high=all_freqs_num - num_freqs_to_mask)\n",
    "            f0 = int(f0)\n",
    "            spec[:, f0:f0 + num_freqs_to_mask] = mean_value\n",
    "\n",
    "            time_percentage = random.uniform(0.0, time_masking_max_percentage)\n",
    "\n",
    "            num_frames_to_mask = int(time_percentage * all_frames_num)\n",
    "            t0 = np.random.uniform(low=0.0, high=all_frames_num - num_frames_to_mask)\n",
    "            t0 = int(t0)\n",
    "            spec[t0:t0 + num_frames_to_mask, :] = mean_value\n",
    "        return spec\n",
    "\n",
    "aug = Compose([\n",
    "    TimeShifting(),\n",
    "    ToMelSpectrogram(),\n",
    "    SpecAugment(),\n",
    "    ToTensor()\n",
    "    ])\n",
    "\n",
    "transform = Compose([\n",
    "    ToMelSpectrogram(),\n",
    "    ToTensor()])\n",
    "        \n",
    "train_set = MyDataset(train_set, aug = aug)\n",
    "val_set = MyDataset(val_set, transform = transform)\n",
    "test_set = MyDataset(test_set, transform = transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set image (augmented vs non-augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax1.imshow(train_set[0][0][0], cmap='viridis')\n",
    "ax2.imshow(val_set[0][0][0], cmap='viridis')\n",
    "print(train_set[0][0][0].shape)\n",
    "ax1.grid(False)\n",
    "ax2.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of classes: 36\n"
     ]
    }
   ],
   "source": [
    "print(\"number of classes:\", len(np.unique(data_frame['Key'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoAtNet (Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stem(nn.Sequential):\n",
    "    def __init__(self, out_channels):\n",
    "        super().__init__(\n",
    "            nn.Conv2d(1, out_channels, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MBConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, expansion_factor=4):\n",
    "        super().__init__()\n",
    "        self.mb_conv = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.Conv2d(in_channels, in_channels * expansion_factor, kernel_size=1),\n",
    "            nn.BatchNorm2d(in_channels * expansion_factor),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(in_channels * expansion_factor, in_channels * expansion_factor, kernel_size=3, padding=1, groups=in_channels * expansion_factor),\n",
    "            nn.BatchNorm2d(in_channels * expansion_factor),\n",
    "            nn.GELU(),\n",
    "            SqueezeExcitation(in_channels * expansion_factor, in_channels, activation=nn.GELU),\n",
    "            nn.Conv2d(in_channels * expansion_factor, out_channels, kernel_size=1),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.mb_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownsamplingMBConv(MBConv):\n",
    "    def __init__(self, in_channels, out_channels, expansion_factor=4):\n",
    "        super().__init__(in_channels, out_channels, expansion_factor=4)\n",
    "        self.mb_conv[1] = nn.Conv2d(in_channels, in_channels * expansion_factor, kernel_size=1, stride = 2)\n",
    "        self.channel_projection = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.channel_projection(self.pool(x)) + self.mb_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelativeAttention2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, image_size, heads=8, head_size=32):\n",
    "        super().__init__()\n",
    "        heads = out_channels // head_size\n",
    "        self.heads = heads\n",
    "        self.head_size = head_size\n",
    "        self.image_size = image_size\n",
    "        self.head_dim = heads * head_size\n",
    "        self.attend = nn.Softmax(dim=-2) # Taken from My_CoAtNet\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.to_q = nn.Linear(in_channels, self.head_dim)\n",
    "        self.to_k = nn.Linear(in_channels, self.head_dim)\n",
    "        self.to_v = nn.Linear(in_channels, self.head_dim)\n",
    "        self.to_output = nn.Sequential(\n",
    "            nn.Linear(self.head_dim, out_channels),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.normalization = nn.LayerNorm(in_channels)\n",
    "        \n",
    "        self.relative_bias = nn.Parameter(torch.randn(heads, (2 * image_size - 1) * (2 * image_size - 1)))\n",
    "        self.register_buffer(\"relative_indices\", self.get_indices(image_size, image_size)) # Taken from My_CoAtNet\n",
    "        self.precomputed_relative_bias = None\n",
    "    \n",
    "    def norm(self, x):\n",
    "        x = x.transpose(1, -1) # Taken from My_CoAtNet\n",
    "        x = self.normalization(x)\n",
    "        x = x.transpose(-1, 1) # Taken from My_CoAtNet\n",
    "        return x\n",
    "    \n",
    "    def get_relative_biases(self):\n",
    "        # Relative bias caching mentioned in CoAtNet: Marrying Convolution and Attention for All Data Sizes\n",
    "        if not self.training:\n",
    "            return self.precomputed_relative_bias\n",
    "        # Taken from od My_CoAtNet\n",
    "        indices = self.relative_indices.expand(self.heads, -1)\n",
    "        rel_pos_enc = self.relative_bias.gather(-1, indices)\n",
    "        rel_pos_enc = rel_pos_enc.unflatten(-1, (self.image_size * self.image_size, self.image_size * self.image_size))\n",
    "        return rel_pos_enc\n",
    "    \n",
    "    def reshape_for_linear(self, x):\n",
    "        b, _, _, _ = x.shape\n",
    "        return x.reshape(b, self.image_size * self.image_size, self.in_channels)\n",
    "    \n",
    "    def attention_score(self, x):\n",
    "        b, _, h, _ = x.shape\n",
    "        q = self.to_q(self.reshape_for_linear(x)).view(b, self.heads, self.head_size, -1) # Taken from My_CoAtNet\n",
    "        k = self.to_k(self.reshape_for_linear(x)).view(b, self.heads, self.head_size, -1) # Taken from My_CoAtNet\n",
    "        dots = torch.matmul(k.transpose(-1, -2), q) / math.sqrt(self.head_dim)\n",
    "        relative_biases_indexed = self.get_relative_biases()\n",
    "        return self.attend(dots + relative_biases_indexed)\n",
    "    \n",
    "    def relative_attention(self, x):\n",
    "        b, _, _, _ = x.shape\n",
    "        v = self.to_v(self.reshape_for_linear(x)).view(b, self.heads, self.head_size, -1) # Taken from My_CoAtNet\n",
    "        out = torch.matmul(v, self.attention_score(x)) # I figured this out after debugging (Still the same as My_CoAtNet)\n",
    "        out = out.view(b, self.image_size, self.image_size, -1)\n",
    "        return self.to_output(out).view(b, self.out_channels, self.image_size, self.image_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.relative_attention(self.norm(x))\n",
    "    \n",
    "    def train(self, training):\n",
    "        if not training:\n",
    "            self.precomputed_relative_bias = self.get_relative_biases()\n",
    "        super().train(training)\n",
    "        \n",
    "    # Taken from My_CoAtNet\n",
    "    @staticmethod\n",
    "    def get_indices(h, w):\n",
    "        y = torch.arange(h, dtype=torch.long)\n",
    "        x = torch.arange(w, dtype=torch.long)\n",
    "        \n",
    "        y1, x1, y2, x2 = torch.meshgrid(y, x, y, x)\n",
    "        indices = (y1 - y2 + h - 1) * (2 * w - 1) + x1 - x2 + w - 1\n",
    "        indices = indices.flatten()\n",
    "        \n",
    "        return indices\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownsamplingRelativeAttention2d(RelativeAttention2d):\n",
    "    def __init__(self, in_channels, out_channels, image_size, heads=8, head_size=32):\n",
    "        super().__init__(in_channels, out_channels, image_size, heads=8, head_size=32)\n",
    "        self.channel_projection = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.normalization = nn.LayerNorm(in_channels)\n",
    "\n",
    "\n",
    "    def norm(self, x):\n",
    "        x = x.transpose(1, -1) # Taken from My_CoAtNet\n",
    "        x = self.normalization(x)\n",
    "        x = x.transpose(-1, 1) # Taken from My_CoAtNet\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.channel_projection(self.pool(x)) + self.relative_attention(self.pool(self.norm(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, out_channels, expansion_factor=4):\n",
    "        super().__init__()\n",
    "        hidden_dim = out_channels * expansion_factor\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(out_channels, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, out_channels),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.normalization = nn.LayerNorm(out_channels)\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    \n",
    "    def norm(self, x):\n",
    "        x = x.transpose(1, -1) # Taken from My_CoAtNet\n",
    "        x = self.normalization(x)\n",
    "        x = x.transpose(-1, 1) # Taken from My_CoAtNet\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        old_shape = x.shape\n",
    "        batch_size = old_shape[0]\n",
    "        return x + torch.reshape(self.ffn(torch.reshape(self.norm(x), (batch_size, -1, self.out_channels))), old_shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownsampleTransformerBlock(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels, image_size):\n",
    "        attention = DownsamplingRelativeAttention2d(in_channels, out_channels, image_size)\n",
    "        ffn = FeedForwardNetwork(out_channels)\n",
    "        super().__init__(\n",
    "            attention,\n",
    "            ffn\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels, image_size):\n",
    "        attention = RelativeAttention2d(in_channels, out_channels, image_size)\n",
    "        ffn = FeedForwardNetwork(out_channels)\n",
    "        super().__init__(\n",
    "            attention,\n",
    "            ffn\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(in_channels, num_classes)\n",
    "        self.in_channels = in_channels\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.pool(x)\n",
    "        x = torch.reshape(x, (batch_size, -1, self.in_channels))\n",
    "        return torch.squeeze(self.fc(x))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCoAtNet(nn.Sequential):\n",
    "    def __init__(self, nums_blocks, layer_out_channels, num_classes=36):\n",
    "        s0 = nn.Sequential(Stem(layer_out_channels[0]))\n",
    "        \n",
    "        s1 = [DownsamplingMBConv(layer_out_channels[0], layer_out_channels[1])]\n",
    "        for i in range(nums_blocks[1] - 1):\n",
    "            s1.append(MBConv(layer_out_channels[1], layer_out_channels[1]))\n",
    "        s1 = nn.Sequential(*s1)\n",
    "        \n",
    "        s2 = [DownsamplingMBConv(layer_out_channels[1], layer_out_channels[2])]\n",
    "        for i in range(nums_blocks[2] - 1):\n",
    "            s2.append(MBConv(layer_out_channels[2], layer_out_channels[2]))\n",
    "        s2 = nn.Sequential(*s2)\n",
    "        \n",
    "        s3 = [DownsampleTransformerBlock(layer_out_channels[2], layer_out_channels[3], 64 // 16)]\n",
    "        for i in range(nums_blocks[3] - 1):\n",
    "            s3.append(TransformerBlock(layer_out_channels[3], layer_out_channels[3], 64 // 16))\n",
    "        s3 = nn.Sequential(*s3)\n",
    "        \n",
    "        s4 = [DownsampleTransformerBlock(layer_out_channels[3], layer_out_channels[4], 64 // 32)]\n",
    "        for i in range(nums_blocks[4] - 1):\n",
    "            s4.append(TransformerBlock(layer_out_channels[4], layer_out_channels[4], 64 // 32))\n",
    "        s4 = nn.Sequential(*s4)\n",
    "        \n",
    "        head = Head(layer_out_channels[4], num_classes)\n",
    "        \n",
    "        super().__init__(\n",
    "            s0,\n",
    "            s1,\n",
    "            s2,\n",
    "            s3,\n",
    "            s4,\n",
    "            head\n",
    "        )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\miniconda3\\Lib\\site-packages\\torch\\functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# CoAtNet-1\n",
    "nums_blocks = [2, 2, 3, 5, 2]           # L\n",
    "channels = [64, 96, 192, 384, 768]      # D\n",
    "\n",
    "model = MyCoAtNet(nums_blocks, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_linear(m):\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "        if m.bias is not None: nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 24,033,296\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]             640\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "              GELU-3           [-1, 64, 32, 32]               0\n",
      "            Conv2d-4           [-1, 64, 30, 30]          36,928\n",
      "         MaxPool2d-5           [-1, 64, 15, 15]               0\n",
      "            Conv2d-6           [-1, 96, 15, 15]           6,144\n",
      "       BatchNorm2d-7           [-1, 64, 30, 30]             128\n",
      "            Conv2d-8          [-1, 256, 15, 15]          16,640\n",
      "       BatchNorm2d-9          [-1, 256, 15, 15]             512\n",
      "             GELU-10          [-1, 256, 15, 15]               0\n",
      "           Conv2d-11          [-1, 256, 15, 15]           2,560\n",
      "      BatchNorm2d-12          [-1, 256, 15, 15]             512\n",
      "             GELU-13          [-1, 256, 15, 15]               0\n",
      "AdaptiveAvgPool2d-14            [-1, 256, 1, 1]               0\n",
      "           Conv2d-15             [-1, 64, 1, 1]          16,448\n",
      "             GELU-16             [-1, 64, 1, 1]               0\n",
      "           Conv2d-17            [-1, 256, 1, 1]          16,640\n",
      "          Sigmoid-18            [-1, 256, 1, 1]               0\n",
      "SqueezeExcitation-19          [-1, 256, 15, 15]               0\n",
      "           Conv2d-20           [-1, 96, 15, 15]          24,672\n",
      "      BatchNorm2d-21           [-1, 96, 15, 15]             192\n",
      "DownsamplingMBConv-22           [-1, 96, 15, 15]               0\n",
      "      BatchNorm2d-23           [-1, 96, 15, 15]             192\n",
      "           Conv2d-24          [-1, 384, 15, 15]          37,248\n",
      "      BatchNorm2d-25          [-1, 384, 15, 15]             768\n",
      "             GELU-26          [-1, 384, 15, 15]               0\n",
      "           Conv2d-27          [-1, 384, 15, 15]           3,840\n",
      "      BatchNorm2d-28          [-1, 384, 15, 15]             768\n",
      "             GELU-29          [-1, 384, 15, 15]               0\n",
      "AdaptiveAvgPool2d-30            [-1, 384, 1, 1]               0\n",
      "           Conv2d-31             [-1, 96, 1, 1]          36,960\n",
      "             GELU-32             [-1, 96, 1, 1]               0\n",
      "           Conv2d-33            [-1, 384, 1, 1]          37,248\n",
      "          Sigmoid-34            [-1, 384, 1, 1]               0\n",
      "SqueezeExcitation-35          [-1, 384, 15, 15]               0\n",
      "           Conv2d-36           [-1, 96, 15, 15]          36,960\n",
      "      BatchNorm2d-37           [-1, 96, 15, 15]             192\n",
      "           MBConv-38           [-1, 96, 15, 15]               0\n",
      "        MaxPool2d-39             [-1, 96, 8, 8]               0\n",
      "           Conv2d-40            [-1, 192, 8, 8]          18,432\n",
      "      BatchNorm2d-41           [-1, 96, 15, 15]             192\n",
      "           Conv2d-42            [-1, 384, 8, 8]          37,248\n",
      "      BatchNorm2d-43            [-1, 384, 8, 8]             768\n",
      "             GELU-44            [-1, 384, 8, 8]               0\n",
      "           Conv2d-45            [-1, 384, 8, 8]           3,840\n",
      "      BatchNorm2d-46            [-1, 384, 8, 8]             768\n",
      "             GELU-47            [-1, 384, 8, 8]               0\n",
      "AdaptiveAvgPool2d-48            [-1, 384, 1, 1]               0\n",
      "           Conv2d-49             [-1, 96, 1, 1]          36,960\n",
      "             GELU-50             [-1, 96, 1, 1]               0\n",
      "           Conv2d-51            [-1, 384, 1, 1]          37,248\n",
      "          Sigmoid-52            [-1, 384, 1, 1]               0\n",
      "SqueezeExcitation-53            [-1, 384, 8, 8]               0\n",
      "           Conv2d-54            [-1, 192, 8, 8]          73,920\n",
      "      BatchNorm2d-55            [-1, 192, 8, 8]             384\n",
      "DownsamplingMBConv-56            [-1, 192, 8, 8]               0\n",
      "      BatchNorm2d-57            [-1, 192, 8, 8]             384\n",
      "           Conv2d-58            [-1, 768, 8, 8]         148,224\n",
      "      BatchNorm2d-59            [-1, 768, 8, 8]           1,536\n",
      "             GELU-60            [-1, 768, 8, 8]               0\n",
      "           Conv2d-61            [-1, 768, 8, 8]           7,680\n",
      "      BatchNorm2d-62            [-1, 768, 8, 8]           1,536\n",
      "             GELU-63            [-1, 768, 8, 8]               0\n",
      "AdaptiveAvgPool2d-64            [-1, 768, 1, 1]               0\n",
      "           Conv2d-65            [-1, 192, 1, 1]         147,648\n",
      "             GELU-66            [-1, 192, 1, 1]               0\n",
      "           Conv2d-67            [-1, 768, 1, 1]         148,224\n",
      "          Sigmoid-68            [-1, 768, 1, 1]               0\n",
      "SqueezeExcitation-69            [-1, 768, 8, 8]               0\n",
      "           Conv2d-70            [-1, 192, 8, 8]         147,648\n",
      "      BatchNorm2d-71            [-1, 192, 8, 8]             384\n",
      "           MBConv-72            [-1, 192, 8, 8]               0\n",
      "      BatchNorm2d-73            [-1, 192, 8, 8]             384\n",
      "           Conv2d-74            [-1, 768, 8, 8]         148,224\n",
      "      BatchNorm2d-75            [-1, 768, 8, 8]           1,536\n",
      "             GELU-76            [-1, 768, 8, 8]               0\n",
      "           Conv2d-77            [-1, 768, 8, 8]           7,680\n",
      "      BatchNorm2d-78            [-1, 768, 8, 8]           1,536\n",
      "             GELU-79            [-1, 768, 8, 8]               0\n",
      "AdaptiveAvgPool2d-80            [-1, 768, 1, 1]               0\n",
      "           Conv2d-81            [-1, 192, 1, 1]         147,648\n",
      "             GELU-82            [-1, 192, 1, 1]               0\n",
      "           Conv2d-83            [-1, 768, 1, 1]         148,224\n",
      "          Sigmoid-84            [-1, 768, 1, 1]               0\n",
      "SqueezeExcitation-85            [-1, 768, 8, 8]               0\n",
      "           Conv2d-86            [-1, 192, 8, 8]         147,648\n",
      "      BatchNorm2d-87            [-1, 192, 8, 8]             384\n",
      "           MBConv-88            [-1, 192, 8, 8]               0\n",
      "        MaxPool2d-89            [-1, 192, 4, 4]               0\n",
      "           Conv2d-90            [-1, 384, 4, 4]          73,728\n",
      "        LayerNorm-91            [-1, 8, 8, 192]             384\n",
      "        MaxPool2d-92            [-1, 192, 4, 4]               0\n",
      "           Linear-93              [-1, 16, 384]          74,112\n",
      "           Linear-94              [-1, 16, 384]          74,112\n",
      "           Linear-95              [-1, 16, 384]          74,112\n",
      "          Softmax-96           [-1, 12, 16, 16]               0\n",
      "           Linear-97            [-1, 4, 4, 384]         147,840\n",
      "          Dropout-98            [-1, 4, 4, 384]               0\n",
      "DownsamplingRelativeAttention2d-99            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-100            [-1, 4, 4, 384]             768\n",
      "          Linear-101             [-1, 16, 1536]         591,360\n",
      "            GELU-102             [-1, 16, 1536]               0\n",
      "         Dropout-103             [-1, 16, 1536]               0\n",
      "          Linear-104              [-1, 16, 384]         590,208\n",
      "         Dropout-105              [-1, 16, 384]               0\n",
      "FeedForwardNetwork-106            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-107            [-1, 4, 4, 384]             768\n",
      "          Linear-108              [-1, 16, 384]         147,840\n",
      "          Linear-109              [-1, 16, 384]         147,840\n",
      "          Linear-110              [-1, 16, 384]         147,840\n",
      "         Softmax-111           [-1, 12, 16, 16]               0\n",
      "          Linear-112            [-1, 4, 4, 384]         147,840\n",
      "         Dropout-113            [-1, 4, 4, 384]               0\n",
      "RelativeAttention2d-114            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-115            [-1, 4, 4, 384]             768\n",
      "          Linear-116             [-1, 16, 1536]         591,360\n",
      "            GELU-117             [-1, 16, 1536]               0\n",
      "         Dropout-118             [-1, 16, 1536]               0\n",
      "          Linear-119              [-1, 16, 384]         590,208\n",
      "         Dropout-120              [-1, 16, 384]               0\n",
      "FeedForwardNetwork-121            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-122            [-1, 4, 4, 384]             768\n",
      "          Linear-123              [-1, 16, 384]         147,840\n",
      "          Linear-124              [-1, 16, 384]         147,840\n",
      "          Linear-125              [-1, 16, 384]         147,840\n",
      "         Softmax-126           [-1, 12, 16, 16]               0\n",
      "          Linear-127            [-1, 4, 4, 384]         147,840\n",
      "         Dropout-128            [-1, 4, 4, 384]               0\n",
      "RelativeAttention2d-129            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-130            [-1, 4, 4, 384]             768\n",
      "          Linear-131             [-1, 16, 1536]         591,360\n",
      "            GELU-132             [-1, 16, 1536]               0\n",
      "         Dropout-133             [-1, 16, 1536]               0\n",
      "          Linear-134              [-1, 16, 384]         590,208\n",
      "         Dropout-135              [-1, 16, 384]               0\n",
      "FeedForwardNetwork-136            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-137            [-1, 4, 4, 384]             768\n",
      "          Linear-138              [-1, 16, 384]         147,840\n",
      "          Linear-139              [-1, 16, 384]         147,840\n",
      "          Linear-140              [-1, 16, 384]         147,840\n",
      "         Softmax-141           [-1, 12, 16, 16]               0\n",
      "          Linear-142            [-1, 4, 4, 384]         147,840\n",
      "         Dropout-143            [-1, 4, 4, 384]               0\n",
      "RelativeAttention2d-144            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-145            [-1, 4, 4, 384]             768\n",
      "          Linear-146             [-1, 16, 1536]         591,360\n",
      "            GELU-147             [-1, 16, 1536]               0\n",
      "         Dropout-148             [-1, 16, 1536]               0\n",
      "          Linear-149              [-1, 16, 384]         590,208\n",
      "         Dropout-150              [-1, 16, 384]               0\n",
      "FeedForwardNetwork-151            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-152            [-1, 4, 4, 384]             768\n",
      "          Linear-153              [-1, 16, 384]         147,840\n",
      "          Linear-154              [-1, 16, 384]         147,840\n",
      "          Linear-155              [-1, 16, 384]         147,840\n",
      "         Softmax-156           [-1, 12, 16, 16]               0\n",
      "          Linear-157            [-1, 4, 4, 384]         147,840\n",
      "         Dropout-158            [-1, 4, 4, 384]               0\n",
      "RelativeAttention2d-159            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-160            [-1, 4, 4, 384]             768\n",
      "          Linear-161             [-1, 16, 1536]         591,360\n",
      "            GELU-162             [-1, 16, 1536]               0\n",
      "         Dropout-163             [-1, 16, 1536]               0\n",
      "          Linear-164              [-1, 16, 384]         590,208\n",
      "         Dropout-165              [-1, 16, 384]               0\n",
      "FeedForwardNetwork-166            [-1, 384, 4, 4]               0\n",
      "       MaxPool2d-167            [-1, 384, 2, 2]               0\n",
      "          Conv2d-168            [-1, 768, 2, 2]         294,912\n",
      "       LayerNorm-169            [-1, 4, 4, 384]             768\n",
      "       MaxPool2d-170            [-1, 384, 2, 2]               0\n",
      "          Linear-171               [-1, 4, 768]         295,680\n",
      "          Linear-172               [-1, 4, 768]         295,680\n",
      "          Linear-173               [-1, 4, 768]         295,680\n",
      "         Softmax-174             [-1, 24, 4, 4]               0\n",
      "          Linear-175            [-1, 2, 2, 768]         590,592\n",
      "         Dropout-176            [-1, 2, 2, 768]               0\n",
      "DownsamplingRelativeAttention2d-177            [-1, 768, 2, 2]               0\n",
      "       LayerNorm-178            [-1, 2, 2, 768]           1,536\n",
      "          Linear-179              [-1, 4, 3072]       2,362,368\n",
      "            GELU-180              [-1, 4, 3072]               0\n",
      "         Dropout-181              [-1, 4, 3072]               0\n",
      "          Linear-182               [-1, 4, 768]       2,360,064\n",
      "         Dropout-183               [-1, 4, 768]               0\n",
      "FeedForwardNetwork-184            [-1, 768, 2, 2]               0\n",
      "       LayerNorm-185            [-1, 2, 2, 768]           1,536\n",
      "          Linear-186               [-1, 4, 768]         590,592\n",
      "          Linear-187               [-1, 4, 768]         590,592\n",
      "          Linear-188               [-1, 4, 768]         590,592\n",
      "         Softmax-189             [-1, 24, 4, 4]               0\n",
      "          Linear-190            [-1, 2, 2, 768]         590,592\n",
      "         Dropout-191            [-1, 2, 2, 768]               0\n",
      "RelativeAttention2d-192            [-1, 768, 2, 2]               0\n",
      "       LayerNorm-193            [-1, 2, 2, 768]           1,536\n",
      "          Linear-194              [-1, 4, 3072]       2,362,368\n",
      "            GELU-195              [-1, 4, 3072]               0\n",
      "         Dropout-196              [-1, 4, 3072]               0\n",
      "          Linear-197               [-1, 4, 768]       2,360,064\n",
      "         Dropout-198               [-1, 4, 768]               0\n",
      "FeedForwardNetwork-199            [-1, 768, 2, 2]               0\n",
      "AdaptiveAvgPool2d-200            [-1, 768, 1, 1]               0\n",
      "          Linear-201                [-1, 1, 36]          27,684\n",
      "            Head-202                   [-1, 36]               0\n",
      "================================================================\n",
      "Total params: 24,029,924\n",
      "Trainable params: 24,029,924\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 26.27\n",
      "Params size (MB): 91.67\n",
      "Estimated Total Size (MB): 117.96\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model.apply(init_linear)\n",
    "model.to(device)\n",
    "\n",
    "print(\"Number of parameters: {:,}\".format(sum(p.numel() for p in model.parameters())))\n",
    "\n",
    "summary(model, input_size=(1, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyCoAtNet(\n",
       "  (0): Sequential(\n",
       "    (0): Stem(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): DownsamplingMBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (channel_projection): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "        (5): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): DownsamplingMBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(96, 384, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "        (5): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (channel_projection): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        (5): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        (5): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): DownsampleTransformerBlock(\n",
       "      (0): DownsamplingRelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (channel_projection): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): DownsampleTransformerBlock(\n",
       "      (0): DownsamplingRelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (channel_projection): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (5): Head(\n",
       "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (fc): Linear(in_features=768, out_features=36, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model.load_state_dict(torch.load(\"CoAtNet-1-Best-Zoom.pkl\"))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_set,\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from My_CoAtNet\n",
    "def separate_parameters(model):\n",
    "    parameters_decay = set()\n",
    "    parameters_no_decay = set()\n",
    "    modules_weight_decay = (nn.Linear, nn.Conv2d)\n",
    "    modules_no_weight_decay = (nn.LayerNorm, nn.BatchNorm2d)\n",
    "    \n",
    "    for m_name, m in model.named_modules():\n",
    "        for param_name, param in m.named_parameters():\n",
    "            full_param_name = f\"{m_name}.{param_name}\" if m_name else param_name\n",
    "\n",
    "            if isinstance(m, modules_no_weight_decay):\n",
    "                parameters_no_decay.add(full_param_name)\n",
    "            elif param_name.endswith(\"bias\"):\n",
    "                parameters_no_decay.add(full_param_name)\n",
    "            elif isinstance(m, modules_weight_decay):\n",
    "                parameters_decay.add(full_param_name)\n",
    "    \n",
    "    # sanity check\n",
    "    assert len(parameters_decay & parameters_no_decay) == 0\n",
    "    assert len(parameters_decay) + len(parameters_no_decay) == len(list(model.parameters()))\n",
    "\n",
    "    return parameters_decay, parameters_no_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 5e-4\n",
    "weight_decay = 0.1\n",
    "num_epochs = 1100\n",
    "min_learning_rate = 1e-6\n",
    "\n",
    "param_dict = {pn: p for pn, p in model.named_parameters()}\n",
    "parameters_decay, parameters_no_decay = separate_parameters(model)\n",
    "parameter_groups = [\n",
    "    {\"params\": [param_dict[pn] for pn in parameters_decay], \"weight_decay\": weight_decay},\n",
    "    {\"params\": [param_dict[pn] for pn in parameters_no_decay], \"weight_decay\": 0.0},\n",
    "]\n",
    "optimizer = torch.optim.Adam(parameter_groups, lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=min_learning_rate / learning_rate, total_iters=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from My_CoAtNet\n",
    "def plot_results(train_losses, train_accuracies, val_losses, val_accuracies):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title(\"Loss\")\n",
    "    plt.plot(train_losses)\n",
    "    plt.plot(val_losses)\n",
    "    plt.legend([\"Training loss\", \"Validation loss\"], loc =  \"best\")\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.plot(train_accuracies)\n",
    "    plt.plot(val_accuracies)\n",
    "    plt.legend([\"Training accuracy\", \"Validation accuracy\"], loc =  \"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = \"CoAtNet-1-Best-Zoom.pkl\"\n",
    "model_path = \"CoAtNet-1-Zoom.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyCoAtNet(\n",
       "  (0): Sequential(\n",
       "    (0): Stem(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): DownsamplingMBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (channel_projection): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "        (5): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): DownsamplingMBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(96, 384, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "        (5): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (channel_projection): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        (5): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        (5): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): DownsampleTransformerBlock(\n",
       "      (0): DownsamplingRelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (channel_projection): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): DownsampleTransformerBlock(\n",
       "      (0): DownsamplingRelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (channel_projection): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (5): Head(\n",
       "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (fc): Linear(in_features=768, out_features=36, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mappings from indices to syllables and vice versa\n",
    "digits_and_syllables = list('0123456789abcdefghijklmnopqrstuvwxyz')\n",
    "idx_to_syllable = {idx: syllable for idx, syllable in enumerate(digits_and_syllables)}\n",
    "syllable_to_idx = {syllable: idx for idx, syllable in idx_to_syllable.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine test and validation datasets\n",
    "combined_dataset = ConcatDataset([val_set, test_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from syllables to dataset indices\n",
    "syllable_to_indices = {}\n",
    "for idx in range(len(combined_dataset)):\n",
    "    _, label = combined_dataset[idx]\n",
    "    # label = label.item() \n",
    "    syllable = idx_to_syllable[label]\n",
    "    if syllable not in syllable_to_indices:\n",
    "        syllable_to_indices[syllable] = []\n",
    "    syllable_to_indices[syllable].append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process sentences into syllables\n",
    "def get_syllables(sentence):\n",
    "    sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "    # sentence = sentence.replace(' ',  '').lower()\n",
    "    syllables = list(sentence)\n",
    "    return syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 1000\n"
     ]
    }
   ],
   "source": [
    "# Read sentences from the text file\n",
    "with open('../sentences/sentences.txt', 'r') as f:\n",
    "    sentences = f.readlines()\n",
    "\n",
    "print(\"Number of sentences:\", len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "\n",
    "def compute_accuracy_and_wrong_syllables(true_sentence, predicted_sentence):\n",
    "    # Character-level accuracy using SequenceMatcher\n",
    "    char_matcher = difflib.SequenceMatcher(None, true_sentence, predicted_sentence)\n",
    "    accuracy = char_matcher.ratio()\n",
    "    \n",
    "    # Word-level wrong syllable count using SequenceMatcher on word lists\n",
    "    true_words = true_sentence.split()\n",
    "    predicted_words = predicted_sentence.split()\n",
    "    word_matcher = difflib.SequenceMatcher(None, true_words, predicted_words)\n",
    "    \n",
    "    # Calculate wrong syllables based on insert, delete, and replace operations\n",
    "    wrong_syllables = sum(1 for tag, _, _, _, _ in word_matcher.get_opcodes() if tag in ('insert', 'delete', 'replace'))\n",
    "    \n",
    "    return accuracy, wrong_syllables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:13<00:00,  1.32s/it]\n"
     ]
    }
   ],
   "source": [
    "# Process each sentence\n",
    "noise_factor = 0\n",
    "results = []\n",
    "\n",
    "for sentence in tqdm(sentences[:10]):\n",
    "    sentence = sentence.strip()\n",
    "    syllables = get_syllables(sentence)\n",
    "    true_sentence = ''.join(syllables)\n",
    "    predicted_syllables = []\n",
    "\n",
    "    for syllable in syllables:\n",
    "        if syllable in syllable_to_indices:\n",
    "            # Randomly select an index for the syllable\n",
    "            idx = random.choice(syllable_to_indices[syllable])\n",
    "            # Retrieve the image and label from the dataset\n",
    "            image, _ = combined_dataset[idx]\n",
    "\n",
    "            noise = torch.randn_like(image) * noise_factor\n",
    "            image = image + noise\n",
    "            image = image.unsqueeze(0).to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(image)\n",
    "                output = output.reshape(1, -1)\n",
    "                _, predicted_idx = torch.max(output.data, 1)\n",
    "                predicted_syllable = idx_to_syllable[predicted_idx.item()]\n",
    "        else:\n",
    "            if random.random() < 0.90:\n",
    "                predicted_syllable = ' '\n",
    "            else:\n",
    "                predicted_syllable = random.choice(digits_and_syllables)\n",
    "        predicted_syllables.append(predicted_syllable)\n",
    "    \n",
    "    predicted_sentence = ''.join(predicted_syllables)\n",
    "    accuracy, wrong_syllables = compute_accuracy_and_wrong_syllables(true_sentence, predicted_sentence)\n",
    "    results.append([true_sentence, predicted_sentence, accuracy, wrong_syllables])\n",
    "    # print(f\"accuracy: {accuracy}, wrong: {wrong_syllables}, true: {true_sentence}, predicted: {predicted_sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise factor: 0\n",
      "Average accuracy: 0.2825\n",
      "Total wrong syllables: 12\n"
     ]
    }
   ],
   "source": [
    "# accuracy average and wrong syllables sum\n",
    "accuracy_avg = sum(result[2] for result in results) / len(results)\n",
    "wrong_syllables_sum = sum(result[3] for result in results)\n",
    "\n",
    "print(\"Noise factor:\", noise_factor)\n",
    "print(f\"Average accuracy: {accuracy_avg:.4f}\")\n",
    "print(f\"Total wrong syllables: {wrong_syllables_sum}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Noise level: 1\n",
    "- Average accuracy: 0.9776\n",
    "- Total wrong syllables: 1355\n",
    "---\n",
    "- Noise factor: 5\n",
    "- Average accuracy: 0.8453\n",
    "- Total wrong syllables: 2878\n",
    "---\n",
    "- Noise factor: 6\n",
    "- Average accuracy: 0.7241\n",
    "- Total wrong syllables: 2257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results/{noise_factor}.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['True Sentence', 'Predicted Sentence', 'Accuracy', 'Wrong syllables'])\n",
    "    for row in results:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
