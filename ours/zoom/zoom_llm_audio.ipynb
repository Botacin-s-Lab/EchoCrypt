{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import librosa\n",
    "import os\n",
    "import random\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math\n",
    "import torchaudio\n",
    "import csv\n",
    "import string\n",
    "\n",
    "from torch.utils.data import ConcatDataset\n",
    "from torchaudio.transforms import TimeMasking, FrequencyMasking\n",
    "from torchvision.ops import SqueezeExcitation\n",
    "from torchinfo import summary\n",
    "from torchsummary import summary\n",
    "from torchvision.ops import SqueezeExcitation\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from collections import defaultdict\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from scipy.io import wavfile\n",
    "from functools import reduce\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_s = '0123456789abcdefghijklmnopqrstuvwxyz'\n",
    "labels = list(keys_s)\n",
    "keys = [k + '.wav' for k in labels]\n",
    "data_dict = {'Key':[], 'File':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# def add_noise_to_stroke(stroke, noise_factor=None):\n",
    "#     # print(stroke.shape)\n",
    "#     noise = torch.randn_like(stroke)\n",
    "#     return stroke + noise_factor * noise\n",
    "\n",
    "def add_noise_to_stroke(stroke, noise_factor=None):\n",
    "    \"\"\"\n",
    "    Adds random noise to an audio stroke tensor.\n",
    "    \n",
    "    Args:\n",
    "    - stroke (torch.Tensor): The input audio stroke tensor.\n",
    "    - noise_factor (float): The factor determining the noise level relative to the stroke's signal.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: The noisy audio stroke tensor.\n",
    "    \"\"\"\n",
    "    # Generate random noise\n",
    "    noise = torch.randn(stroke.size()) * noise_factor\n",
    "\n",
    "    # Calculate the standard deviation of the stroke signal\n",
    "    std_dev = stroke.std()\n",
    "\n",
    "    # Scale the noise level based on the signal's standard deviation\n",
    "    noise = noise * std_dev\n",
    "\n",
    "    # Add noise to the original stroke\n",
    "    noisy_stroke = stroke + noise\n",
    "    \n",
    "    return noisy_stroke\n",
    "\n",
    "def isolator(signal, sample_rate, size, scan, before, after, threshold, show=False):\n",
    "    strokes = []\n",
    "    if show:\n",
    "        plt.figure(figsize=(7, 2))\n",
    "        librosa.display.waveshow(signal, sr=sample_rate)\n",
    "    fft = librosa.stft(signal, n_fft=size, hop_length=scan)\n",
    "    energy = np.abs(np.sum(fft, axis=0)).astype(float)\n",
    "    if show:\n",
    "        plt.figure(figsize=(7, 2))\n",
    "        librosa.display.waveshow(energy)\n",
    "    threshed = energy > threshold\n",
    "    if show:\n",
    "        plt.figure(figsize=(7, 2))\n",
    "        librosa.display.waveshow(threshed.astype(float))\n",
    "    peaks = np.where(threshed)[0]\n",
    "    peak_count = len(peaks)\n",
    "    prev_end = sample_rate * 0.1 * (-1)\n",
    "    for i in range(peak_count):\n",
    "        this_peak = peaks[i]\n",
    "        timestamp = (this_peak * scan) + size // 2\n",
    "        if timestamp > prev_end + (0.1 * sample_rate):\n",
    "            keystroke = signal[timestamp - before:timestamp + after]\n",
    "            strokes.append(torch.tensor(keystroke)[None, :])\n",
    "            if show:\n",
    "                plt.figure(figsize=(7, 2))\n",
    "                librosa.display.waveshow(keystroke, sr=sample_rate)\n",
    "            prev_end = timestamp + after\n",
    "    return strokes\n",
    "\n",
    "def convert_to_df_with_noise(audio_dir, noise_factor=None):\n",
    "    \"\"\"\n",
    "    Processes each audio file by isolating strokes, adds noise to each stroke,\n",
    "    and stores the strokes with labels in a dataframe.\n",
    "    \"\"\"\n",
    "    # Generate a list of .wav files in the provided directory\n",
    "    keys = sorted([f for f in os.listdir(audio_dir) if f.endswith('.wav')])\n",
    "    \n",
    "    data_dict = {'Key': [], 'File': []}\n",
    "    \n",
    "    # If your labels are inferred from file names, you can extract them here.\n",
    "    # For example, if the file is 'a.wav', you might want to use 'a' as the label.\n",
    "    def extract_label(filename):\n",
    "        base = os.path.splitext(filename)[0]\n",
    "        return base  # or apply any mapping you need\n",
    "\n",
    "    for file in keys:\n",
    "        loc = os.path.join(audio_dir, file)\n",
    "        samples, sample_rate = librosa.load(loc, sr=None)\n",
    "        strokes = []\n",
    "        prom = 0.06\n",
    "        step = 0.005\n",
    "        # Adjust threshold until we get exactly 25 strokes (or break if not possible)\n",
    "        while not len(strokes) == 25:\n",
    "            strokes = isolator(samples[1 * sample_rate:], sample_rate, 48, 24, 2400, 12000, prom, show=False)\n",
    "            if len(strokes) < 25:\n",
    "                prom -= step\n",
    "            elif len(strokes) > 25:\n",
    "                prom += step\n",
    "            if prom <= 0:\n",
    "                print('-- not possible for:', file)\n",
    "                break\n",
    "            step *= 0.99\n",
    "        \n",
    "        # Apply noise to each extracted stroke\n",
    "        noisy_strokes = [add_noise_to_stroke(stroke, noise_factor) for stroke in strokes]\n",
    "\n",
    "        # Extract a label for this file (modify as needed)\n",
    "        label = extract_label(file)\n",
    "        data_dict['Key'] += [label] * len(noisy_strokes)\n",
    "        data_dict['File'] += noisy_strokes\n",
    "\n",
    "    df = pd.DataFrame(data_dict)\n",
    "    \n",
    "    # Optionally, create a mapping for the labels (if needed)\n",
    "    mapper = {}\n",
    "    counter = 0\n",
    "    for l in df['Key']:\n",
    "        if l not in mapper:\n",
    "            mapper[l] = counter\n",
    "            counter += 1\n",
    "    df.replace({'Key': mapper}, inplace=True)\n",
    "    \n",
    "    return df, sample_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Key                                               File\n",
      "0   0  [[tensor(-0.0013), tensor(-0.0023), tensor(0.0...\n",
      "1   0  [[tensor(0.0036), tensor(-0.0039), tensor(0.00...\n",
      "2   0  [[tensor(0.0022), tensor(0.0002), tensor(-0.00...\n",
      "3   0  [[tensor(-0.0009), tensor(0.0004), tensor(-0.0...\n",
      "4   0  [[tensor(-0.0014), tensor(-5.0908e-05), tensor...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 900 entries, 0 to 899\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Key     900 non-null    object\n",
      " 1   File    900 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 14.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data_frame, sr = convert_to_df_with_noise(\"../../dataset/Zoom/\", noise_factor=1.0)\n",
    "\n",
    "print(data_frame.head())\n",
    "print(data_frame.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample rate: 32000\n",
      "630 180 90\n"
     ]
    }
   ],
   "source": [
    "train_set, tmp_set = train_test_split(data_frame, test_size=0.3, stratify=data_frame['Key'])\n",
    "val_set, test_set = train_test_split(tmp_set, test_size=0.33, stratify=tmp_set['Key'])\n",
    "\n",
    "print(\"Sample rate:\", sr)\n",
    "print(len(train_set), len(val_set), len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, file_name, transform = None, aug = None):\n",
    "        df = file_name\n",
    "        self.transform = transform\n",
    "        self.aug = aug\n",
    "        self.labels = df['Key']\n",
    "        self.values = df['File']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, index):\n",
    "        label = self.labels.iloc[index]\n",
    "        value = self.values.iloc[index]\n",
    "        waveform = self.values.iloc[index]\n",
    "        label = self.labels.iloc[index]\n",
    "        if self.transform:\n",
    "            waveform = waveform.numpy()\n",
    "            waveform = waveform.flatten()\n",
    "            waveform = self.transform(waveform)\n",
    "        if self.aug:\n",
    "            waveform = self.aug(waveform)\n",
    "        return waveform, label\n",
    "\n",
    "class ToMelSpectrogram:\n",
    "    def __call__(self, samples):\n",
    "#         samples = np.array(samples)\n",
    "        spec = librosa.feature.melspectrogram(y = samples, sr = sr, n_mels=64, n_fft=2048, win_length=1024, hop_length=226)\n",
    "        return librosa.power_to_db(spec)\n",
    "\n",
    "class TimeShifting():\n",
    "    def __call__(self, samples):\n",
    "        samples = samples.numpy()\n",
    "        samples = samples.flatten()\n",
    "        \n",
    "        shift = int(len(samples) * 0.4)\n",
    "        random_shift =random.randint(0, shift)\n",
    "        data_roll = np.roll(samples, random_shift)\n",
    "        return data_roll\n",
    "    \n",
    "class SpecAugment():\n",
    "    def __call__(self, samples):\n",
    "        num_mask = 2\n",
    "        freq_masking_max_percentage=0.10\n",
    "        time_masking_max_percentage=0.10\n",
    "        spec = samples.copy()\n",
    "        mean_value = spec.mean()\n",
    "        for i in range(num_mask):\n",
    "            all_frames_num, all_freqs_num = spec.shape[1], spec.shape[1] \n",
    "            freq_percentage = random.uniform(0.0, freq_masking_max_percentage)\n",
    "\n",
    "            num_freqs_to_mask = int(freq_percentage * all_freqs_num)\n",
    "            f0 = np.random.uniform(low=0.0, high=all_freqs_num - num_freqs_to_mask)\n",
    "            f0 = int(f0)\n",
    "            spec[:, f0:f0 + num_freqs_to_mask] = mean_value\n",
    "\n",
    "            time_percentage = random.uniform(0.0, time_masking_max_percentage)\n",
    "\n",
    "            num_frames_to_mask = int(time_percentage * all_frames_num)\n",
    "            t0 = np.random.uniform(low=0.0, high=all_frames_num - num_frames_to_mask)\n",
    "            t0 = int(t0)\n",
    "            spec[t0:t0 + num_frames_to_mask, :] = mean_value\n",
    "        return spec\n",
    "\n",
    "aug = Compose([\n",
    "    TimeShifting(),\n",
    "    ToMelSpectrogram(),\n",
    "    SpecAugment(),\n",
    "    ToTensor()\n",
    "    ])\n",
    "\n",
    "transform = Compose([\n",
    "    ToMelSpectrogram(),\n",
    "    ToTensor()])\n",
    "        \n",
    "train_set = MyDataset(train_set, aug = aug)\n",
    "val_set = MyDataset(val_set, transform = transform)\n",
    "test_set = MyDataset(test_set, transform = transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set image (augmented vs non-augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax1.imshow(train_set[0][0][0], cmap='viridis')\n",
    "ax2.imshow(val_set[0][0][0], cmap='viridis')\n",
    "print(train_set[0][0][0].shape)\n",
    "ax1.grid(False)\n",
    "ax2.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of classes: 36\n"
     ]
    }
   ],
   "source": [
    "print(\"number of classes:\", len(np.unique(data_frame['Key'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoAtNet (Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stem(nn.Sequential):\n",
    "    def __init__(self, out_channels):\n",
    "        super().__init__(\n",
    "            nn.Conv2d(1, out_channels, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MBConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, expansion_factor=4):\n",
    "        super().__init__()\n",
    "        self.mb_conv = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.Conv2d(in_channels, in_channels * expansion_factor, kernel_size=1),\n",
    "            nn.BatchNorm2d(in_channels * expansion_factor),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(in_channels * expansion_factor, in_channels * expansion_factor, kernel_size=3, padding=1, groups=in_channels * expansion_factor),\n",
    "            nn.BatchNorm2d(in_channels * expansion_factor),\n",
    "            nn.GELU(),\n",
    "            SqueezeExcitation(in_channels * expansion_factor, in_channels, activation=nn.GELU),\n",
    "            nn.Conv2d(in_channels * expansion_factor, out_channels, kernel_size=1),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.mb_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownsamplingMBConv(MBConv):\n",
    "    def __init__(self, in_channels, out_channels, expansion_factor=4):\n",
    "        super().__init__(in_channels, out_channels, expansion_factor=4)\n",
    "        self.mb_conv[1] = nn.Conv2d(in_channels, in_channels * expansion_factor, kernel_size=1, stride = 2)\n",
    "        self.channel_projection = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.channel_projection(self.pool(x)) + self.mb_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelativeAttention2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, image_size, heads=8, head_size=32):\n",
    "        super().__init__()\n",
    "        heads = out_channels // head_size\n",
    "        self.heads = heads\n",
    "        self.head_size = head_size\n",
    "        self.image_size = image_size\n",
    "        self.head_dim = heads * head_size\n",
    "        self.attend = nn.Softmax(dim=-2) # Taken from My_CoAtNet\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.to_q = nn.Linear(in_channels, self.head_dim)\n",
    "        self.to_k = nn.Linear(in_channels, self.head_dim)\n",
    "        self.to_v = nn.Linear(in_channels, self.head_dim)\n",
    "        self.to_output = nn.Sequential(\n",
    "            nn.Linear(self.head_dim, out_channels),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.normalization = nn.LayerNorm(in_channels)\n",
    "        \n",
    "        self.relative_bias = nn.Parameter(torch.randn(heads, (2 * image_size - 1) * (2 * image_size - 1)))\n",
    "        self.register_buffer(\"relative_indices\", self.get_indices(image_size, image_size)) # Taken from My_CoAtNet\n",
    "        self.precomputed_relative_bias = None\n",
    "    \n",
    "    def norm(self, x):\n",
    "        x = x.transpose(1, -1) # Taken from My_CoAtNet\n",
    "        x = self.normalization(x)\n",
    "        x = x.transpose(-1, 1) # Taken from My_CoAtNet\n",
    "        return x\n",
    "    \n",
    "    def get_relative_biases(self):\n",
    "        # Relative bias caching mentioned in CoAtNet: Marrying Convolution and Attention for All Data Sizes\n",
    "        if not self.training:\n",
    "            return self.precomputed_relative_bias\n",
    "        # Taken from od My_CoAtNet\n",
    "        indices = self.relative_indices.expand(self.heads, -1)\n",
    "        rel_pos_enc = self.relative_bias.gather(-1, indices)\n",
    "        rel_pos_enc = rel_pos_enc.unflatten(-1, (self.image_size * self.image_size, self.image_size * self.image_size))\n",
    "        return rel_pos_enc\n",
    "    \n",
    "    def reshape_for_linear(self, x):\n",
    "        b, _, _, _ = x.shape\n",
    "        return x.reshape(b, self.image_size * self.image_size, self.in_channels)\n",
    "    \n",
    "    def attention_score(self, x):\n",
    "        b, _, h, _ = x.shape\n",
    "        q = self.to_q(self.reshape_for_linear(x)).view(b, self.heads, self.head_size, -1) # Taken from My_CoAtNet\n",
    "        k = self.to_k(self.reshape_for_linear(x)).view(b, self.heads, self.head_size, -1) # Taken from My_CoAtNet\n",
    "        dots = torch.matmul(k.transpose(-1, -2), q) / math.sqrt(self.head_dim)\n",
    "        relative_biases_indexed = self.get_relative_biases()\n",
    "        return self.attend(dots + relative_biases_indexed)\n",
    "    \n",
    "    def relative_attention(self, x):\n",
    "        b, _, _, _ = x.shape\n",
    "        v = self.to_v(self.reshape_for_linear(x)).view(b, self.heads, self.head_size, -1) # Taken from My_CoAtNet\n",
    "        out = torch.matmul(v, self.attention_score(x)) # I figured this out after debugging (Still the same as My_CoAtNet)\n",
    "        out = out.view(b, self.image_size, self.image_size, -1)\n",
    "        return self.to_output(out).view(b, self.out_channels, self.image_size, self.image_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.relative_attention(self.norm(x))\n",
    "    \n",
    "    def train(self, training):\n",
    "        if not training:\n",
    "            self.precomputed_relative_bias = self.get_relative_biases()\n",
    "        super().train(training)\n",
    "        \n",
    "    # Taken from My_CoAtNet\n",
    "    @staticmethod\n",
    "    def get_indices(h, w):\n",
    "        y = torch.arange(h, dtype=torch.long)\n",
    "        x = torch.arange(w, dtype=torch.long)\n",
    "        \n",
    "        y1, x1, y2, x2 = torch.meshgrid(y, x, y, x)\n",
    "        indices = (y1 - y2 + h - 1) * (2 * w - 1) + x1 - x2 + w - 1\n",
    "        indices = indices.flatten()\n",
    "        \n",
    "        return indices\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownsamplingRelativeAttention2d(RelativeAttention2d):\n",
    "    def __init__(self, in_channels, out_channels, image_size, heads=8, head_size=32):\n",
    "        super().__init__(in_channels, out_channels, image_size, heads=8, head_size=32)\n",
    "        self.channel_projection = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.normalization = nn.LayerNorm(in_channels)\n",
    "\n",
    "\n",
    "    def norm(self, x):\n",
    "        x = x.transpose(1, -1) # Taken from My_CoAtNet\n",
    "        x = self.normalization(x)\n",
    "        x = x.transpose(-1, 1) # Taken from My_CoAtNet\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.channel_projection(self.pool(x)) + self.relative_attention(self.pool(self.norm(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, out_channels, expansion_factor=4):\n",
    "        super().__init__()\n",
    "        hidden_dim = out_channels * expansion_factor\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(out_channels, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, out_channels),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.normalization = nn.LayerNorm(out_channels)\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    \n",
    "    def norm(self, x):\n",
    "        x = x.transpose(1, -1) # Taken from My_CoAtNet\n",
    "        x = self.normalization(x)\n",
    "        x = x.transpose(-1, 1) # Taken from My_CoAtNet\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        old_shape = x.shape\n",
    "        batch_size = old_shape[0]\n",
    "        return x + torch.reshape(self.ffn(torch.reshape(self.norm(x), (batch_size, -1, self.out_channels))), old_shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownsampleTransformerBlock(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels, image_size):\n",
    "        attention = DownsamplingRelativeAttention2d(in_channels, out_channels, image_size)\n",
    "        ffn = FeedForwardNetwork(out_channels)\n",
    "        super().__init__(\n",
    "            attention,\n",
    "            ffn\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels, image_size):\n",
    "        attention = RelativeAttention2d(in_channels, out_channels, image_size)\n",
    "        ffn = FeedForwardNetwork(out_channels)\n",
    "        super().__init__(\n",
    "            attention,\n",
    "            ffn\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(in_channels, num_classes)\n",
    "        self.in_channels = in_channels\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.pool(x)\n",
    "        x = torch.reshape(x, (batch_size, -1, self.in_channels))\n",
    "        return torch.squeeze(self.fc(x))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCoAtNet(nn.Sequential):\n",
    "    def __init__(self, nums_blocks, layer_out_channels, num_classes=36):\n",
    "        s0 = nn.Sequential(Stem(layer_out_channels[0]))\n",
    "        \n",
    "        s1 = [DownsamplingMBConv(layer_out_channels[0], layer_out_channels[1])]\n",
    "        for i in range(nums_blocks[1] - 1):\n",
    "            s1.append(MBConv(layer_out_channels[1], layer_out_channels[1]))\n",
    "        s1 = nn.Sequential(*s1)\n",
    "        \n",
    "        s2 = [DownsamplingMBConv(layer_out_channels[1], layer_out_channels[2])]\n",
    "        for i in range(nums_blocks[2] - 1):\n",
    "            s2.append(MBConv(layer_out_channels[2], layer_out_channels[2]))\n",
    "        s2 = nn.Sequential(*s2)\n",
    "        \n",
    "        s3 = [DownsampleTransformerBlock(layer_out_channels[2], layer_out_channels[3], 64 // 16)]\n",
    "        for i in range(nums_blocks[3] - 1):\n",
    "            s3.append(TransformerBlock(layer_out_channels[3], layer_out_channels[3], 64 // 16))\n",
    "        s3 = nn.Sequential(*s3)\n",
    "        \n",
    "        s4 = [DownsampleTransformerBlock(layer_out_channels[3], layer_out_channels[4], 64 // 32)]\n",
    "        for i in range(nums_blocks[4] - 1):\n",
    "            s4.append(TransformerBlock(layer_out_channels[4], layer_out_channels[4], 64 // 32))\n",
    "        s4 = nn.Sequential(*s4)\n",
    "        \n",
    "        head = Head(layer_out_channels[4], num_classes)\n",
    "        \n",
    "        super().__init__(\n",
    "            s0,\n",
    "            s1,\n",
    "            s2,\n",
    "            s3,\n",
    "            s4,\n",
    "            head\n",
    "        )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ali/venv/lib/python3.10/site-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3637.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# CoAtNet-1\n",
    "nums_blocks = [2, 2, 3, 5, 2]           # L\n",
    "channels = [64, 96, 192, 384, 768]      # D\n",
    "\n",
    "model = MyCoAtNet(nums_blocks, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_linear(m):\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "        if m.bias is not None: nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 24,033,296\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]             640\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "              GELU-3           [-1, 64, 32, 32]               0\n",
      "            Conv2d-4           [-1, 64, 30, 30]          36,928\n",
      "         MaxPool2d-5           [-1, 64, 15, 15]               0\n",
      "            Conv2d-6           [-1, 96, 15, 15]           6,144\n",
      "       BatchNorm2d-7           [-1, 64, 30, 30]             128\n",
      "            Conv2d-8          [-1, 256, 15, 15]          16,640\n",
      "       BatchNorm2d-9          [-1, 256, 15, 15]             512\n",
      "             GELU-10          [-1, 256, 15, 15]               0\n",
      "           Conv2d-11          [-1, 256, 15, 15]           2,560\n",
      "      BatchNorm2d-12          [-1, 256, 15, 15]             512\n",
      "             GELU-13          [-1, 256, 15, 15]               0\n",
      "AdaptiveAvgPool2d-14            [-1, 256, 1, 1]               0\n",
      "           Conv2d-15             [-1, 64, 1, 1]          16,448\n",
      "             GELU-16             [-1, 64, 1, 1]               0\n",
      "           Conv2d-17            [-1, 256, 1, 1]          16,640\n",
      "          Sigmoid-18            [-1, 256, 1, 1]               0\n",
      "SqueezeExcitation-19          [-1, 256, 15, 15]               0\n",
      "           Conv2d-20           [-1, 96, 15, 15]          24,672\n",
      "      BatchNorm2d-21           [-1, 96, 15, 15]             192\n",
      "DownsamplingMBConv-22           [-1, 96, 15, 15]               0\n",
      "      BatchNorm2d-23           [-1, 96, 15, 15]             192\n",
      "           Conv2d-24          [-1, 384, 15, 15]          37,248\n",
      "      BatchNorm2d-25          [-1, 384, 15, 15]             768\n",
      "             GELU-26          [-1, 384, 15, 15]               0\n",
      "           Conv2d-27          [-1, 384, 15, 15]           3,840\n",
      "      BatchNorm2d-28          [-1, 384, 15, 15]             768\n",
      "             GELU-29          [-1, 384, 15, 15]               0\n",
      "AdaptiveAvgPool2d-30            [-1, 384, 1, 1]               0\n",
      "           Conv2d-31             [-1, 96, 1, 1]          36,960\n",
      "             GELU-32             [-1, 96, 1, 1]               0\n",
      "           Conv2d-33            [-1, 384, 1, 1]          37,248\n",
      "          Sigmoid-34            [-1, 384, 1, 1]               0\n",
      "SqueezeExcitation-35          [-1, 384, 15, 15]               0\n",
      "           Conv2d-36           [-1, 96, 15, 15]          36,960\n",
      "      BatchNorm2d-37           [-1, 96, 15, 15]             192\n",
      "           MBConv-38           [-1, 96, 15, 15]               0\n",
      "        MaxPool2d-39             [-1, 96, 8, 8]               0\n",
      "           Conv2d-40            [-1, 192, 8, 8]          18,432\n",
      "      BatchNorm2d-41           [-1, 96, 15, 15]             192\n",
      "           Conv2d-42            [-1, 384, 8, 8]          37,248\n",
      "      BatchNorm2d-43            [-1, 384, 8, 8]             768\n",
      "             GELU-44            [-1, 384, 8, 8]               0\n",
      "           Conv2d-45            [-1, 384, 8, 8]           3,840\n",
      "      BatchNorm2d-46            [-1, 384, 8, 8]             768\n",
      "             GELU-47            [-1, 384, 8, 8]               0\n",
      "AdaptiveAvgPool2d-48            [-1, 384, 1, 1]               0\n",
      "           Conv2d-49             [-1, 96, 1, 1]          36,960\n",
      "             GELU-50             [-1, 96, 1, 1]               0\n",
      "           Conv2d-51            [-1, 384, 1, 1]          37,248\n",
      "          Sigmoid-52            [-1, 384, 1, 1]               0\n",
      "SqueezeExcitation-53            [-1, 384, 8, 8]               0\n",
      "           Conv2d-54            [-1, 192, 8, 8]          73,920\n",
      "      BatchNorm2d-55            [-1, 192, 8, 8]             384\n",
      "DownsamplingMBConv-56            [-1, 192, 8, 8]               0\n",
      "      BatchNorm2d-57            [-1, 192, 8, 8]             384\n",
      "           Conv2d-58            [-1, 768, 8, 8]         148,224\n",
      "      BatchNorm2d-59            [-1, 768, 8, 8]           1,536\n",
      "             GELU-60            [-1, 768, 8, 8]               0\n",
      "           Conv2d-61            [-1, 768, 8, 8]           7,680\n",
      "      BatchNorm2d-62            [-1, 768, 8, 8]           1,536\n",
      "             GELU-63            [-1, 768, 8, 8]               0\n",
      "AdaptiveAvgPool2d-64            [-1, 768, 1, 1]               0\n",
      "           Conv2d-65            [-1, 192, 1, 1]         147,648\n",
      "             GELU-66            [-1, 192, 1, 1]               0\n",
      "           Conv2d-67            [-1, 768, 1, 1]         148,224\n",
      "          Sigmoid-68            [-1, 768, 1, 1]               0\n",
      "SqueezeExcitation-69            [-1, 768, 8, 8]               0\n",
      "           Conv2d-70            [-1, 192, 8, 8]         147,648\n",
      "      BatchNorm2d-71            [-1, 192, 8, 8]             384\n",
      "           MBConv-72            [-1, 192, 8, 8]               0\n",
      "      BatchNorm2d-73            [-1, 192, 8, 8]             384\n",
      "           Conv2d-74            [-1, 768, 8, 8]         148,224\n",
      "      BatchNorm2d-75            [-1, 768, 8, 8]           1,536\n",
      "             GELU-76            [-1, 768, 8, 8]               0\n",
      "           Conv2d-77            [-1, 768, 8, 8]           7,680\n",
      "      BatchNorm2d-78            [-1, 768, 8, 8]           1,536\n",
      "             GELU-79            [-1, 768, 8, 8]               0\n",
      "AdaptiveAvgPool2d-80            [-1, 768, 1, 1]               0\n",
      "           Conv2d-81            [-1, 192, 1, 1]         147,648\n",
      "             GELU-82            [-1, 192, 1, 1]               0\n",
      "           Conv2d-83            [-1, 768, 1, 1]         148,224\n",
      "          Sigmoid-84            [-1, 768, 1, 1]               0\n",
      "SqueezeExcitation-85            [-1, 768, 8, 8]               0\n",
      "           Conv2d-86            [-1, 192, 8, 8]         147,648\n",
      "      BatchNorm2d-87            [-1, 192, 8, 8]             384\n",
      "           MBConv-88            [-1, 192, 8, 8]               0\n",
      "        MaxPool2d-89            [-1, 192, 4, 4]               0\n",
      "           Conv2d-90            [-1, 384, 4, 4]          73,728\n",
      "        LayerNorm-91            [-1, 8, 8, 192]             384\n",
      "        MaxPool2d-92            [-1, 192, 4, 4]               0\n",
      "           Linear-93              [-1, 16, 384]          74,112\n",
      "           Linear-94              [-1, 16, 384]          74,112\n",
      "           Linear-95              [-1, 16, 384]          74,112\n",
      "          Softmax-96           [-1, 12, 16, 16]               0\n",
      "           Linear-97            [-1, 4, 4, 384]         147,840\n",
      "          Dropout-98            [-1, 4, 4, 384]               0\n",
      "DownsamplingRelativeAttention2d-99            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-100            [-1, 4, 4, 384]             768\n",
      "          Linear-101             [-1, 16, 1536]         591,360\n",
      "            GELU-102             [-1, 16, 1536]               0\n",
      "         Dropout-103             [-1, 16, 1536]               0\n",
      "          Linear-104              [-1, 16, 384]         590,208\n",
      "         Dropout-105              [-1, 16, 384]               0\n",
      "FeedForwardNetwork-106            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-107            [-1, 4, 4, 384]             768\n",
      "          Linear-108              [-1, 16, 384]         147,840\n",
      "          Linear-109              [-1, 16, 384]         147,840\n",
      "          Linear-110              [-1, 16, 384]         147,840\n",
      "         Softmax-111           [-1, 12, 16, 16]               0\n",
      "          Linear-112            [-1, 4, 4, 384]         147,840\n",
      "         Dropout-113            [-1, 4, 4, 384]               0\n",
      "RelativeAttention2d-114            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-115            [-1, 4, 4, 384]             768\n",
      "          Linear-116             [-1, 16, 1536]         591,360\n",
      "            GELU-117             [-1, 16, 1536]               0\n",
      "         Dropout-118             [-1, 16, 1536]               0\n",
      "          Linear-119              [-1, 16, 384]         590,208\n",
      "         Dropout-120              [-1, 16, 384]               0\n",
      "FeedForwardNetwork-121            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-122            [-1, 4, 4, 384]             768\n",
      "          Linear-123              [-1, 16, 384]         147,840\n",
      "          Linear-124              [-1, 16, 384]         147,840\n",
      "          Linear-125              [-1, 16, 384]         147,840\n",
      "         Softmax-126           [-1, 12, 16, 16]               0\n",
      "          Linear-127            [-1, 4, 4, 384]         147,840\n",
      "         Dropout-128            [-1, 4, 4, 384]               0\n",
      "RelativeAttention2d-129            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-130            [-1, 4, 4, 384]             768\n",
      "          Linear-131             [-1, 16, 1536]         591,360\n",
      "            GELU-132             [-1, 16, 1536]               0\n",
      "         Dropout-133             [-1, 16, 1536]               0\n",
      "          Linear-134              [-1, 16, 384]         590,208\n",
      "         Dropout-135              [-1, 16, 384]               0\n",
      "FeedForwardNetwork-136            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-137            [-1, 4, 4, 384]             768\n",
      "          Linear-138              [-1, 16, 384]         147,840\n",
      "          Linear-139              [-1, 16, 384]         147,840\n",
      "          Linear-140              [-1, 16, 384]         147,840\n",
      "         Softmax-141           [-1, 12, 16, 16]               0\n",
      "          Linear-142            [-1, 4, 4, 384]         147,840\n",
      "         Dropout-143            [-1, 4, 4, 384]               0\n",
      "RelativeAttention2d-144            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-145            [-1, 4, 4, 384]             768\n",
      "          Linear-146             [-1, 16, 1536]         591,360\n",
      "            GELU-147             [-1, 16, 1536]               0\n",
      "         Dropout-148             [-1, 16, 1536]               0\n",
      "          Linear-149              [-1, 16, 384]         590,208\n",
      "         Dropout-150              [-1, 16, 384]               0\n",
      "FeedForwardNetwork-151            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-152            [-1, 4, 4, 384]             768\n",
      "          Linear-153              [-1, 16, 384]         147,840\n",
      "          Linear-154              [-1, 16, 384]         147,840\n",
      "          Linear-155              [-1, 16, 384]         147,840\n",
      "         Softmax-156           [-1, 12, 16, 16]               0\n",
      "          Linear-157            [-1, 4, 4, 384]         147,840\n",
      "         Dropout-158            [-1, 4, 4, 384]               0\n",
      "RelativeAttention2d-159            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-160            [-1, 4, 4, 384]             768\n",
      "          Linear-161             [-1, 16, 1536]         591,360\n",
      "            GELU-162             [-1, 16, 1536]               0\n",
      "         Dropout-163             [-1, 16, 1536]               0\n",
      "          Linear-164              [-1, 16, 384]         590,208\n",
      "         Dropout-165              [-1, 16, 384]               0\n",
      "FeedForwardNetwork-166            [-1, 384, 4, 4]               0\n",
      "       MaxPool2d-167            [-1, 384, 2, 2]               0\n",
      "          Conv2d-168            [-1, 768, 2, 2]         294,912\n",
      "       LayerNorm-169            [-1, 4, 4, 384]             768\n",
      "       MaxPool2d-170            [-1, 384, 2, 2]               0\n",
      "          Linear-171               [-1, 4, 768]         295,680\n",
      "          Linear-172               [-1, 4, 768]         295,680\n",
      "          Linear-173               [-1, 4, 768]         295,680\n",
      "         Softmax-174             [-1, 24, 4, 4]               0\n",
      "          Linear-175            [-1, 2, 2, 768]         590,592\n",
      "         Dropout-176            [-1, 2, 2, 768]               0\n",
      "DownsamplingRelativeAttention2d-177            [-1, 768, 2, 2]               0\n",
      "       LayerNorm-178            [-1, 2, 2, 768]           1,536\n",
      "          Linear-179              [-1, 4, 3072]       2,362,368\n",
      "            GELU-180              [-1, 4, 3072]               0\n",
      "         Dropout-181              [-1, 4, 3072]               0\n",
      "          Linear-182               [-1, 4, 768]       2,360,064\n",
      "         Dropout-183               [-1, 4, 768]               0\n",
      "FeedForwardNetwork-184            [-1, 768, 2, 2]               0\n",
      "       LayerNorm-185            [-1, 2, 2, 768]           1,536\n",
      "          Linear-186               [-1, 4, 768]         590,592\n",
      "          Linear-187               [-1, 4, 768]         590,592\n",
      "          Linear-188               [-1, 4, 768]         590,592\n",
      "         Softmax-189             [-1, 24, 4, 4]               0\n",
      "          Linear-190            [-1, 2, 2, 768]         590,592\n",
      "         Dropout-191            [-1, 2, 2, 768]               0\n",
      "RelativeAttention2d-192            [-1, 768, 2, 2]               0\n",
      "       LayerNorm-193            [-1, 2, 2, 768]           1,536\n",
      "          Linear-194              [-1, 4, 3072]       2,362,368\n",
      "            GELU-195              [-1, 4, 3072]               0\n",
      "         Dropout-196              [-1, 4, 3072]               0\n",
      "          Linear-197               [-1, 4, 768]       2,360,064\n",
      "         Dropout-198               [-1, 4, 768]               0\n",
      "FeedForwardNetwork-199            [-1, 768, 2, 2]               0\n",
      "AdaptiveAvgPool2d-200            [-1, 768, 1, 1]               0\n",
      "          Linear-201                [-1, 1, 36]          27,684\n",
      "            Head-202                   [-1, 36]               0\n",
      "================================================================\n",
      "Total params: 24,029,924\n",
      "Trainable params: 24,029,924\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 26.27\n",
      "Params size (MB): 91.67\n",
      "Estimated Total Size (MB): 117.96\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model.apply(init_linear)\n",
    "model.to(device)\n",
    "\n",
    "print(\"Number of parameters: {:,}\".format(sum(p.numel() for p in model.parameters())))\n",
    "\n",
    "summary(model, input_size=(1, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyCoAtNet(\n",
       "  (0): Sequential(\n",
       "    (0): Stem(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): DownsamplingMBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (channel_projection): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "        (5): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): DownsamplingMBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(96, 384, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "        (5): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (channel_projection): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        (5): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        (5): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): DownsampleTransformerBlock(\n",
       "      (0): DownsamplingRelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (channel_projection): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): DownsampleTransformerBlock(\n",
       "      (0): DownsamplingRelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (channel_projection): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (5): Head(\n",
       "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (fc): Linear(in_features=768, out_features=36, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model.load_state_dict(torch.load(\"CoAtNet-1-Best-Zoom.pkl\"))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_set,\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from My_CoAtNet\n",
    "def separate_parameters(model):\n",
    "    parameters_decay = set()\n",
    "    parameters_no_decay = set()\n",
    "    modules_weight_decay = (nn.Linear, nn.Conv2d)\n",
    "    modules_no_weight_decay = (nn.LayerNorm, nn.BatchNorm2d)\n",
    "    \n",
    "    for m_name, m in model.named_modules():\n",
    "        for param_name, param in m.named_parameters():\n",
    "            full_param_name = f\"{m_name}.{param_name}\" if m_name else param_name\n",
    "\n",
    "            if isinstance(m, modules_no_weight_decay):\n",
    "                parameters_no_decay.add(full_param_name)\n",
    "            elif param_name.endswith(\"bias\"):\n",
    "                parameters_no_decay.add(full_param_name)\n",
    "            elif isinstance(m, modules_weight_decay):\n",
    "                parameters_decay.add(full_param_name)\n",
    "    \n",
    "    # sanity check\n",
    "    assert len(parameters_decay & parameters_no_decay) == 0\n",
    "    assert len(parameters_decay) + len(parameters_no_decay) == len(list(model.parameters()))\n",
    "\n",
    "    return parameters_decay, parameters_no_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 5e-4\n",
    "weight_decay = 0.1\n",
    "num_epochs = 1100\n",
    "min_learning_rate = 1e-6\n",
    "\n",
    "param_dict = {pn: p for pn, p in model.named_parameters()}\n",
    "parameters_decay, parameters_no_decay = separate_parameters(model)\n",
    "parameter_groups = [\n",
    "    {\"params\": [param_dict[pn] for pn in parameters_decay], \"weight_decay\": weight_decay},\n",
    "    {\"params\": [param_dict[pn] for pn in parameters_no_decay], \"weight_decay\": 0.0},\n",
    "]\n",
    "optimizer = torch.optim.Adam(parameter_groups, lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=min_learning_rate / learning_rate, total_iters=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from My_CoAtNet\n",
    "def plot_results(train_losses, train_accuracies, val_losses, val_accuracies):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title(\"Loss\")\n",
    "    plt.plot(train_losses)\n",
    "    plt.plot(val_losses)\n",
    "    plt.legend([\"Training loss\", \"Validation loss\"], loc =  \"best\")\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.plot(train_accuracies)\n",
    "    plt.plot(val_accuracies)\n",
    "    plt.legend([\"Training accuracy\", \"Validation accuracy\"], loc =  \"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = \"CoAtNet-1-Best-Zoom.pkl\"\n",
    "model_path = \"CoAtNet-1-Zoom.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyCoAtNet(\n",
       "  (0): Sequential(\n",
       "    (0): Stem(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): DownsamplingMBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (channel_projection): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "        (5): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): DownsamplingMBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(96, 384, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "        (5): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (channel_projection): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        (5): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        (5): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): DownsampleTransformerBlock(\n",
       "      (0): DownsamplingRelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (channel_projection): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): DownsampleTransformerBlock(\n",
       "      (0): DownsamplingRelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (channel_projection): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (5): Head(\n",
       "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (fc): Linear(in_features=768, out_features=36, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mappings from indices to syllables and vice versa\n",
    "digits_and_syllables = list('0123456789abcdefghijklmnopqrstuvwxyz')\n",
    "idx_to_syllable = {idx: syllable for idx, syllable in enumerate(digits_and_syllables)}\n",
    "syllable_to_idx = {syllable: idx for idx, syllable in idx_to_syllable.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine test and validation datasets\n",
    "combined_dataset = ConcatDataset([val_set, test_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from syllables to dataset indices\n",
    "syllable_to_indices = {}\n",
    "for idx in range(len(combined_dataset)):\n",
    "    _, label = combined_dataset[idx]\n",
    "    # label = label.item() \n",
    "    syllable = idx_to_syllable[label]\n",
    "    if syllable not in syllable_to_indices:\n",
    "        syllable_to_indices[syllable] = []\n",
    "    syllable_to_indices[syllable].append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process sentences into syllables\n",
    "def get_syllables(sentence):\n",
    "    sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "    # sentence = sentence.replace(' ',  '').lower()\n",
    "    syllables = list(sentence)\n",
    "    return syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 1000\n"
     ]
    }
   ],
   "source": [
    "# Read sentences from the text file\n",
    "with open('../sentences/sentences.txt', 'r') as f:\n",
    "    sentences = f.readlines()\n",
    "\n",
    "print(\"Number of sentences:\", len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "\n",
    "def compute_accuracy_and_wrong_syllables(true_sentence, predicted_sentence):\n",
    "    # Character-level accuracy using SequenceMatcher\n",
    "    char_matcher = difflib.SequenceMatcher(None, true_sentence, predicted_sentence)\n",
    "    accuracy = char_matcher.ratio()\n",
    "    \n",
    "    # Word-level wrong syllable count using SequenceMatcher on word lists\n",
    "    true_words = true_sentence.split()\n",
    "    predicted_words = predicted_sentence.split()\n",
    "    word_matcher = difflib.SequenceMatcher(None, true_words, predicted_words)\n",
    "    \n",
    "    # Calculate wrong syllables based on insert, delete, and replace operations\n",
    "    wrong_syllables = sum(1 for tag, _, _, _, _ in word_matcher.get_opcodes() if tag in ('insert', 'delete', 'replace'))\n",
    "    \n",
    "    return accuracy, wrong_syllables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1000/1000 [11:28<00:00,  1.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# Process each sentence\n",
    "noise_factor = 0\n",
    "results = []\n",
    "\n",
    "for sentence in tqdm(sentences[:]):\n",
    "    sentence = sentence.strip()\n",
    "    syllables = get_syllables(sentence)\n",
    "    true_sentence = ''.join(syllables)\n",
    "    predicted_syllables = []\n",
    "\n",
    "    for syllable in syllables:\n",
    "        if syllable in syllable_to_indices:\n",
    "            # Randomly select an index for the syllable\n",
    "            idx = random.choice(syllable_to_indices[syllable])\n",
    "            # Retrieve the image and label from the dataset\n",
    "            image, _ = combined_dataset[idx]\n",
    "\n",
    "            noise = torch.randn_like(image) * noise_factor\n",
    "            image = image + noise\n",
    "            image = image.unsqueeze(0).to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(image)\n",
    "                output = output.reshape(1, -1)\n",
    "                _, predicted_idx = torch.max(output.data, 1)\n",
    "                predicted_syllable = idx_to_syllable[predicted_idx.item()]\n",
    "        else:\n",
    "            if random.random() < 0.90:\n",
    "                predicted_syllable = ' '\n",
    "            else:\n",
    "                predicted_syllable = random.choice(digits_and_syllables)\n",
    "        predicted_syllables.append(predicted_syllable)\n",
    "    \n",
    "    predicted_sentence = ''.join(predicted_syllables)\n",
    "    accuracy, wrong_syllables = compute_accuracy_and_wrong_syllables(true_sentence, predicted_sentence)\n",
    "    results.append([true_sentence, predicted_sentence, accuracy, wrong_syllables])\n",
    "    # print(f\"accuracy: {accuracy}, wrong: {wrong_syllables}, true: {true_sentence}, predicted: {predicted_sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise factor: 0\n",
      "Average accuracy: 0.6424\n",
      "Total wrong syllables: 1940\n"
     ]
    }
   ],
   "source": [
    "# accuracy average and wrong syllables sum\n",
    "accuracy_avg = sum(result[2] for result in results) / len(results)\n",
    "wrong_syllables_sum = sum(result[3] for result in results)\n",
    "\n",
    "print(\"Noise factor:\", noise_factor)\n",
    "print(f\"Average accuracy: {accuracy_avg:.4f}\")\n",
    "print(f\"Total wrong syllables: {wrong_syllables_sum}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results/noise_1.0.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['True Sentence', 'Predicted Sentence', 'Accuracy', 'Wrong syllables'])\n",
    "    for row in results:\n",
    "        writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
