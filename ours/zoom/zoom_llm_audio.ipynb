{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import librosa\n",
    "import os\n",
    "import random\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math\n",
    "import torchaudio\n",
    "import csv\n",
    "import string\n",
    "\n",
    "from torch.utils.data import ConcatDataset\n",
    "from torchaudio.transforms import TimeMasking, FrequencyMasking\n",
    "from torchvision.ops import SqueezeExcitation\n",
    "from torchinfo import summary\n",
    "from torchsummary import summary\n",
    "from torchvision.ops import SqueezeExcitation\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from collections import defaultdict\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from scipy.io import wavfile\n",
    "from functools import reduce\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_s = '0123456789abcdefghijklmnopqrstuvwxyz'\n",
    "labels = list(keys_s)\n",
    "keys = [k + '.wav' for k in labels]\n",
    "data_dict = {'Key':[], 'File':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def add_noise_to_stroke(stroke, noise_factor=None):\n",
    "    # print(stroke.shape)\n",
    "    noise = torch.randn_like(stroke)\n",
    "    return stroke + noise_factor * noise\n",
    "\n",
    "def isolator(signal, sample_rate, size, scan, before, after, threshold, show=False):\n",
    "    strokes = []\n",
    "    if show:\n",
    "        plt.figure(figsize=(7, 2))\n",
    "        librosa.display.waveshow(signal, sr=sample_rate)\n",
    "    fft = librosa.stft(signal, n_fft=size, hop_length=scan)\n",
    "    energy = np.abs(np.sum(fft, axis=0)).astype(float)\n",
    "    if show:\n",
    "        plt.figure(figsize=(7, 2))\n",
    "        librosa.display.waveshow(energy)\n",
    "    threshed = energy > threshold\n",
    "    if show:\n",
    "        plt.figure(figsize=(7, 2))\n",
    "        librosa.display.waveshow(threshed.astype(float))\n",
    "    peaks = np.where(threshed)[0]\n",
    "    peak_count = len(peaks)\n",
    "    prev_end = sample_rate * 0.1 * (-1)\n",
    "    for i in range(peak_count):\n",
    "        this_peak = peaks[i]\n",
    "        timestamp = (this_peak * scan) + size // 2\n",
    "        if timestamp > prev_end + (0.1 * sample_rate):\n",
    "            keystroke = signal[timestamp - before:timestamp + after]\n",
    "            strokes.append(torch.tensor(keystroke)[None, :])\n",
    "            if show:\n",
    "                plt.figure(figsize=(7, 2))\n",
    "                librosa.display.waveshow(keystroke, sr=sample_rate)\n",
    "            prev_end = timestamp + after\n",
    "    return strokes\n",
    "\n",
    "def convert_to_df_with_noise(audio_dir, noise_factor=None):\n",
    "    \"\"\"\n",
    "    Processes each audio file by isolating strokes, adds noise to each stroke,\n",
    "    and stores the strokes with labels in a dataframe.\n",
    "    \"\"\"\n",
    "    # Generate a list of .wav files in the provided directory\n",
    "    keys = sorted([f for f in os.listdir(audio_dir) if f.endswith('.wav')])\n",
    "    \n",
    "    data_dict = {'Key': [], 'File': []}\n",
    "    \n",
    "    # If your labels are inferred from file names, you can extract them here.\n",
    "    # For example, if the file is 'a.wav', you might want to use 'a' as the label.\n",
    "    def extract_label(filename):\n",
    "        base = os.path.splitext(filename)[0]\n",
    "        return base  # or apply any mapping you need\n",
    "\n",
    "    for file in keys:\n",
    "        loc = os.path.join(audio_dir, file)\n",
    "        samples, sample_rate = librosa.load(loc, sr=None)\n",
    "        strokes = []\n",
    "        prom = 0.06\n",
    "        step = 0.005\n",
    "        # Adjust threshold until we get exactly 25 strokes (or break if not possible)\n",
    "        while not len(strokes) == 25:\n",
    "            strokes = isolator(samples[1 * sample_rate:], sample_rate, 48, 24, 2400, 12000, prom, show=False)\n",
    "            if len(strokes) < 25:\n",
    "                prom -= step\n",
    "            elif len(strokes) > 25:\n",
    "                prom += step\n",
    "            if prom <= 0:\n",
    "                print('-- not possible for:', file)\n",
    "                break\n",
    "            step *= 0.99\n",
    "        \n",
    "        # Apply noise to each extracted stroke\n",
    "        noisy_strokes = [add_noise_to_stroke(stroke, noise_factor) for stroke in strokes]\n",
    "\n",
    "        # Extract a label for this file (modify as needed)\n",
    "        label = extract_label(file)\n",
    "        data_dict['Key'] += [label] * len(noisy_strokes)\n",
    "        data_dict['File'] += noisy_strokes\n",
    "\n",
    "    df = pd.DataFrame(data_dict)\n",
    "    \n",
    "    # Optionally, create a mapping for the labels (if needed)\n",
    "    mapper = {}\n",
    "    counter = 0\n",
    "    for l in df['Key']:\n",
    "        if l not in mapper:\n",
    "            mapper[l] = counter\n",
    "            counter += 1\n",
    "    df.replace({'Key': mapper}, inplace=True)\n",
    "    \n",
    "    return df, sample_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Key                                               File\n",
      "0   0  [[tensor(-0.0007), tensor(-0.0041), tensor(0.0...\n",
      "1   0  [[tensor(0.0017), tensor(-0.0024), tensor(0.00...\n",
      "2   0  [[tensor(0.0008), tensor(0.0007), tensor(0.002...\n",
      "3   0  [[tensor(-0.0004), tensor(-0.0010), tensor(-0....\n",
      "4   0  [[tensor(-6.5417e-05), tensor(-0.0021), tensor...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 900 entries, 0 to 899\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Key     900 non-null    object\n",
      " 1   File    900 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 14.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data_frame, sr = convert_to_df_with_noise(\"../../dataset/Zoom/\", noise_factor=0.002)\n",
    "\n",
    "print(data_frame.head())\n",
    "print(data_frame.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample rate: 32000\n",
      "630 180 90\n"
     ]
    }
   ],
   "source": [
    "train_set, tmp_set = train_test_split(data_frame, test_size=0.3, stratify=data_frame['Key'])\n",
    "val_set, test_set = train_test_split(tmp_set, test_size=0.33, stratify=tmp_set['Key'])\n",
    "\n",
    "print(\"Sample rate:\", sr)\n",
    "print(len(train_set), len(val_set), len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, file_name, transform = None, aug = None):\n",
    "        df = file_name\n",
    "        self.transform = transform\n",
    "        self.aug = aug\n",
    "        self.labels = df['Key']\n",
    "        self.values = df['File']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, index):\n",
    "        label = self.labels.iloc[index]\n",
    "        value = self.values.iloc[index]\n",
    "        waveform = self.values.iloc[index]\n",
    "        label = self.labels.iloc[index]\n",
    "        if self.transform:\n",
    "            waveform = waveform.numpy()\n",
    "            waveform = waveform.flatten()\n",
    "            waveform = self.transform(waveform)\n",
    "        if self.aug:\n",
    "            waveform = self.aug(waveform)\n",
    "        return waveform, label\n",
    "\n",
    "class ToMelSpectrogram:\n",
    "    def __call__(self, samples):\n",
    "#         samples = np.array(samples)\n",
    "        spec = librosa.feature.melspectrogram(y = samples, sr = sr, n_mels=64, n_fft=2048, win_length=1024, hop_length=226)\n",
    "        return librosa.power_to_db(spec)\n",
    "\n",
    "class TimeShifting():\n",
    "    def __call__(self, samples):\n",
    "        samples = samples.numpy()\n",
    "        samples = samples.flatten()\n",
    "        \n",
    "        shift = int(len(samples) * 0.4)\n",
    "        random_shift =random.randint(0, shift)\n",
    "        data_roll = np.roll(samples, random_shift)\n",
    "        return data_roll\n",
    "    \n",
    "class SpecAugment():\n",
    "    def __call__(self, samples):\n",
    "        num_mask = 2\n",
    "        freq_masking_max_percentage=0.10\n",
    "        time_masking_max_percentage=0.10\n",
    "        spec = samples.copy()\n",
    "        mean_value = spec.mean()\n",
    "        for i in range(num_mask):\n",
    "            all_frames_num, all_freqs_num = spec.shape[1], spec.shape[1] \n",
    "            freq_percentage = random.uniform(0.0, freq_masking_max_percentage)\n",
    "\n",
    "            num_freqs_to_mask = int(freq_percentage * all_freqs_num)\n",
    "            f0 = np.random.uniform(low=0.0, high=all_freqs_num - num_freqs_to_mask)\n",
    "            f0 = int(f0)\n",
    "            spec[:, f0:f0 + num_freqs_to_mask] = mean_value\n",
    "\n",
    "            time_percentage = random.uniform(0.0, time_masking_max_percentage)\n",
    "\n",
    "            num_frames_to_mask = int(time_percentage * all_frames_num)\n",
    "            t0 = np.random.uniform(low=0.0, high=all_frames_num - num_frames_to_mask)\n",
    "            t0 = int(t0)\n",
    "            spec[t0:t0 + num_frames_to_mask, :] = mean_value\n",
    "        return spec\n",
    "\n",
    "aug = Compose([\n",
    "    TimeShifting(),\n",
    "    ToMelSpectrogram(),\n",
    "    SpecAugment(),\n",
    "    ToTensor()\n",
    "    ])\n",
    "\n",
    "transform = Compose([\n",
    "    ToMelSpectrogram(),\n",
    "    ToTensor()])\n",
    "        \n",
    "train_set = MyDataset(train_set, aug = aug)\n",
    "val_set = MyDataset(val_set, transform = transform)\n",
    "test_set = MyDataset(test_set, transform = transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set image (augmented vs non-augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax1.imshow(train_set[0][0][0], cmap='viridis')\n",
    "ax2.imshow(val_set[0][0][0], cmap='viridis')\n",
    "print(train_set[0][0][0].shape)\n",
    "ax1.grid(False)\n",
    "ax2.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of classes: 36\n"
     ]
    }
   ],
   "source": [
    "print(\"number of classes:\", len(np.unique(data_frame['Key'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoAtNet (Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stem(nn.Sequential):\n",
    "    def __init__(self, out_channels):\n",
    "        super().__init__(\n",
    "            nn.Conv2d(1, out_channels, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MBConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, expansion_factor=4):\n",
    "        super().__init__()\n",
    "        self.mb_conv = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.Conv2d(in_channels, in_channels * expansion_factor, kernel_size=1),\n",
    "            nn.BatchNorm2d(in_channels * expansion_factor),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(in_channels * expansion_factor, in_channels * expansion_factor, kernel_size=3, padding=1, groups=in_channels * expansion_factor),\n",
    "            nn.BatchNorm2d(in_channels * expansion_factor),\n",
    "            nn.GELU(),\n",
    "            SqueezeExcitation(in_channels * expansion_factor, in_channels, activation=nn.GELU),\n",
    "            nn.Conv2d(in_channels * expansion_factor, out_channels, kernel_size=1),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.mb_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownsamplingMBConv(MBConv):\n",
    "    def __init__(self, in_channels, out_channels, expansion_factor=4):\n",
    "        super().__init__(in_channels, out_channels, expansion_factor=4)\n",
    "        self.mb_conv[1] = nn.Conv2d(in_channels, in_channels * expansion_factor, kernel_size=1, stride = 2)\n",
    "        self.channel_projection = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.channel_projection(self.pool(x)) + self.mb_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelativeAttention2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, image_size, heads=8, head_size=32):\n",
    "        super().__init__()\n",
    "        heads = out_channels // head_size\n",
    "        self.heads = heads\n",
    "        self.head_size = head_size\n",
    "        self.image_size = image_size\n",
    "        self.head_dim = heads * head_size\n",
    "        self.attend = nn.Softmax(dim=-2) # Taken from My_CoAtNet\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.to_q = nn.Linear(in_channels, self.head_dim)\n",
    "        self.to_k = nn.Linear(in_channels, self.head_dim)\n",
    "        self.to_v = nn.Linear(in_channels, self.head_dim)\n",
    "        self.to_output = nn.Sequential(\n",
    "            nn.Linear(self.head_dim, out_channels),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.normalization = nn.LayerNorm(in_channels)\n",
    "        \n",
    "        self.relative_bias = nn.Parameter(torch.randn(heads, (2 * image_size - 1) * (2 * image_size - 1)))\n",
    "        self.register_buffer(\"relative_indices\", self.get_indices(image_size, image_size)) # Taken from My_CoAtNet\n",
    "        self.precomputed_relative_bias = None\n",
    "    \n",
    "    def norm(self, x):\n",
    "        x = x.transpose(1, -1) # Taken from My_CoAtNet\n",
    "        x = self.normalization(x)\n",
    "        x = x.transpose(-1, 1) # Taken from My_CoAtNet\n",
    "        return x\n",
    "    \n",
    "    def get_relative_biases(self):\n",
    "        # Relative bias caching mentioned in CoAtNet: Marrying Convolution and Attention for All Data Sizes\n",
    "        if not self.training:\n",
    "            return self.precomputed_relative_bias\n",
    "        # Taken from od My_CoAtNet\n",
    "        indices = self.relative_indices.expand(self.heads, -1)\n",
    "        rel_pos_enc = self.relative_bias.gather(-1, indices)\n",
    "        rel_pos_enc = rel_pos_enc.unflatten(-1, (self.image_size * self.image_size, self.image_size * self.image_size))\n",
    "        return rel_pos_enc\n",
    "    \n",
    "    def reshape_for_linear(self, x):\n",
    "        b, _, _, _ = x.shape\n",
    "        return x.reshape(b, self.image_size * self.image_size, self.in_channels)\n",
    "    \n",
    "    def attention_score(self, x):\n",
    "        b, _, h, _ = x.shape\n",
    "        q = self.to_q(self.reshape_for_linear(x)).view(b, self.heads, self.head_size, -1) # Taken from My_CoAtNet\n",
    "        k = self.to_k(self.reshape_for_linear(x)).view(b, self.heads, self.head_size, -1) # Taken from My_CoAtNet\n",
    "        dots = torch.matmul(k.transpose(-1, -2), q) / math.sqrt(self.head_dim)\n",
    "        relative_biases_indexed = self.get_relative_biases()\n",
    "        return self.attend(dots + relative_biases_indexed)\n",
    "    \n",
    "    def relative_attention(self, x):\n",
    "        b, _, _, _ = x.shape\n",
    "        v = self.to_v(self.reshape_for_linear(x)).view(b, self.heads, self.head_size, -1) # Taken from My_CoAtNet\n",
    "        out = torch.matmul(v, self.attention_score(x)) # I figured this out after debugging (Still the same as My_CoAtNet)\n",
    "        out = out.view(b, self.image_size, self.image_size, -1)\n",
    "        return self.to_output(out).view(b, self.out_channels, self.image_size, self.image_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.relative_attention(self.norm(x))\n",
    "    \n",
    "    def train(self, training):\n",
    "        if not training:\n",
    "            self.precomputed_relative_bias = self.get_relative_biases()\n",
    "        super().train(training)\n",
    "        \n",
    "    # Taken from My_CoAtNet\n",
    "    @staticmethod\n",
    "    def get_indices(h, w):\n",
    "        y = torch.arange(h, dtype=torch.long)\n",
    "        x = torch.arange(w, dtype=torch.long)\n",
    "        \n",
    "        y1, x1, y2, x2 = torch.meshgrid(y, x, y, x)\n",
    "        indices = (y1 - y2 + h - 1) * (2 * w - 1) + x1 - x2 + w - 1\n",
    "        indices = indices.flatten()\n",
    "        \n",
    "        return indices\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownsamplingRelativeAttention2d(RelativeAttention2d):\n",
    "    def __init__(self, in_channels, out_channels, image_size, heads=8, head_size=32):\n",
    "        super().__init__(in_channels, out_channels, image_size, heads=8, head_size=32)\n",
    "        self.channel_projection = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.normalization = nn.LayerNorm(in_channels)\n",
    "\n",
    "\n",
    "    def norm(self, x):\n",
    "        x = x.transpose(1, -1) # Taken from My_CoAtNet\n",
    "        x = self.normalization(x)\n",
    "        x = x.transpose(-1, 1) # Taken from My_CoAtNet\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.channel_projection(self.pool(x)) + self.relative_attention(self.pool(self.norm(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, out_channels, expansion_factor=4):\n",
    "        super().__init__()\n",
    "        hidden_dim = out_channels * expansion_factor\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(out_channels, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, out_channels),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.normalization = nn.LayerNorm(out_channels)\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    \n",
    "    def norm(self, x):\n",
    "        x = x.transpose(1, -1) # Taken from My_CoAtNet\n",
    "        x = self.normalization(x)\n",
    "        x = x.transpose(-1, 1) # Taken from My_CoAtNet\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        old_shape = x.shape\n",
    "        batch_size = old_shape[0]\n",
    "        return x + torch.reshape(self.ffn(torch.reshape(self.norm(x), (batch_size, -1, self.out_channels))), old_shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownsampleTransformerBlock(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels, image_size):\n",
    "        attention = DownsamplingRelativeAttention2d(in_channels, out_channels, image_size)\n",
    "        ffn = FeedForwardNetwork(out_channels)\n",
    "        super().__init__(\n",
    "            attention,\n",
    "            ffn\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels, image_size):\n",
    "        attention = RelativeAttention2d(in_channels, out_channels, image_size)\n",
    "        ffn = FeedForwardNetwork(out_channels)\n",
    "        super().__init__(\n",
    "            attention,\n",
    "            ffn\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(in_channels, num_classes)\n",
    "        self.in_channels = in_channels\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.pool(x)\n",
    "        x = torch.reshape(x, (batch_size, -1, self.in_channels))\n",
    "        return torch.squeeze(self.fc(x))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCoAtNet(nn.Sequential):\n",
    "    def __init__(self, nums_blocks, layer_out_channels, num_classes=36):\n",
    "        s0 = nn.Sequential(Stem(layer_out_channels[0]))\n",
    "        \n",
    "        s1 = [DownsamplingMBConv(layer_out_channels[0], layer_out_channels[1])]\n",
    "        for i in range(nums_blocks[1] - 1):\n",
    "            s1.append(MBConv(layer_out_channels[1], layer_out_channels[1]))\n",
    "        s1 = nn.Sequential(*s1)\n",
    "        \n",
    "        s2 = [DownsamplingMBConv(layer_out_channels[1], layer_out_channels[2])]\n",
    "        for i in range(nums_blocks[2] - 1):\n",
    "            s2.append(MBConv(layer_out_channels[2], layer_out_channels[2]))\n",
    "        s2 = nn.Sequential(*s2)\n",
    "        \n",
    "        s3 = [DownsampleTransformerBlock(layer_out_channels[2], layer_out_channels[3], 64 // 16)]\n",
    "        for i in range(nums_blocks[3] - 1):\n",
    "            s3.append(TransformerBlock(layer_out_channels[3], layer_out_channels[3], 64 // 16))\n",
    "        s3 = nn.Sequential(*s3)\n",
    "        \n",
    "        s4 = [DownsampleTransformerBlock(layer_out_channels[3], layer_out_channels[4], 64 // 32)]\n",
    "        for i in range(nums_blocks[4] - 1):\n",
    "            s4.append(TransformerBlock(layer_out_channels[4], layer_out_channels[4], 64 // 32))\n",
    "        s4 = nn.Sequential(*s4)\n",
    "        \n",
    "        head = Head(layer_out_channels[4], num_classes)\n",
    "        \n",
    "        super().__init__(\n",
    "            s0,\n",
    "            s1,\n",
    "            s2,\n",
    "            s3,\n",
    "            s4,\n",
    "            head\n",
    "        )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ali/CSCE689_LLM/venv/lib/python3.10/site-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3637.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# CoAtNet-1\n",
    "nums_blocks = [2, 2, 3, 5, 2]           # L\n",
    "channels = [64, 96, 192, 384, 768]      # D\n",
    "\n",
    "model = MyCoAtNet(nums_blocks, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_linear(m):\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "        if m.bias is not None: nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 24,033,296\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]             640\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "              GELU-3           [-1, 64, 32, 32]               0\n",
      "            Conv2d-4           [-1, 64, 30, 30]          36,928\n",
      "         MaxPool2d-5           [-1, 64, 15, 15]               0\n",
      "            Conv2d-6           [-1, 96, 15, 15]           6,144\n",
      "       BatchNorm2d-7           [-1, 64, 30, 30]             128\n",
      "            Conv2d-8          [-1, 256, 15, 15]          16,640\n",
      "       BatchNorm2d-9          [-1, 256, 15, 15]             512\n",
      "             GELU-10          [-1, 256, 15, 15]               0\n",
      "           Conv2d-11          [-1, 256, 15, 15]           2,560\n",
      "      BatchNorm2d-12          [-1, 256, 15, 15]             512\n",
      "             GELU-13          [-1, 256, 15, 15]               0\n",
      "AdaptiveAvgPool2d-14            [-1, 256, 1, 1]               0\n",
      "           Conv2d-15             [-1, 64, 1, 1]          16,448\n",
      "             GELU-16             [-1, 64, 1, 1]               0\n",
      "           Conv2d-17            [-1, 256, 1, 1]          16,640\n",
      "          Sigmoid-18            [-1, 256, 1, 1]               0\n",
      "SqueezeExcitation-19          [-1, 256, 15, 15]               0\n",
      "           Conv2d-20           [-1, 96, 15, 15]          24,672\n",
      "      BatchNorm2d-21           [-1, 96, 15, 15]             192\n",
      "DownsamplingMBConv-22           [-1, 96, 15, 15]               0\n",
      "      BatchNorm2d-23           [-1, 96, 15, 15]             192\n",
      "           Conv2d-24          [-1, 384, 15, 15]          37,248\n",
      "      BatchNorm2d-25          [-1, 384, 15, 15]             768\n",
      "             GELU-26          [-1, 384, 15, 15]               0\n",
      "           Conv2d-27          [-1, 384, 15, 15]           3,840\n",
      "      BatchNorm2d-28          [-1, 384, 15, 15]             768\n",
      "             GELU-29          [-1, 384, 15, 15]               0\n",
      "AdaptiveAvgPool2d-30            [-1, 384, 1, 1]               0\n",
      "           Conv2d-31             [-1, 96, 1, 1]          36,960\n",
      "             GELU-32             [-1, 96, 1, 1]               0\n",
      "           Conv2d-33            [-1, 384, 1, 1]          37,248\n",
      "          Sigmoid-34            [-1, 384, 1, 1]               0\n",
      "SqueezeExcitation-35          [-1, 384, 15, 15]               0\n",
      "           Conv2d-36           [-1, 96, 15, 15]          36,960\n",
      "      BatchNorm2d-37           [-1, 96, 15, 15]             192\n",
      "           MBConv-38           [-1, 96, 15, 15]               0\n",
      "        MaxPool2d-39             [-1, 96, 8, 8]               0\n",
      "           Conv2d-40            [-1, 192, 8, 8]          18,432\n",
      "      BatchNorm2d-41           [-1, 96, 15, 15]             192\n",
      "           Conv2d-42            [-1, 384, 8, 8]          37,248\n",
      "      BatchNorm2d-43            [-1, 384, 8, 8]             768\n",
      "             GELU-44            [-1, 384, 8, 8]               0\n",
      "           Conv2d-45            [-1, 384, 8, 8]           3,840\n",
      "      BatchNorm2d-46            [-1, 384, 8, 8]             768\n",
      "             GELU-47            [-1, 384, 8, 8]               0\n",
      "AdaptiveAvgPool2d-48            [-1, 384, 1, 1]               0\n",
      "           Conv2d-49             [-1, 96, 1, 1]          36,960\n",
      "             GELU-50             [-1, 96, 1, 1]               0\n",
      "           Conv2d-51            [-1, 384, 1, 1]          37,248\n",
      "          Sigmoid-52            [-1, 384, 1, 1]               0\n",
      "SqueezeExcitation-53            [-1, 384, 8, 8]               0\n",
      "           Conv2d-54            [-1, 192, 8, 8]          73,920\n",
      "      BatchNorm2d-55            [-1, 192, 8, 8]             384\n",
      "DownsamplingMBConv-56            [-1, 192, 8, 8]               0\n",
      "      BatchNorm2d-57            [-1, 192, 8, 8]             384\n",
      "           Conv2d-58            [-1, 768, 8, 8]         148,224\n",
      "      BatchNorm2d-59            [-1, 768, 8, 8]           1,536\n",
      "             GELU-60            [-1, 768, 8, 8]               0\n",
      "           Conv2d-61            [-1, 768, 8, 8]           7,680\n",
      "      BatchNorm2d-62            [-1, 768, 8, 8]           1,536\n",
      "             GELU-63            [-1, 768, 8, 8]               0\n",
      "AdaptiveAvgPool2d-64            [-1, 768, 1, 1]               0\n",
      "           Conv2d-65            [-1, 192, 1, 1]         147,648\n",
      "             GELU-66            [-1, 192, 1, 1]               0\n",
      "           Conv2d-67            [-1, 768, 1, 1]         148,224\n",
      "          Sigmoid-68            [-1, 768, 1, 1]               0\n",
      "SqueezeExcitation-69            [-1, 768, 8, 8]               0\n",
      "           Conv2d-70            [-1, 192, 8, 8]         147,648\n",
      "      BatchNorm2d-71            [-1, 192, 8, 8]             384\n",
      "           MBConv-72            [-1, 192, 8, 8]               0\n",
      "      BatchNorm2d-73            [-1, 192, 8, 8]             384\n",
      "           Conv2d-74            [-1, 768, 8, 8]         148,224\n",
      "      BatchNorm2d-75            [-1, 768, 8, 8]           1,536\n",
      "             GELU-76            [-1, 768, 8, 8]               0\n",
      "           Conv2d-77            [-1, 768, 8, 8]           7,680\n",
      "      BatchNorm2d-78            [-1, 768, 8, 8]           1,536\n",
      "             GELU-79            [-1, 768, 8, 8]               0\n",
      "AdaptiveAvgPool2d-80            [-1, 768, 1, 1]               0\n",
      "           Conv2d-81            [-1, 192, 1, 1]         147,648\n",
      "             GELU-82            [-1, 192, 1, 1]               0\n",
      "           Conv2d-83            [-1, 768, 1, 1]         148,224\n",
      "          Sigmoid-84            [-1, 768, 1, 1]               0\n",
      "SqueezeExcitation-85            [-1, 768, 8, 8]               0\n",
      "           Conv2d-86            [-1, 192, 8, 8]         147,648\n",
      "      BatchNorm2d-87            [-1, 192, 8, 8]             384\n",
      "           MBConv-88            [-1, 192, 8, 8]               0\n",
      "        MaxPool2d-89            [-1, 192, 4, 4]               0\n",
      "           Conv2d-90            [-1, 384, 4, 4]          73,728\n",
      "        LayerNorm-91            [-1, 8, 8, 192]             384\n",
      "        MaxPool2d-92            [-1, 192, 4, 4]               0\n",
      "           Linear-93              [-1, 16, 384]          74,112\n",
      "           Linear-94              [-1, 16, 384]          74,112\n",
      "           Linear-95              [-1, 16, 384]          74,112\n",
      "          Softmax-96           [-1, 12, 16, 16]               0\n",
      "           Linear-97            [-1, 4, 4, 384]         147,840\n",
      "          Dropout-98            [-1, 4, 4, 384]               0\n",
      "DownsamplingRelativeAttention2d-99            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-100            [-1, 4, 4, 384]             768\n",
      "          Linear-101             [-1, 16, 1536]         591,360\n",
      "            GELU-102             [-1, 16, 1536]               0\n",
      "         Dropout-103             [-1, 16, 1536]               0\n",
      "          Linear-104              [-1, 16, 384]         590,208\n",
      "         Dropout-105              [-1, 16, 384]               0\n",
      "FeedForwardNetwork-106            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-107            [-1, 4, 4, 384]             768\n",
      "          Linear-108              [-1, 16, 384]         147,840\n",
      "          Linear-109              [-1, 16, 384]         147,840\n",
      "          Linear-110              [-1, 16, 384]         147,840\n",
      "         Softmax-111           [-1, 12, 16, 16]               0\n",
      "          Linear-112            [-1, 4, 4, 384]         147,840\n",
      "         Dropout-113            [-1, 4, 4, 384]               0\n",
      "RelativeAttention2d-114            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-115            [-1, 4, 4, 384]             768\n",
      "          Linear-116             [-1, 16, 1536]         591,360\n",
      "            GELU-117             [-1, 16, 1536]               0\n",
      "         Dropout-118             [-1, 16, 1536]               0\n",
      "          Linear-119              [-1, 16, 384]         590,208\n",
      "         Dropout-120              [-1, 16, 384]               0\n",
      "FeedForwardNetwork-121            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-122            [-1, 4, 4, 384]             768\n",
      "          Linear-123              [-1, 16, 384]         147,840\n",
      "          Linear-124              [-1, 16, 384]         147,840\n",
      "          Linear-125              [-1, 16, 384]         147,840\n",
      "         Softmax-126           [-1, 12, 16, 16]               0\n",
      "          Linear-127            [-1, 4, 4, 384]         147,840\n",
      "         Dropout-128            [-1, 4, 4, 384]               0\n",
      "RelativeAttention2d-129            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-130            [-1, 4, 4, 384]             768\n",
      "          Linear-131             [-1, 16, 1536]         591,360\n",
      "            GELU-132             [-1, 16, 1536]               0\n",
      "         Dropout-133             [-1, 16, 1536]               0\n",
      "          Linear-134              [-1, 16, 384]         590,208\n",
      "         Dropout-135              [-1, 16, 384]               0\n",
      "FeedForwardNetwork-136            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-137            [-1, 4, 4, 384]             768\n",
      "          Linear-138              [-1, 16, 384]         147,840\n",
      "          Linear-139              [-1, 16, 384]         147,840\n",
      "          Linear-140              [-1, 16, 384]         147,840\n",
      "         Softmax-141           [-1, 12, 16, 16]               0\n",
      "          Linear-142            [-1, 4, 4, 384]         147,840\n",
      "         Dropout-143            [-1, 4, 4, 384]               0\n",
      "RelativeAttention2d-144            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-145            [-1, 4, 4, 384]             768\n",
      "          Linear-146             [-1, 16, 1536]         591,360\n",
      "            GELU-147             [-1, 16, 1536]               0\n",
      "         Dropout-148             [-1, 16, 1536]               0\n",
      "          Linear-149              [-1, 16, 384]         590,208\n",
      "         Dropout-150              [-1, 16, 384]               0\n",
      "FeedForwardNetwork-151            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-152            [-1, 4, 4, 384]             768\n",
      "          Linear-153              [-1, 16, 384]         147,840\n",
      "          Linear-154              [-1, 16, 384]         147,840\n",
      "          Linear-155              [-1, 16, 384]         147,840\n",
      "         Softmax-156           [-1, 12, 16, 16]               0\n",
      "          Linear-157            [-1, 4, 4, 384]         147,840\n",
      "         Dropout-158            [-1, 4, 4, 384]               0\n",
      "RelativeAttention2d-159            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-160            [-1, 4, 4, 384]             768\n",
      "          Linear-161             [-1, 16, 1536]         591,360\n",
      "            GELU-162             [-1, 16, 1536]               0\n",
      "         Dropout-163             [-1, 16, 1536]               0\n",
      "          Linear-164              [-1, 16, 384]         590,208\n",
      "         Dropout-165              [-1, 16, 384]               0\n",
      "FeedForwardNetwork-166            [-1, 384, 4, 4]               0\n",
      "       MaxPool2d-167            [-1, 384, 2, 2]               0\n",
      "          Conv2d-168            [-1, 768, 2, 2]         294,912\n",
      "       LayerNorm-169            [-1, 4, 4, 384]             768\n",
      "       MaxPool2d-170            [-1, 384, 2, 2]               0\n",
      "          Linear-171               [-1, 4, 768]         295,680\n",
      "          Linear-172               [-1, 4, 768]         295,680\n",
      "          Linear-173               [-1, 4, 768]         295,680\n",
      "         Softmax-174             [-1, 24, 4, 4]               0\n",
      "          Linear-175            [-1, 2, 2, 768]         590,592\n",
      "         Dropout-176            [-1, 2, 2, 768]               0\n",
      "DownsamplingRelativeAttention2d-177            [-1, 768, 2, 2]               0\n",
      "       LayerNorm-178            [-1, 2, 2, 768]           1,536\n",
      "          Linear-179              [-1, 4, 3072]       2,362,368\n",
      "            GELU-180              [-1, 4, 3072]               0\n",
      "         Dropout-181              [-1, 4, 3072]               0\n",
      "          Linear-182               [-1, 4, 768]       2,360,064\n",
      "         Dropout-183               [-1, 4, 768]               0\n",
      "FeedForwardNetwork-184            [-1, 768, 2, 2]               0\n",
      "       LayerNorm-185            [-1, 2, 2, 768]           1,536\n",
      "          Linear-186               [-1, 4, 768]         590,592\n",
      "          Linear-187               [-1, 4, 768]         590,592\n",
      "          Linear-188               [-1, 4, 768]         590,592\n",
      "         Softmax-189             [-1, 24, 4, 4]               0\n",
      "          Linear-190            [-1, 2, 2, 768]         590,592\n",
      "         Dropout-191            [-1, 2, 2, 768]               0\n",
      "RelativeAttention2d-192            [-1, 768, 2, 2]               0\n",
      "       LayerNorm-193            [-1, 2, 2, 768]           1,536\n",
      "          Linear-194              [-1, 4, 3072]       2,362,368\n",
      "            GELU-195              [-1, 4, 3072]               0\n",
      "         Dropout-196              [-1, 4, 3072]               0\n",
      "          Linear-197               [-1, 4, 768]       2,360,064\n",
      "         Dropout-198               [-1, 4, 768]               0\n",
      "FeedForwardNetwork-199            [-1, 768, 2, 2]               0\n",
      "AdaptiveAvgPool2d-200            [-1, 768, 1, 1]               0\n",
      "          Linear-201                [-1, 1, 36]          27,684\n",
      "            Head-202                   [-1, 36]               0\n",
      "================================================================\n",
      "Total params: 24,029,924\n",
      "Trainable params: 24,029,924\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 26.27\n",
      "Params size (MB): 91.67\n",
      "Estimated Total Size (MB): 117.96\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model.apply(init_linear)\n",
    "model.to(device)\n",
    "\n",
    "print(\"Number of parameters: {:,}\".format(sum(p.numel() for p in model.parameters())))\n",
    "\n",
    "summary(model, input_size=(1, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyCoAtNet(\n",
       "  (0): Sequential(\n",
       "    (0): Stem(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): DownsamplingMBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (channel_projection): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "        (5): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): DownsamplingMBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(96, 384, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "        (5): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (channel_projection): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        (5): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        (5): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): DownsampleTransformerBlock(\n",
       "      (0): DownsamplingRelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (channel_projection): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): DownsampleTransformerBlock(\n",
       "      (0): DownsamplingRelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (channel_projection): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (5): Head(\n",
       "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (fc): Linear(in_features=768, out_features=36, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model.load_state_dict(torch.load(\"CoAtNet-1-Best-Zoom.pkl\"))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_set,\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from My_CoAtNet\n",
    "def separate_parameters(model):\n",
    "    parameters_decay = set()\n",
    "    parameters_no_decay = set()\n",
    "    modules_weight_decay = (nn.Linear, nn.Conv2d)\n",
    "    modules_no_weight_decay = (nn.LayerNorm, nn.BatchNorm2d)\n",
    "    \n",
    "    for m_name, m in model.named_modules():\n",
    "        for param_name, param in m.named_parameters():\n",
    "            full_param_name = f\"{m_name}.{param_name}\" if m_name else param_name\n",
    "\n",
    "            if isinstance(m, modules_no_weight_decay):\n",
    "                parameters_no_decay.add(full_param_name)\n",
    "            elif param_name.endswith(\"bias\"):\n",
    "                parameters_no_decay.add(full_param_name)\n",
    "            elif isinstance(m, modules_weight_decay):\n",
    "                parameters_decay.add(full_param_name)\n",
    "    \n",
    "    # sanity check\n",
    "    assert len(parameters_decay & parameters_no_decay) == 0\n",
    "    assert len(parameters_decay) + len(parameters_no_decay) == len(list(model.parameters()))\n",
    "\n",
    "    return parameters_decay, parameters_no_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 5e-4\n",
    "weight_decay = 0.1\n",
    "num_epochs = 1100\n",
    "min_learning_rate = 1e-6\n",
    "\n",
    "param_dict = {pn: p for pn, p in model.named_parameters()}\n",
    "parameters_decay, parameters_no_decay = separate_parameters(model)\n",
    "parameter_groups = [\n",
    "    {\"params\": [param_dict[pn] for pn in parameters_decay], \"weight_decay\": weight_decay},\n",
    "    {\"params\": [param_dict[pn] for pn in parameters_no_decay], \"weight_decay\": 0.0},\n",
    "]\n",
    "optimizer = torch.optim.Adam(parameter_groups, lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=min_learning_rate / learning_rate, total_iters=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from My_CoAtNet\n",
    "def plot_results(train_losses, train_accuracies, val_losses, val_accuracies):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title(\"Loss\")\n",
    "    plt.plot(train_losses)\n",
    "    plt.plot(val_losses)\n",
    "    plt.legend([\"Training loss\", \"Validation loss\"], loc =  \"best\")\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.plot(train_accuracies)\n",
    "    plt.plot(val_accuracies)\n",
    "    plt.legend([\"Training accuracy\", \"Validation accuracy\"], loc =  \"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = \"CoAtNet-1-Best-Zoom.pkl\"\n",
    "model_path = \"CoAtNet-1-Zoom.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyCoAtNet(\n",
       "  (0): Sequential(\n",
       "    (0): Stem(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): DownsamplingMBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (channel_projection): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "        (5): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): DownsamplingMBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(96, 384, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "        (5): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (channel_projection): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        (5): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        (5): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): DownsampleTransformerBlock(\n",
       "      (0): DownsamplingRelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (channel_projection): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): DownsampleTransformerBlock(\n",
       "      (0): DownsamplingRelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (channel_projection): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (5): Head(\n",
       "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (fc): Linear(in_features=768, out_features=36, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mappings from indices to syllables and vice versa\n",
    "digits_and_syllables = list('0123456789abcdefghijklmnopqrstuvwxyz')\n",
    "idx_to_syllable = {idx: syllable for idx, syllable in enumerate(digits_and_syllables)}\n",
    "syllable_to_idx = {syllable: idx for idx, syllable in idx_to_syllable.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine test and validation datasets\n",
    "combined_dataset = ConcatDataset([val_set, test_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from syllables to dataset indices\n",
    "syllable_to_indices = {}\n",
    "for idx in range(len(combined_dataset)):\n",
    "    _, label = combined_dataset[idx]\n",
    "    # label = label.item() \n",
    "    syllable = idx_to_syllable[label]\n",
    "    if syllable not in syllable_to_indices:\n",
    "        syllable_to_indices[syllable] = []\n",
    "    syllable_to_indices[syllable].append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process sentences into syllables\n",
    "def get_syllables(sentence):\n",
    "    sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "    # sentence = sentence.replace(' ',  '').lower()\n",
    "    syllables = list(sentence)\n",
    "    return syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 1000\n"
     ]
    }
   ],
   "source": [
    "# Read sentences from the text file\n",
    "with open('../sentences/sentences.txt', 'r') as f:\n",
    "    sentences = f.readlines()\n",
    "\n",
    "print(\"Number of sentences:\", len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "\n",
    "def compute_accuracy_and_wrong_syllables(true_sentence, predicted_sentence):\n",
    "    # Character-level accuracy using SequenceMatcher\n",
    "    char_matcher = difflib.SequenceMatcher(None, true_sentence, predicted_sentence)\n",
    "    accuracy = char_matcher.ratio()\n",
    "    \n",
    "    # Word-level wrong syllable count using SequenceMatcher on word lists\n",
    "    true_words = true_sentence.split()\n",
    "    predicted_words = predicted_sentence.split()\n",
    "    word_matcher = difflib.SequenceMatcher(None, true_words, predicted_words)\n",
    "    \n",
    "    # Calculate wrong syllables based on insert, delete, and replace operations\n",
    "    wrong_syllables = sum(1 for tag, _, _, _, _ in word_matcher.get_opcodes() if tag in ('insert', 'delete', 'replace'))\n",
    "    \n",
    "    return accuracy, wrong_syllables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1000/1000 [08:16<00:00,  2.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# Process each sentence\n",
    "noise_factor = 0\n",
    "results = []\n",
    "\n",
    "for sentence in tqdm(sentences):\n",
    "    sentence = sentence.strip()\n",
    "    syllables = get_syllables(sentence)\n",
    "    true_sentence = ''.join(syllables)\n",
    "    predicted_syllables = []\n",
    "\n",
    "    for syllable in syllables:\n",
    "        if syllable in syllable_to_indices:\n",
    "            # Randomly select an index for the syllable\n",
    "            idx = random.choice(syllable_to_indices[syllable])\n",
    "            # Retrieve the image and label from the dataset\n",
    "            image, _ = combined_dataset[idx]\n",
    "\n",
    "            noise = torch.randn_like(image) * noise_factor\n",
    "            image = image + noise\n",
    "            image = image.unsqueeze(0).to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(image)\n",
    "                output = output.reshape(1, -1)\n",
    "                _, predicted_idx = torch.max(output.data, 1)\n",
    "                predicted_syllable = idx_to_syllable[predicted_idx.item()]\n",
    "        else:\n",
    "            if random.random() < 0.90:\n",
    "                predicted_syllable = ' '\n",
    "            else:\n",
    "                predicted_syllable = random.choice(digits_and_syllables)\n",
    "        predicted_syllables.append(predicted_syllable)\n",
    "    \n",
    "    predicted_sentence = ''.join(predicted_syllables)\n",
    "    accuracy, wrong_syllables = compute_accuracy_and_wrong_syllables(true_sentence, predicted_sentence)\n",
    "    results.append([true_sentence, predicted_sentence, accuracy, wrong_syllables])\n",
    "    # print(f\"accuracy: {accuracy}, wrong: {wrong_syllables}, true: {true_sentence}, predicted: {predicted_sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise factor: 0\n",
      "Average accuracy: 0.6136\n",
      "Total wrong syllables: 2010\n"
     ]
    }
   ],
   "source": [
    "# accuracy average and wrong syllables sum\n",
    "accuracy_avg = sum(result[2] for result in results) / len(results)\n",
    "wrong_syllables_sum = sum(result[3] for result in results)\n",
    "\n",
    "print(\"Noise factor:\", noise_factor)\n",
    "print(f\"Average accuracy: {accuracy_avg:.4f}\")\n",
    "print(f\"Total wrong syllables: {wrong_syllables_sum}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results/002_noise.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['True Sentence', 'Predicted Sentence', 'Accuracy', 'Wrong syllables'])\n",
    "    for row in results:\n",
    "        writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
