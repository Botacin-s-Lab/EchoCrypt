{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import librosa\n",
    "import os\n",
    "import random\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math\n",
    "import torchaudio\n",
    "import csv\n",
    "import string\n",
    "\n",
    "from torch.utils.data import ConcatDataset\n",
    "from torchaudio.transforms import TimeMasking, FrequencyMasking\n",
    "from torchvision.ops import SqueezeExcitation\n",
    "from torchinfo import summary\n",
    "from torchsummary import summary\n",
    "from torchvision.ops import SqueezeExcitation\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from collections import defaultdict\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from scipy.io import wavfile\n",
    "from functools import reduce\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_s = '0123456789abcdefghijklmnopqrstuvwxyz'\n",
    "labels = list(keys_s)\n",
    "keys = [k + '.wav' for k in labels]\n",
    "data_dict = {'Key':[], 'File':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def add_noise_to_stroke(stroke, noise_factor=0.005):\n",
    "    # print(stroke.shape)\n",
    "    noise = torch.randn_like(stroke)\n",
    "    return stroke + noise_factor * noise\n",
    "\n",
    "def isolator(signal, sample_rate, size, scan, before, after, threshold, show=False):\n",
    "    strokes = []\n",
    "    if show:\n",
    "        plt.figure(figsize=(7, 2))\n",
    "        librosa.display.waveshow(signal, sr=sample_rate)\n",
    "    fft = librosa.stft(signal, n_fft=size, hop_length=scan)\n",
    "    energy = np.abs(np.sum(fft, axis=0)).astype(float)\n",
    "    if show:\n",
    "        plt.figure(figsize=(7, 2))\n",
    "        librosa.display.waveshow(energy)\n",
    "    threshed = energy > threshold\n",
    "    if show:\n",
    "        plt.figure(figsize=(7, 2))\n",
    "        librosa.display.waveshow(threshed.astype(float))\n",
    "    peaks = np.where(threshed)[0]\n",
    "    peak_count = len(peaks)\n",
    "    prev_end = sample_rate * 0.1 * (-1)\n",
    "    for i in range(peak_count):\n",
    "        this_peak = peaks[i]\n",
    "        timestamp = (this_peak * scan) + size // 2\n",
    "        if timestamp > prev_end + (0.1 * sample_rate):\n",
    "            keystroke = signal[timestamp - before:timestamp + after]\n",
    "            strokes.append(torch.tensor(keystroke)[None, :])\n",
    "            if show:\n",
    "                plt.figure(figsize=(7, 2))\n",
    "                librosa.display.waveshow(keystroke, sr=sample_rate)\n",
    "            prev_end = timestamp + after\n",
    "    return strokes\n",
    "\n",
    "def convert_to_df_with_noise(audio_dir, noise_factor=0.005):\n",
    "    \"\"\"\n",
    "    Processes each audio file by isolating strokes, adds noise to each stroke,\n",
    "    and stores the strokes with labels in a dataframe.\n",
    "    \"\"\"\n",
    "    # Generate a list of .wav files in the provided directory\n",
    "    keys = sorted([f for f in os.listdir(audio_dir) if f.endswith('.wav')])\n",
    "    \n",
    "    data_dict = {'Key': [], 'File': []}\n",
    "    \n",
    "    # If your labels are inferred from file names, you can extract them here.\n",
    "    # For example, if the file is 'a.wav', you might want to use 'a' as the label.\n",
    "    def extract_label(filename):\n",
    "        base = os.path.splitext(filename)[0]\n",
    "        return base  # or apply any mapping you need\n",
    "\n",
    "    for file in keys:\n",
    "        loc = os.path.join(audio_dir, file)\n",
    "        samples, sample_rate = librosa.load(loc, sr=None)\n",
    "        strokes = []\n",
    "        prom = 0.06\n",
    "        step = 0.005\n",
    "        # Adjust threshold until we get exactly 25 strokes (or break if not possible)\n",
    "        while not len(strokes) == 25:\n",
    "            strokes = isolator(samples[1 * sample_rate:], sample_rate, 48, 24, 2400, 12000, prom, show=False)\n",
    "            if len(strokes) < 25:\n",
    "                prom -= step\n",
    "            elif len(strokes) > 25:\n",
    "                prom += step\n",
    "            if prom <= 0:\n",
    "                print('-- not possible for:', file)\n",
    "                break\n",
    "            step *= 0.99\n",
    "        \n",
    "        # Apply noise to each extracted stroke\n",
    "        noisy_strokes = [add_noise_to_stroke(stroke, noise_factor) for stroke in strokes]\n",
    "\n",
    "        # Extract a label for this file (modify as needed)\n",
    "        label = extract_label(file)\n",
    "        data_dict['Key'] += [label] * len(noisy_strokes)\n",
    "        data_dict['File'] += noisy_strokes\n",
    "\n",
    "    df = pd.DataFrame(data_dict)\n",
    "    \n",
    "    # Optionally, create a mapping for the labels (if needed)\n",
    "    mapper = {}\n",
    "    counter = 0\n",
    "    for l in df['Key']:\n",
    "        if l not in mapper:\n",
    "            mapper[l] = counter\n",
    "            counter += 1\n",
    "    df.replace({'Key': mapper}, inplace=True)\n",
    "    \n",
    "    return df, sample_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Key                                               File\n",
      "0   0  [[tensor(0.0097), tensor(0.0020), tensor(-0.00...\n",
      "1   0  [[tensor(0.0043), tensor(-0.0001), tensor(0.01...\n",
      "2   0  [[tensor(-0.0001), tensor(0.0012), tensor(0.00...\n",
      "3   0  [[tensor(0.0049), tensor(0.0025), tensor(0.001...\n",
      "4   0  [[tensor(0.0020), tensor(0.0033), tensor(0.009...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 900 entries, 0 to 899\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Key     900 non-null    object\n",
      " 1   File    900 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 14.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data_frame, sr = convert_to_df_with_noise(\"../../dataset/Zoom/\", noise_factor=0.005)\n",
    "\n",
    "print(data_frame.head())\n",
    "print(data_frame.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample rate: 32000\n",
      "630 180 90\n"
     ]
    }
   ],
   "source": [
    "train_set, tmp_set = train_test_split(data_frame, test_size=0.3, stratify=data_frame['Key'])\n",
    "val_set, test_set = train_test_split(tmp_set, test_size=0.33, stratify=tmp_set['Key'])\n",
    "\n",
    "print(\"Sample rate:\", sr)\n",
    "print(len(train_set), len(val_set), len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, file_name, transform = None, aug = None):\n",
    "        df = file_name\n",
    "        self.transform = transform\n",
    "        self.aug = aug\n",
    "        self.labels = df['Key']\n",
    "        self.values = df['File']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, index):\n",
    "        label = self.labels.iloc[index]\n",
    "        value = self.values.iloc[index]\n",
    "        waveform = self.values.iloc[index]\n",
    "        label = self.labels.iloc[index]\n",
    "        if self.transform:\n",
    "            waveform = waveform.numpy()\n",
    "            waveform = waveform.flatten()\n",
    "            waveform = self.transform(waveform)\n",
    "        if self.aug:\n",
    "            waveform = self.aug(waveform)\n",
    "        return waveform, label\n",
    "\n",
    "class ToMelSpectrogram:\n",
    "    def __call__(self, samples):\n",
    "#         samples = np.array(samples)\n",
    "        spec = librosa.feature.melspectrogram(y = samples, sr = sr, n_mels=64, n_fft=2048, win_length=1024, hop_length=226)\n",
    "        return librosa.power_to_db(spec)\n",
    "\n",
    "class TimeShifting():\n",
    "    def __call__(self, samples):\n",
    "        samples = samples.numpy()\n",
    "        samples = samples.flatten()\n",
    "        \n",
    "        shift = int(len(samples) * 0.4)\n",
    "        random_shift =random.randint(0, shift)\n",
    "        data_roll = np.roll(samples, random_shift)\n",
    "        return data_roll\n",
    "    \n",
    "class SpecAugment():\n",
    "    def __call__(self, samples):\n",
    "        num_mask = 2\n",
    "        freq_masking_max_percentage=0.10\n",
    "        time_masking_max_percentage=0.10\n",
    "        spec = samples.copy()\n",
    "        mean_value = spec.mean()\n",
    "        for i in range(num_mask):\n",
    "            all_frames_num, all_freqs_num = spec.shape[1], spec.shape[1] \n",
    "            freq_percentage = random.uniform(0.0, freq_masking_max_percentage)\n",
    "\n",
    "            num_freqs_to_mask = int(freq_percentage * all_freqs_num)\n",
    "            f0 = np.random.uniform(low=0.0, high=all_freqs_num - num_freqs_to_mask)\n",
    "            f0 = int(f0)\n",
    "            spec[:, f0:f0 + num_freqs_to_mask] = mean_value\n",
    "\n",
    "            time_percentage = random.uniform(0.0, time_masking_max_percentage)\n",
    "\n",
    "            num_frames_to_mask = int(time_percentage * all_frames_num)\n",
    "            t0 = np.random.uniform(low=0.0, high=all_frames_num - num_frames_to_mask)\n",
    "            t0 = int(t0)\n",
    "            spec[t0:t0 + num_frames_to_mask, :] = mean_value\n",
    "        return spec\n",
    "\n",
    "aug = Compose([\n",
    "    TimeShifting(),\n",
    "    ToMelSpectrogram(),\n",
    "    SpecAugment(),\n",
    "    ToTensor()\n",
    "    ])\n",
    "\n",
    "transform = Compose([\n",
    "    ToMelSpectrogram(),\n",
    "    ToTensor()])\n",
    "        \n",
    "train_set = MyDataset(train_set, aug = aug)\n",
    "val_set = MyDataset(val_set, transform = transform)\n",
    "test_set = MyDataset(test_set, transform = transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set image (augmented vs non-augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax1.imshow(train_set[0][0][0], cmap='viridis')\n",
    "ax2.imshow(val_set[0][0][0], cmap='viridis')\n",
    "print(train_set[0][0][0].shape)\n",
    "ax1.grid(False)\n",
    "ax2.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of classes: 36\n"
     ]
    }
   ],
   "source": [
    "print(\"number of classes:\", len(np.unique(data_frame['Key'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoAtNet (Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stem(nn.Sequential):\n",
    "    def __init__(self, out_channels):\n",
    "        super().__init__(\n",
    "            nn.Conv2d(1, out_channels, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MBConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, expansion_factor=4):\n",
    "        super().__init__()\n",
    "        self.mb_conv = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.Conv2d(in_channels, in_channels * expansion_factor, kernel_size=1),\n",
    "            nn.BatchNorm2d(in_channels * expansion_factor),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(in_channels * expansion_factor, in_channels * expansion_factor, kernel_size=3, padding=1, groups=in_channels * expansion_factor),\n",
    "            nn.BatchNorm2d(in_channels * expansion_factor),\n",
    "            nn.GELU(),\n",
    "            SqueezeExcitation(in_channels * expansion_factor, in_channels, activation=nn.GELU),\n",
    "            nn.Conv2d(in_channels * expansion_factor, out_channels, kernel_size=1),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.mb_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownsamplingMBConv(MBConv):\n",
    "    def __init__(self, in_channels, out_channels, expansion_factor=4):\n",
    "        super().__init__(in_channels, out_channels, expansion_factor=4)\n",
    "        self.mb_conv[1] = nn.Conv2d(in_channels, in_channels * expansion_factor, kernel_size=1, stride = 2)\n",
    "        self.channel_projection = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.channel_projection(self.pool(x)) + self.mb_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelativeAttention2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, image_size, heads=8, head_size=32):\n",
    "        super().__init__()\n",
    "        heads = out_channels // head_size\n",
    "        self.heads = heads\n",
    "        self.head_size = head_size\n",
    "        self.image_size = image_size\n",
    "        self.head_dim = heads * head_size\n",
    "        self.attend = nn.Softmax(dim=-2) # Taken from My_CoAtNet\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.to_q = nn.Linear(in_channels, self.head_dim)\n",
    "        self.to_k = nn.Linear(in_channels, self.head_dim)\n",
    "        self.to_v = nn.Linear(in_channels, self.head_dim)\n",
    "        self.to_output = nn.Sequential(\n",
    "            nn.Linear(self.head_dim, out_channels),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.normalization = nn.LayerNorm(in_channels)\n",
    "        \n",
    "        self.relative_bias = nn.Parameter(torch.randn(heads, (2 * image_size - 1) * (2 * image_size - 1)))\n",
    "        self.register_buffer(\"relative_indices\", self.get_indices(image_size, image_size)) # Taken from My_CoAtNet\n",
    "        self.precomputed_relative_bias = None\n",
    "    \n",
    "    def norm(self, x):\n",
    "        x = x.transpose(1, -1) # Taken from My_CoAtNet\n",
    "        x = self.normalization(x)\n",
    "        x = x.transpose(-1, 1) # Taken from My_CoAtNet\n",
    "        return x\n",
    "    \n",
    "    def get_relative_biases(self):\n",
    "        # Relative bias caching mentioned in CoAtNet: Marrying Convolution and Attention for All Data Sizes\n",
    "        if not self.training:\n",
    "            return self.precomputed_relative_bias\n",
    "        # Taken from od My_CoAtNet\n",
    "        indices = self.relative_indices.expand(self.heads, -1)\n",
    "        rel_pos_enc = self.relative_bias.gather(-1, indices)\n",
    "        rel_pos_enc = rel_pos_enc.unflatten(-1, (self.image_size * self.image_size, self.image_size * self.image_size))\n",
    "        return rel_pos_enc\n",
    "    \n",
    "    def reshape_for_linear(self, x):\n",
    "        b, _, _, _ = x.shape\n",
    "        return x.reshape(b, self.image_size * self.image_size, self.in_channels)\n",
    "    \n",
    "    def attention_score(self, x):\n",
    "        b, _, h, _ = x.shape\n",
    "        q = self.to_q(self.reshape_for_linear(x)).view(b, self.heads, self.head_size, -1) # Taken from My_CoAtNet\n",
    "        k = self.to_k(self.reshape_for_linear(x)).view(b, self.heads, self.head_size, -1) # Taken from My_CoAtNet\n",
    "        dots = torch.matmul(k.transpose(-1, -2), q) / math.sqrt(self.head_dim)\n",
    "        relative_biases_indexed = self.get_relative_biases()\n",
    "        return self.attend(dots + relative_biases_indexed)\n",
    "    \n",
    "    def relative_attention(self, x):\n",
    "        b, _, _, _ = x.shape\n",
    "        v = self.to_v(self.reshape_for_linear(x)).view(b, self.heads, self.head_size, -1) # Taken from My_CoAtNet\n",
    "        out = torch.matmul(v, self.attention_score(x)) # I figured this out after debugging (Still the same as My_CoAtNet)\n",
    "        out = out.view(b, self.image_size, self.image_size, -1)\n",
    "        return self.to_output(out).view(b, self.out_channels, self.image_size, self.image_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.relative_attention(self.norm(x))\n",
    "    \n",
    "    def train(self, training):\n",
    "        if not training:\n",
    "            self.precomputed_relative_bias = self.get_relative_biases()\n",
    "        super().train(training)\n",
    "        \n",
    "    # Taken from My_CoAtNet\n",
    "    @staticmethod\n",
    "    def get_indices(h, w):\n",
    "        y = torch.arange(h, dtype=torch.long)\n",
    "        x = torch.arange(w, dtype=torch.long)\n",
    "        \n",
    "        y1, x1, y2, x2 = torch.meshgrid(y, x, y, x)\n",
    "        indices = (y1 - y2 + h - 1) * (2 * w - 1) + x1 - x2 + w - 1\n",
    "        indices = indices.flatten()\n",
    "        \n",
    "        return indices\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownsamplingRelativeAttention2d(RelativeAttention2d):\n",
    "    def __init__(self, in_channels, out_channels, image_size, heads=8, head_size=32):\n",
    "        super().__init__(in_channels, out_channels, image_size, heads=8, head_size=32)\n",
    "        self.channel_projection = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.normalization = nn.LayerNorm(in_channels)\n",
    "\n",
    "\n",
    "    def norm(self, x):\n",
    "        x = x.transpose(1, -1) # Taken from My_CoAtNet\n",
    "        x = self.normalization(x)\n",
    "        x = x.transpose(-1, 1) # Taken from My_CoAtNet\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.channel_projection(self.pool(x)) + self.relative_attention(self.pool(self.norm(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, out_channels, expansion_factor=4):\n",
    "        super().__init__()\n",
    "        hidden_dim = out_channels * expansion_factor\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(out_channels, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, out_channels),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.normalization = nn.LayerNorm(out_channels)\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    \n",
    "    def norm(self, x):\n",
    "        x = x.transpose(1, -1) # Taken from My_CoAtNet\n",
    "        x = self.normalization(x)\n",
    "        x = x.transpose(-1, 1) # Taken from My_CoAtNet\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        old_shape = x.shape\n",
    "        batch_size = old_shape[0]\n",
    "        return x + torch.reshape(self.ffn(torch.reshape(self.norm(x), (batch_size, -1, self.out_channels))), old_shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownsampleTransformerBlock(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels, image_size):\n",
    "        attention = DownsamplingRelativeAttention2d(in_channels, out_channels, image_size)\n",
    "        ffn = FeedForwardNetwork(out_channels)\n",
    "        super().__init__(\n",
    "            attention,\n",
    "            ffn\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels, image_size):\n",
    "        attention = RelativeAttention2d(in_channels, out_channels, image_size)\n",
    "        ffn = FeedForwardNetwork(out_channels)\n",
    "        super().__init__(\n",
    "            attention,\n",
    "            ffn\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(in_channels, num_classes)\n",
    "        self.in_channels = in_channels\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.pool(x)\n",
    "        x = torch.reshape(x, (batch_size, -1, self.in_channels))\n",
    "        return torch.squeeze(self.fc(x))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCoAtNet(nn.Sequential):\n",
    "    def __init__(self, nums_blocks, layer_out_channels, num_classes=36):\n",
    "        s0 = nn.Sequential(Stem(layer_out_channels[0]))\n",
    "        \n",
    "        s1 = [DownsamplingMBConv(layer_out_channels[0], layer_out_channels[1])]\n",
    "        for i in range(nums_blocks[1] - 1):\n",
    "            s1.append(MBConv(layer_out_channels[1], layer_out_channels[1]))\n",
    "        s1 = nn.Sequential(*s1)\n",
    "        \n",
    "        s2 = [DownsamplingMBConv(layer_out_channels[1], layer_out_channels[2])]\n",
    "        for i in range(nums_blocks[2] - 1):\n",
    "            s2.append(MBConv(layer_out_channels[2], layer_out_channels[2]))\n",
    "        s2 = nn.Sequential(*s2)\n",
    "        \n",
    "        s3 = [DownsampleTransformerBlock(layer_out_channels[2], layer_out_channels[3], 64 // 16)]\n",
    "        for i in range(nums_blocks[3] - 1):\n",
    "            s3.append(TransformerBlock(layer_out_channels[3], layer_out_channels[3], 64 // 16))\n",
    "        s3 = nn.Sequential(*s3)\n",
    "        \n",
    "        s4 = [DownsampleTransformerBlock(layer_out_channels[3], layer_out_channels[4], 64 // 32)]\n",
    "        for i in range(nums_blocks[4] - 1):\n",
    "            s4.append(TransformerBlock(layer_out_channels[4], layer_out_channels[4], 64 // 32))\n",
    "        s4 = nn.Sequential(*s4)\n",
    "        \n",
    "        head = Head(layer_out_channels[4], num_classes)\n",
    "        \n",
    "        super().__init__(\n",
    "            s0,\n",
    "            s1,\n",
    "            s2,\n",
    "            s3,\n",
    "            s4,\n",
    "            head\n",
    "        )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\miniconda3\\Lib\\site-packages\\torch\\functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# CoAtNet-1\n",
    "nums_blocks = [2, 2, 3, 5, 2]           # L\n",
    "channels = [64, 96, 192, 384, 768]      # D\n",
    "\n",
    "model = MyCoAtNet(nums_blocks, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_linear(m):\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "        if m.bias is not None: nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 24,033,296\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]             640\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "              GELU-3           [-1, 64, 32, 32]               0\n",
      "            Conv2d-4           [-1, 64, 30, 30]          36,928\n",
      "         MaxPool2d-5           [-1, 64, 15, 15]               0\n",
      "            Conv2d-6           [-1, 96, 15, 15]           6,144\n",
      "       BatchNorm2d-7           [-1, 64, 30, 30]             128\n",
      "            Conv2d-8          [-1, 256, 15, 15]          16,640\n",
      "       BatchNorm2d-9          [-1, 256, 15, 15]             512\n",
      "             GELU-10          [-1, 256, 15, 15]               0\n",
      "           Conv2d-11          [-1, 256, 15, 15]           2,560\n",
      "      BatchNorm2d-12          [-1, 256, 15, 15]             512\n",
      "             GELU-13          [-1, 256, 15, 15]               0\n",
      "AdaptiveAvgPool2d-14            [-1, 256, 1, 1]               0\n",
      "           Conv2d-15             [-1, 64, 1, 1]          16,448\n",
      "             GELU-16             [-1, 64, 1, 1]               0\n",
      "           Conv2d-17            [-1, 256, 1, 1]          16,640\n",
      "          Sigmoid-18            [-1, 256, 1, 1]               0\n",
      "SqueezeExcitation-19          [-1, 256, 15, 15]               0\n",
      "           Conv2d-20           [-1, 96, 15, 15]          24,672\n",
      "      BatchNorm2d-21           [-1, 96, 15, 15]             192\n",
      "DownsamplingMBConv-22           [-1, 96, 15, 15]               0\n",
      "      BatchNorm2d-23           [-1, 96, 15, 15]             192\n",
      "           Conv2d-24          [-1, 384, 15, 15]          37,248\n",
      "      BatchNorm2d-25          [-1, 384, 15, 15]             768\n",
      "             GELU-26          [-1, 384, 15, 15]               0\n",
      "           Conv2d-27          [-1, 384, 15, 15]           3,840\n",
      "      BatchNorm2d-28          [-1, 384, 15, 15]             768\n",
      "             GELU-29          [-1, 384, 15, 15]               0\n",
      "AdaptiveAvgPool2d-30            [-1, 384, 1, 1]               0\n",
      "           Conv2d-31             [-1, 96, 1, 1]          36,960\n",
      "             GELU-32             [-1, 96, 1, 1]               0\n",
      "           Conv2d-33            [-1, 384, 1, 1]          37,248\n",
      "          Sigmoid-34            [-1, 384, 1, 1]               0\n",
      "SqueezeExcitation-35          [-1, 384, 15, 15]               0\n",
      "           Conv2d-36           [-1, 96, 15, 15]          36,960\n",
      "      BatchNorm2d-37           [-1, 96, 15, 15]             192\n",
      "           MBConv-38           [-1, 96, 15, 15]               0\n",
      "        MaxPool2d-39             [-1, 96, 8, 8]               0\n",
      "           Conv2d-40            [-1, 192, 8, 8]          18,432\n",
      "      BatchNorm2d-41           [-1, 96, 15, 15]             192\n",
      "           Conv2d-42            [-1, 384, 8, 8]          37,248\n",
      "      BatchNorm2d-43            [-1, 384, 8, 8]             768\n",
      "             GELU-44            [-1, 384, 8, 8]               0\n",
      "           Conv2d-45            [-1, 384, 8, 8]           3,840\n",
      "      BatchNorm2d-46            [-1, 384, 8, 8]             768\n",
      "             GELU-47            [-1, 384, 8, 8]               0\n",
      "AdaptiveAvgPool2d-48            [-1, 384, 1, 1]               0\n",
      "           Conv2d-49             [-1, 96, 1, 1]          36,960\n",
      "             GELU-50             [-1, 96, 1, 1]               0\n",
      "           Conv2d-51            [-1, 384, 1, 1]          37,248\n",
      "          Sigmoid-52            [-1, 384, 1, 1]               0\n",
      "SqueezeExcitation-53            [-1, 384, 8, 8]               0\n",
      "           Conv2d-54            [-1, 192, 8, 8]          73,920\n",
      "      BatchNorm2d-55            [-1, 192, 8, 8]             384\n",
      "DownsamplingMBConv-56            [-1, 192, 8, 8]               0\n",
      "      BatchNorm2d-57            [-1, 192, 8, 8]             384\n",
      "           Conv2d-58            [-1, 768, 8, 8]         148,224\n",
      "      BatchNorm2d-59            [-1, 768, 8, 8]           1,536\n",
      "             GELU-60            [-1, 768, 8, 8]               0\n",
      "           Conv2d-61            [-1, 768, 8, 8]           7,680\n",
      "      BatchNorm2d-62            [-1, 768, 8, 8]           1,536\n",
      "             GELU-63            [-1, 768, 8, 8]               0\n",
      "AdaptiveAvgPool2d-64            [-1, 768, 1, 1]               0\n",
      "           Conv2d-65            [-1, 192, 1, 1]         147,648\n",
      "             GELU-66            [-1, 192, 1, 1]               0\n",
      "           Conv2d-67            [-1, 768, 1, 1]         148,224\n",
      "          Sigmoid-68            [-1, 768, 1, 1]               0\n",
      "SqueezeExcitation-69            [-1, 768, 8, 8]               0\n",
      "           Conv2d-70            [-1, 192, 8, 8]         147,648\n",
      "      BatchNorm2d-71            [-1, 192, 8, 8]             384\n",
      "           MBConv-72            [-1, 192, 8, 8]               0\n",
      "      BatchNorm2d-73            [-1, 192, 8, 8]             384\n",
      "           Conv2d-74            [-1, 768, 8, 8]         148,224\n",
      "      BatchNorm2d-75            [-1, 768, 8, 8]           1,536\n",
      "             GELU-76            [-1, 768, 8, 8]               0\n",
      "           Conv2d-77            [-1, 768, 8, 8]           7,680\n",
      "      BatchNorm2d-78            [-1, 768, 8, 8]           1,536\n",
      "             GELU-79            [-1, 768, 8, 8]               0\n",
      "AdaptiveAvgPool2d-80            [-1, 768, 1, 1]               0\n",
      "           Conv2d-81            [-1, 192, 1, 1]         147,648\n",
      "             GELU-82            [-1, 192, 1, 1]               0\n",
      "           Conv2d-83            [-1, 768, 1, 1]         148,224\n",
      "          Sigmoid-84            [-1, 768, 1, 1]               0\n",
      "SqueezeExcitation-85            [-1, 768, 8, 8]               0\n",
      "           Conv2d-86            [-1, 192, 8, 8]         147,648\n",
      "      BatchNorm2d-87            [-1, 192, 8, 8]             384\n",
      "           MBConv-88            [-1, 192, 8, 8]               0\n",
      "        MaxPool2d-89            [-1, 192, 4, 4]               0\n",
      "           Conv2d-90            [-1, 384, 4, 4]          73,728\n",
      "        LayerNorm-91            [-1, 8, 8, 192]             384\n",
      "        MaxPool2d-92            [-1, 192, 4, 4]               0\n",
      "           Linear-93              [-1, 16, 384]          74,112\n",
      "           Linear-94              [-1, 16, 384]          74,112\n",
      "           Linear-95              [-1, 16, 384]          74,112\n",
      "          Softmax-96           [-1, 12, 16, 16]               0\n",
      "           Linear-97            [-1, 4, 4, 384]         147,840\n",
      "          Dropout-98            [-1, 4, 4, 384]               0\n",
      "DownsamplingRelativeAttention2d-99            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-100            [-1, 4, 4, 384]             768\n",
      "          Linear-101             [-1, 16, 1536]         591,360\n",
      "            GELU-102             [-1, 16, 1536]               0\n",
      "         Dropout-103             [-1, 16, 1536]               0\n",
      "          Linear-104              [-1, 16, 384]         590,208\n",
      "         Dropout-105              [-1, 16, 384]               0\n",
      "FeedForwardNetwork-106            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-107            [-1, 4, 4, 384]             768\n",
      "          Linear-108              [-1, 16, 384]         147,840\n",
      "          Linear-109              [-1, 16, 384]         147,840\n",
      "          Linear-110              [-1, 16, 384]         147,840\n",
      "         Softmax-111           [-1, 12, 16, 16]               0\n",
      "          Linear-112            [-1, 4, 4, 384]         147,840\n",
      "         Dropout-113            [-1, 4, 4, 384]               0\n",
      "RelativeAttention2d-114            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-115            [-1, 4, 4, 384]             768\n",
      "          Linear-116             [-1, 16, 1536]         591,360\n",
      "            GELU-117             [-1, 16, 1536]               0\n",
      "         Dropout-118             [-1, 16, 1536]               0\n",
      "          Linear-119              [-1, 16, 384]         590,208\n",
      "         Dropout-120              [-1, 16, 384]               0\n",
      "FeedForwardNetwork-121            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-122            [-1, 4, 4, 384]             768\n",
      "          Linear-123              [-1, 16, 384]         147,840\n",
      "          Linear-124              [-1, 16, 384]         147,840\n",
      "          Linear-125              [-1, 16, 384]         147,840\n",
      "         Softmax-126           [-1, 12, 16, 16]               0\n",
      "          Linear-127            [-1, 4, 4, 384]         147,840\n",
      "         Dropout-128            [-1, 4, 4, 384]               0\n",
      "RelativeAttention2d-129            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-130            [-1, 4, 4, 384]             768\n",
      "          Linear-131             [-1, 16, 1536]         591,360\n",
      "            GELU-132             [-1, 16, 1536]               0\n",
      "         Dropout-133             [-1, 16, 1536]               0\n",
      "          Linear-134              [-1, 16, 384]         590,208\n",
      "         Dropout-135              [-1, 16, 384]               0\n",
      "FeedForwardNetwork-136            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-137            [-1, 4, 4, 384]             768\n",
      "          Linear-138              [-1, 16, 384]         147,840\n",
      "          Linear-139              [-1, 16, 384]         147,840\n",
      "          Linear-140              [-1, 16, 384]         147,840\n",
      "         Softmax-141           [-1, 12, 16, 16]               0\n",
      "          Linear-142            [-1, 4, 4, 384]         147,840\n",
      "         Dropout-143            [-1, 4, 4, 384]               0\n",
      "RelativeAttention2d-144            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-145            [-1, 4, 4, 384]             768\n",
      "          Linear-146             [-1, 16, 1536]         591,360\n",
      "            GELU-147             [-1, 16, 1536]               0\n",
      "         Dropout-148             [-1, 16, 1536]               0\n",
      "          Linear-149              [-1, 16, 384]         590,208\n",
      "         Dropout-150              [-1, 16, 384]               0\n",
      "FeedForwardNetwork-151            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-152            [-1, 4, 4, 384]             768\n",
      "          Linear-153              [-1, 16, 384]         147,840\n",
      "          Linear-154              [-1, 16, 384]         147,840\n",
      "          Linear-155              [-1, 16, 384]         147,840\n",
      "         Softmax-156           [-1, 12, 16, 16]               0\n",
      "          Linear-157            [-1, 4, 4, 384]         147,840\n",
      "         Dropout-158            [-1, 4, 4, 384]               0\n",
      "RelativeAttention2d-159            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-160            [-1, 4, 4, 384]             768\n",
      "          Linear-161             [-1, 16, 1536]         591,360\n",
      "            GELU-162             [-1, 16, 1536]               0\n",
      "         Dropout-163             [-1, 16, 1536]               0\n",
      "          Linear-164              [-1, 16, 384]         590,208\n",
      "         Dropout-165              [-1, 16, 384]               0\n",
      "FeedForwardNetwork-166            [-1, 384, 4, 4]               0\n",
      "       MaxPool2d-167            [-1, 384, 2, 2]               0\n",
      "          Conv2d-168            [-1, 768, 2, 2]         294,912\n",
      "       LayerNorm-169            [-1, 4, 4, 384]             768\n",
      "       MaxPool2d-170            [-1, 384, 2, 2]               0\n",
      "          Linear-171               [-1, 4, 768]         295,680\n",
      "          Linear-172               [-1, 4, 768]         295,680\n",
      "          Linear-173               [-1, 4, 768]         295,680\n",
      "         Softmax-174             [-1, 24, 4, 4]               0\n",
      "          Linear-175            [-1, 2, 2, 768]         590,592\n",
      "         Dropout-176            [-1, 2, 2, 768]               0\n",
      "DownsamplingRelativeAttention2d-177            [-1, 768, 2, 2]               0\n",
      "       LayerNorm-178            [-1, 2, 2, 768]           1,536\n",
      "          Linear-179              [-1, 4, 3072]       2,362,368\n",
      "            GELU-180              [-1, 4, 3072]               0\n",
      "         Dropout-181              [-1, 4, 3072]               0\n",
      "          Linear-182               [-1, 4, 768]       2,360,064\n",
      "         Dropout-183               [-1, 4, 768]               0\n",
      "FeedForwardNetwork-184            [-1, 768, 2, 2]               0\n",
      "       LayerNorm-185            [-1, 2, 2, 768]           1,536\n",
      "          Linear-186               [-1, 4, 768]         590,592\n",
      "          Linear-187               [-1, 4, 768]         590,592\n",
      "          Linear-188               [-1, 4, 768]         590,592\n",
      "         Softmax-189             [-1, 24, 4, 4]               0\n",
      "          Linear-190            [-1, 2, 2, 768]         590,592\n",
      "         Dropout-191            [-1, 2, 2, 768]               0\n",
      "RelativeAttention2d-192            [-1, 768, 2, 2]               0\n",
      "       LayerNorm-193            [-1, 2, 2, 768]           1,536\n",
      "          Linear-194              [-1, 4, 3072]       2,362,368\n",
      "            GELU-195              [-1, 4, 3072]               0\n",
      "         Dropout-196              [-1, 4, 3072]               0\n",
      "          Linear-197               [-1, 4, 768]       2,360,064\n",
      "         Dropout-198               [-1, 4, 768]               0\n",
      "FeedForwardNetwork-199            [-1, 768, 2, 2]               0\n",
      "AdaptiveAvgPool2d-200            [-1, 768, 1, 1]               0\n",
      "          Linear-201                [-1, 1, 36]          27,684\n",
      "            Head-202                   [-1, 36]               0\n",
      "================================================================\n",
      "Total params: 24,029,924\n",
      "Trainable params: 24,029,924\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 26.27\n",
      "Params size (MB): 91.67\n",
      "Estimated Total Size (MB): 117.96\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model.apply(init_linear)\n",
    "model.to(device)\n",
    "\n",
    "print(\"Number of parameters: {:,}\".format(sum(p.numel() for p in model.parameters())))\n",
    "\n",
    "summary(model, input_size=(1, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyCoAtNet(\n",
       "  (0): Sequential(\n",
       "    (0): Stem(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): DownsamplingMBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (channel_projection): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "        (5): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): DownsamplingMBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(96, 384, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "        (5): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (channel_projection): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        (5): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        (5): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): DownsampleTransformerBlock(\n",
       "      (0): DownsamplingRelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (channel_projection): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): DownsampleTransformerBlock(\n",
       "      (0): DownsamplingRelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (channel_projection): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (5): Head(\n",
       "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (fc): Linear(in_features=768, out_features=36, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model.load_state_dict(torch.load(\"CoAtNet-1-Best-Zoom.pkl\"))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_set,\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from My_CoAtNet\n",
    "def separate_parameters(model):\n",
    "    parameters_decay = set()\n",
    "    parameters_no_decay = set()\n",
    "    modules_weight_decay = (nn.Linear, nn.Conv2d)\n",
    "    modules_no_weight_decay = (nn.LayerNorm, nn.BatchNorm2d)\n",
    "    \n",
    "    for m_name, m in model.named_modules():\n",
    "        for param_name, param in m.named_parameters():\n",
    "            full_param_name = f\"{m_name}.{param_name}\" if m_name else param_name\n",
    "\n",
    "            if isinstance(m, modules_no_weight_decay):\n",
    "                parameters_no_decay.add(full_param_name)\n",
    "            elif param_name.endswith(\"bias\"):\n",
    "                parameters_no_decay.add(full_param_name)\n",
    "            elif isinstance(m, modules_weight_decay):\n",
    "                parameters_decay.add(full_param_name)\n",
    "    \n",
    "    # sanity check\n",
    "    assert len(parameters_decay & parameters_no_decay) == 0\n",
    "    assert len(parameters_decay) + len(parameters_no_decay) == len(list(model.parameters()))\n",
    "\n",
    "    return parameters_decay, parameters_no_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 5e-4\n",
    "weight_decay = 0.1\n",
    "num_epochs = 1100\n",
    "min_learning_rate = 1e-6\n",
    "\n",
    "param_dict = {pn: p for pn, p in model.named_parameters()}\n",
    "parameters_decay, parameters_no_decay = separate_parameters(model)\n",
    "parameter_groups = [\n",
    "    {\"params\": [param_dict[pn] for pn in parameters_decay], \"weight_decay\": weight_decay},\n",
    "    {\"params\": [param_dict[pn] for pn in parameters_no_decay], \"weight_decay\": 0.0},\n",
    "]\n",
    "optimizer = torch.optim.Adam(parameter_groups, lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=min_learning_rate / learning_rate, total_iters=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from My_CoAtNet\n",
    "def plot_results(train_losses, train_accuracies, val_losses, val_accuracies):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title(\"Loss\")\n",
    "    plt.plot(train_losses)\n",
    "    plt.plot(val_losses)\n",
    "    plt.legend([\"Training loss\", \"Validation loss\"], loc =  \"best\")\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.plot(train_accuracies)\n",
    "    plt.plot(val_accuracies)\n",
    "    plt.legend([\"Training accuracy\", \"Validation accuracy\"], loc =  \"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = \"CoAtNet-1-Best-Zoom.pkl\"\n",
    "model_path = \"CoAtNet-1-Zoom.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyCoAtNet(\n",
       "  (0): Sequential(\n",
       "    (0): Stem(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): DownsamplingMBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (channel_projection): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "        (5): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): DownsamplingMBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(96, 384, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "        (5): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (channel_projection): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        (5): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        (5): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): DownsampleTransformerBlock(\n",
       "      (0): DownsamplingRelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (channel_projection): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): DownsampleTransformerBlock(\n",
       "      (0): DownsamplingRelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (channel_projection): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (5): Head(\n",
       "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (fc): Linear(in_features=768, out_features=36, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mappings from indices to syllables and vice versa\n",
    "digits_and_syllables = list('0123456789abcdefghijklmnopqrstuvwxyz')\n",
    "idx_to_syllable = {idx: syllable for idx, syllable in enumerate(digits_and_syllables)}\n",
    "syllable_to_idx = {syllable: idx for idx, syllable in idx_to_syllable.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine test and validation datasets\n",
    "combined_dataset = ConcatDataset([val_set, test_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from syllables to dataset indices\n",
    "syllable_to_indices = {}\n",
    "for idx in range(len(combined_dataset)):\n",
    "    _, label = combined_dataset[idx]\n",
    "    # label = label.item() \n",
    "    syllable = idx_to_syllable[label]\n",
    "    if syllable not in syllable_to_indices:\n",
    "        syllable_to_indices[syllable] = []\n",
    "    syllable_to_indices[syllable].append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process sentences into syllables\n",
    "def get_syllables(sentence):\n",
    "    sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "    # sentence = sentence.replace(' ',  '').lower()\n",
    "    syllables = list(sentence)\n",
    "    return syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 1000\n"
     ]
    }
   ],
   "source": [
    "# Read sentences from the text file\n",
    "with open('../sentences/sentences.txt', 'r') as f:\n",
    "    sentences = f.readlines()\n",
    "\n",
    "print(\"Number of sentences:\", len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "\n",
    "def compute_accuracy_and_wrong_syllables(true_sentence, predicted_sentence):\n",
    "    # Character-level accuracy using SequenceMatcher\n",
    "    char_matcher = difflib.SequenceMatcher(None, true_sentence, predicted_sentence)\n",
    "    accuracy = char_matcher.ratio()\n",
    "    \n",
    "    # Word-level wrong syllable count using SequenceMatcher on word lists\n",
    "    true_words = true_sentence.split()\n",
    "    predicted_words = predicted_sentence.split()\n",
    "    word_matcher = difflib.SequenceMatcher(None, true_words, predicted_words)\n",
    "    \n",
    "    # Calculate wrong syllables based on insert, delete, and replace operations\n",
    "    wrong_syllables = sum(1 for tag, _, _, _, _ in word_matcher.get_opcodes() if tag in ('insert', 'delete', 'replace'))\n",
    "    \n",
    "    return accuracy, wrong_syllables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:13<00:00,  1.34s/it]\n"
     ]
    }
   ],
   "source": [
    "# Process each sentence\n",
    "noise_factor = 6\n",
    "results = []\n",
    "\n",
    "for sentence in tqdm(sentences[:10]):\n",
    "    sentence = sentence.strip()\n",
    "    syllables = get_syllables(sentence)\n",
    "    true_sentence = ''.join(syllables)\n",
    "    predicted_syllables = []\n",
    "\n",
    "    for syllable in syllables:\n",
    "        if syllable in syllable_to_indices:\n",
    "            # Randomly select an index for the syllable\n",
    "            idx = random.choice(syllable_to_indices[syllable])\n",
    "            # Retrieve the image and label from the dataset\n",
    "            image, _ = combined_dataset[idx]\n",
    "\n",
    "            noise = torch.randn_like(image) * noise_factor\n",
    "            image = image + noise\n",
    "            image = image.unsqueeze(0).to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(image)\n",
    "                output = output.reshape(1, -1)\n",
    "                _, predicted_idx = torch.max(output.data, 1)\n",
    "                predicted_syllable = idx_to_syllable[predicted_idx.item()]\n",
    "        else:\n",
    "            if random.random() < 0.90:\n",
    "                predicted_syllable = ' '\n",
    "            else:\n",
    "                predicted_syllable = random.choice(digits_and_syllables)\n",
    "        predicted_syllables.append(predicted_syllable)\n",
    "    \n",
    "    predicted_sentence = ''.join(predicted_syllables)\n",
    "    accuracy, wrong_syllables = compute_accuracy_and_wrong_syllables(true_sentence, predicted_sentence)\n",
    "    results.append([true_sentence, predicted_sentence, accuracy, wrong_syllables])\n",
    "    # print(f\"accuracy: {accuracy}, wrong: {wrong_syllables}, true: {true_sentence}, predicted: {predicted_sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise factor: 6\n",
      "Average accuracy: 0.1508\n",
      "Total wrong syllables: 12\n"
     ]
    }
   ],
   "source": [
    "# accuracy average and wrong syllables sum\n",
    "accuracy_avg = sum(result[2] for result in results) / len(results)\n",
    "wrong_syllables_sum = sum(result[3] for result in results)\n",
    "\n",
    "print(\"Noise factor:\", noise_factor)\n",
    "print(f\"Average accuracy: {accuracy_avg:.4f}\")\n",
    "print(f\"Total wrong syllables: {wrong_syllables_sum}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Noise level: 1\n",
    "- Average accuracy: 0.9776\n",
    "- Total wrong syllables: 1355\n",
    "---\n",
    "- Noise factor: 5\n",
    "- Average accuracy: 0.8453\n",
    "- Total wrong syllables: 2878\n",
    "---\n",
    "- Noise factor: 6\n",
    "- Average accuracy: 0.7241\n",
    "- Total wrong syllables: 2257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results/{noise_factor}.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['True Sentence', 'Predicted Sentence', 'Accuracy', 'Wrong syllables'])\n",
    "    for row in results:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
